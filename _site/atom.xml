<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>turboFei's blog</title>
 <link href="http://turbofei.github.io/" rel="self"/>
 <link href="http://turbofei.github.io"/>
 <updated>2019-05-19T15:35:09+08:00</updated>
 <id>http://turbofei.github.io</id>
 <author>
   <name>feiwang</name>
   <email>turbofei@foxmail.com</email>
 </author>

 
 <entry>
   <title>Scala Concurrent Programming: Future And Thread</title>
   <link href="http://turbofei.github.io/coding/2019/05/19/scala-concurrent-programming-Future-And-Thread"/>
   <updated>2019-05-19T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/coding/2019/05/19/scala-concurrent-programming:-Future-And-Thread</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#java-future&quot; id=&quot;markdown-toc-java-future&quot;&gt;Java Future&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scala-future&quot; id=&quot;markdown-toc-scala-future&quot;&gt;Scala Future&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thread&quot; id=&quot;markdown-toc-thread&quot;&gt;Thread&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#thread状态&quot; id=&quot;markdown-toc-thread状态&quot;&gt;Thread状态&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#thread-方法解析&quot; id=&quot;markdown-toc-thread-方法解析&quot;&gt;Thread 方法解析&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;简单写下scala中的Future以及对Thread的认识&lt;/p&gt;

&lt;p&gt;java和scala中都有Future，那么这两个Future有什么不同呢？Thread是怎么样的，它的状态是如何变化的呢？一些操作比如sleep会涉及到锁么？&lt;/p&gt;

&lt;h3 id=&quot;java-future&quot;&gt;Java Future&lt;/h3&gt;

&lt;p&gt;java中Future类中方法很简单，也很少.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cancel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mayInterruptIfRunning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isCancelled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InterruptedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExecutionException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimeUnit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InterruptedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExecutionException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimeoutException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;比较常用的就是get，可以设置超时时间。下面是使用java Future的一个场景，通常是使用线程池submit Callable。记得线程池要放在finally模块关闭。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testJavaFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Executors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newFixedThreadPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TimeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SECONDS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;scala-future&quot;&gt;Scala Future&lt;/h3&gt;

&lt;p&gt;相较于java的Future，scala的Future中方法很丰富。而且scala中伴生对象的apply方法使得创建一个Future非常方便.例如:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s&quot;&gt;&quot; future!&quot;&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;介绍其中几个方法，用法写在注释中，println结果也在注释中。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.generic.CanBuildFrom&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.duration.Duration&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.Success&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.control.NonFatal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestScalaFuture&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executionContext&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFutureWithFailure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * recover方法是在Future发生异常时的处理。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testRecover&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFutureWithFailure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recover&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// -1
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 将两个Future zip到一起，这样就只需要使用一个Await就可以等结果。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testZip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// (1,2)
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 功能类似于zip，是处理更多个，需要指定CanBuildFrom。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testSequence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;CanBuildFrom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 1 2 3
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 这里的map， flatMap等操作是对返回值进行的操作，也是lazy的。
   * 这里的andThen不会改变返回值。
   * Transform是对返回值进行的操作，以及对异常的转换。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testMisc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 8
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;andThen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;the value is 2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 这里只是执行一些操作，但是不会改变Future的返回值
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 2
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;str:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NonFatal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// str:3
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;thread&quot;&gt;Thread&lt;/h3&gt;

&lt;p&gt;Thread类实现了Runnable，是一个特殊的Runnable类。&lt;/p&gt;

&lt;p&gt;一个线程代表一个程序的执行。jvm允许一个应用并发执行多个线程。每个线程都有一个优先级，优先级高的线程相对于优先级低的线程，更容易被执行。每个线程都可能被标记为一个守护(daemon)线程。当一个线程创建了一个新的线程，这个新的线程的优先级初始化为和创建它的线程一样。&lt;/p&gt;

&lt;p&gt;当一个JVM 启动时，通常是只有一个非守护线程。JVM会一直运行直到:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;exit方法被调用，并且允许exit。&lt;/li&gt;
  &lt;li&gt;所有非守护线程都已经结束，可以是正常返回结束也可以是异常结束。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有两种方法生成一个新的执行线程。&lt;/p&gt;

&lt;p&gt;一种是继承Thread类，overwrite run方法，然后start。&lt;/p&gt;

&lt;p&gt;另一种是继承&lt;code class=&quot;highlighter-rouge&quot;&gt;Runnable&lt;/code&gt;类，实现run方法，然后 &lt;code class=&quot;highlighter-rouge&quot;&gt;new Thread(runnable).start.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;线程的优先级分为1，5，10。1是所允许的最低优先级，5是默认分配，10是能够拥有的最高优先级。&lt;/p&gt;

&lt;p&gt;Thread类里面提供了一些静态工具方法. &lt;strong&gt;Deprecated&lt;/strong&gt;的方法不再列出.&lt;/p&gt;

&lt;h4 id=&quot;thread状态&quot;&gt;Thread状态&lt;/h4&gt;

&lt;p&gt;首先，thread的五种状态.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NEW 线程被创建，还没start&lt;/li&gt;
  &lt;li&gt;RUNNABLE  在JVM上运行，可能在等操作系统的资源，比如时间片&lt;/li&gt;
  &lt;li&gt;BLOCKED 阻塞状态，等待lock来进入同步代码块&lt;/li&gt;
  &lt;li&gt;WAITING
    &lt;ul&gt;
      &lt;li&gt;Object.wait 没有指定timeout&lt;/li&gt;
      &lt;li&gt;因为Thread.join 无timeout等待&lt;/li&gt;
      &lt;li&gt;LockSupport.park()无限期等待&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TIMED_WAITING  有timeout的WAITING
    &lt;ul&gt;
      &lt;li&gt;Object.wait(long)&lt;/li&gt;
      &lt;li&gt;Thread.join(long)&lt;/li&gt;
      &lt;li&gt;LockSupport.parkNanos LockSupport.parkUntil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TREMINATED  线程退出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;thread-方法解析&quot;&gt;Thread 方法解析&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;yield&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;yield方法是给调度器一个hint表明自己自愿放弃当前的处理器，调度器可以忽略这个hint。这个方法不推荐，很少使用，可以用于避免cpu过度利用，但是使用之前要做好详细的分析与benchmark。spark项目中没有用到过yield.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sleep&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;sleep方法比较常用，这是将当前线程放弃执行，休眠一段时间，但是sleep不会放弃自己得到的monitor.&lt;/p&gt;

&lt;p&gt;sleep(0)的意思代表是，大家所有线程重新抢占一下处理器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;threadGroup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在创建thread时候可以传入threadGroup参数。如果没有传入group，如果该线程指定了securityManager，则去问securityManager拿group，最终是拿currentThread的group，如果没指定securityManager，则和父线程一组。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;开始运行线程，jvm调用run()方法。一个线程只能启动一次，否则会报IllegalThreadStateException。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;run&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现的Runnable的run方法，用于让jvm调用&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interrupt&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果是线程自己interrupt自己，是允许的，否则，需要securityManager进行checkAccess，可能会抛出SecurityException。&lt;/p&gt;

&lt;p&gt;interrupt之后会加一个标志位interrupted.&lt;/p&gt;

&lt;p&gt;如果此时该线程被 wait, join, sleep, 那么这个interrupted标志位会被清除然后抛出InterruptedException.&lt;/p&gt;

&lt;p&gt;如果线程被&lt;code class=&quot;highlighter-rouge&quot;&gt;java.nio.channels.InterruptibleChannel&lt;/code&gt;的I/O操作阻塞，那么这个channel将被关闭，然后set interrupted标志位，这个线程会收到一个&lt;code class=&quot;highlighter-rouge&quot;&gt;ClosedByInterruptException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;如果线程被&lt;code class=&quot;highlighter-rouge&quot;&gt;java.nio.channels.Selector&lt;/code&gt;阻塞，那么将会设置interrupted标志位，并马上从selection操作返回。&lt;/p&gt;

&lt;p&gt;如果上述情况都没发生，那么这个线程设置interrup状态标志位.&lt;/p&gt;

&lt;p&gt;如果线程已经dead，interrupt操作没丝毫作用，也不会出错。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isInterrupted&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;查看是否被设为interrupted.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setPriority&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;改变线程的优先级。首先会由securityManager进行校验，校验失败抛SecurityException. 校验成功，则取设置的值和当前threadGroup的最大权限中的较小值，作为线程的优先级。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getPriority&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程优先级.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setName, getName&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设置线程名字，获取线程名字&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getThreadGroup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程的threadGroup&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;activeCount&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得当前线程的threadGroup以及subGroup中的线程数.由于线程在动态变化，因此只是一个估计值，主要是用于debug以及monitoring.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;join(time)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;等待线程结束，如果join(0)代表一直等待。如果该线程被其他thread interrupt，那么这个线程的interrupted标志位被清除，然后抛出&lt;code class=&quot;highlighter-rouge&quot;&gt;InterruptedException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dumpStack&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;打印当前线程的栈，只用于&lt;strong&gt;debug&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setDaemon(isDaemon)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设为守护线程或者用户线程。JVM会在所有用户线程都挂掉之后退出。&lt;/p&gt;

&lt;p&gt;必须在线程启动之前设置，如果线程已经是alive，会抛&lt;code class=&quot;highlighter-rouge&quot;&gt;IllegalThreadStateException&lt;/code&gt;.同样也会检查SecurityManager当前线程是否有权限去设置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isDaemon&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否是守护线程&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;checkAccess&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;检查当前线程有没有权限去修改这个线程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getContextClassLoader, setContextClassLoader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;classLoader是用于加载classes和resources。默认的classLoader是父线程的classLoader。原始的线程classLoader通常是设置为应用的classLoader。如果classLoader不为空， 且securityManager不为空，将会进行权限校验。&lt;strong&gt;权限校验几乎伴随thread的每个操作&lt;/strong&gt;，后面就不再提了.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;holdsLock(Object obj)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线程是否持有某个monitor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getStackTrace, getAllStackTraces&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个是打印当前线程的stack，一个是所有线程的stack，用户debug&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getId&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程Id&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getState&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程状态&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UncaughtExceptionHandler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是一个接口，用于当线程由于一些未捕获的异常而导致终止时的处理。&lt;/p&gt;

&lt;p&gt;里面只有一个方法.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;uncaughtException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;get(set)DefaultUncaughtExceptionHandler, get(set)UncaughtExceptionHandler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于设置UncaughtExceptionHandler。ThreadGroup是UncaughtExceptionHandler的一个实现类，如果当前thread没有设置UncaughtExceptionHandler，那么返回threadGroup。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>[转载] Raft译文</title>
   <link href="http://turbofei.github.io/bigdata/2019/05/19/%E8%BD%AC%E8%BD%BD-Raft%E8%AF%91%E6%96%87"/>
   <updated>2019-05-19T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/bigdata/2019/05/19/[转载]-Raft译文</id>
   <content type="html">
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#寻找一种易于理解的一致性算法扩展版&quot; id=&quot;markdown-toc-寻找一种易于理解的一致性算法扩展版&quot;&gt;寻找一种易于理解的一致性算法（扩展版）&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#摘要&quot; id=&quot;markdown-toc-摘要&quot;&gt;摘要&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#1-介绍&quot; id=&quot;markdown-toc-1-介绍&quot;&gt;1 介绍&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#2-复制状态机&quot; id=&quot;markdown-toc-2-复制状态机&quot;&gt;2 复制状态机&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#3-paxos算法的问题&quot; id=&quot;markdown-toc-3-paxos算法的问题&quot;&gt;3 Paxos算法的问题&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#4-为了可理解性的设计&quot; id=&quot;markdown-toc-4-为了可理解性的设计&quot;&gt;4 为了可理解性的设计&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#5-raft-一致性算法&quot; id=&quot;markdown-toc-5-raft-一致性算法&quot;&gt;5 Raft 一致性算法&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#51-raft-基础&quot; id=&quot;markdown-toc-51-raft-基础&quot;&gt;5.1 Raft 基础&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#52-领导人选举&quot; id=&quot;markdown-toc-52-领导人选举&quot;&gt;5.2 领导人选举&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#53-日志复制&quot; id=&quot;markdown-toc-53-日志复制&quot;&gt;5.3 日志复制&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#54-安全性&quot; id=&quot;markdown-toc-54-安全性&quot;&gt;5.4 安全性&lt;/a&gt;            &lt;ul&gt;
              &lt;li&gt;&lt;a href=&quot;#541-选举限制&quot; id=&quot;markdown-toc-541-选举限制&quot;&gt;5.4.1 选举限制&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#542-提交之前任期内的日志条目&quot; id=&quot;markdown-toc-542-提交之前任期内的日志条目&quot;&gt;5.4.2 提交之前任期内的日志条目&lt;/a&gt;&lt;/li&gt;
              &lt;li&gt;&lt;a href=&quot;#543-安全性论证&quot; id=&quot;markdown-toc-543-安全性论证&quot;&gt;5.4.3 安全性论证&lt;/a&gt;&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#55-跟随者和候选人崩溃&quot; id=&quot;markdown-toc-55-跟随者和候选人崩溃&quot;&gt;5.5 跟随者和候选人崩溃&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#56-时间和可用性&quot; id=&quot;markdown-toc-56-时间和可用性&quot;&gt;5.6 时间和可用性&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#6-集群成员变化&quot; id=&quot;markdown-toc-6-集群成员变化&quot;&gt;6 集群成员变化&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#7-日志压缩&quot; id=&quot;markdown-toc-7-日志压缩&quot;&gt;7 日志压缩&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#8-客户端交互&quot; id=&quot;markdown-toc-8-客户端交互&quot;&gt;8 客户端交互&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#9-算法实现和评估&quot; id=&quot;markdown-toc-9-算法实现和评估&quot;&gt;9 算法实现和评估&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#91-可理解性&quot; id=&quot;markdown-toc-91-可理解性&quot;&gt;9.1 可理解性&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#92-正确性&quot; id=&quot;markdown-toc-92-正确性&quot;&gt;9.2 正确性&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#93-性能&quot; id=&quot;markdown-toc-93-性能&quot;&gt;9.3 性能&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#10-相关工作&quot; id=&quot;markdown-toc-10-相关工作&quot;&gt;10 相关工作&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#11-结论&quot; id=&quot;markdown-toc-11-结论&quot;&gt;11 结论&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#12-感谢&quot; id=&quot;markdown-toc-12-感谢&quot;&gt;12 感谢&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;Raft的译文&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/maemual/raft-zh_cn/edit/master/raft-zh_cn.md&quot;&gt;原文地址&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;寻找一种易于理解的一致性算法扩展版&quot;&gt;寻找一种易于理解的一致性算法（扩展版）&lt;/h1&gt;

&lt;h2 id=&quot;摘要&quot;&gt;摘要&lt;/h2&gt;

&lt;p&gt;Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。从一个用户研究的结果可以证明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。&lt;/p&gt;

&lt;h2 id=&quot;1-介绍&quot;&gt;1 介绍&lt;/h2&gt;

&lt;p&gt;一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos  算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。&lt;/p&gt;

&lt;p&gt;但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。这些都导致了工业界和学术界都对 Paxos 算法感到十分头疼。&lt;/p&gt;

&lt;p&gt;和 Paxos 算法进行过努力之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。我们的做法是不寻常的，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且能够比 Paxos 算法以一种更加容易的方式来学习。此外，我们希望该算法方便系统构建者的直觉的发展。不仅一个算法能够工作很重要，而且能够显而易见的知道为什么能工作也很重要。&lt;/p&gt;

&lt;p&gt;Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。&lt;/p&gt;

&lt;p&gt;Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;强领导者&lt;/strong&gt;：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导者发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;领导选举&lt;/strong&gt;：Raft 算法使用一个随机计时器来选举领导者。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;成员关系调整&lt;/strong&gt;：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全性已经被证明；它的效率和其他算法比起来也不相上下。&lt;/p&gt;

&lt;p&gt;接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了理解能力而使用的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。&lt;/p&gt;

&lt;h2 id=&quot;2-复制状态机&quot;&gt;2 复制状态机&lt;/h2&gt;

&lt;p&gt;一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导者，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE1.png&quot; alt=&quot;图 1 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。&lt;/p&gt;

&lt;p&gt;保证复制日志相同就是一致性算法的工作了。在一台服务器上，一致性模块接收客户端发送来的指令然后增加到自己的日志中去。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，尽管有些服务器会宕机。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成一个高可靠的状态机。&lt;/p&gt;

&lt;p&gt;实际系统中使用的一致性算法通常含有以下特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、冗余和乱序等错误都可以保证正确。&lt;/li&gt;
  &lt;li&gt;可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。他们当有稳定的存储的时候可以从状态中恢复回来并重新加入集群。&lt;/li&gt;
  &lt;li&gt;不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟在可能只有在最坏情况下才会导致可用性问题。&lt;/li&gt;
  &lt;li&gt;通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-paxos算法的问题&quot;&gt;3 Paxos算法的问题&lt;/h2&gt;

&lt;p&gt;在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。&lt;/p&gt;

&lt;p&gt;不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。&lt;/p&gt;

&lt;p&gt;我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。&lt;/p&gt;

&lt;p&gt;Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。&lt;/p&gt;

&lt;p&gt;而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立的选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。&lt;/p&gt;

&lt;p&gt;因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft算法就是这次实验的结果。&lt;/p&gt;

&lt;h2 id=&quot;4-为了可理解性的设计&quot;&gt;4 为了可理解性的设计&lt;/h2&gt;

&lt;p&gt;设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。&lt;/p&gt;

&lt;p&gt;在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？&lt;/p&gt;

&lt;p&gt;我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：只要有可能，我们就将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和角色改变几个部分。&lt;/p&gt;

&lt;p&gt;我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图去消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化去简化 Raft 中领导人选举算法。&lt;/p&gt;

&lt;h2 id=&quot;5-raft-一致性算法&quot;&gt;5 Raft 一致性算法&lt;/h2&gt;

&lt;p&gt;Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。&lt;/p&gt;

&lt;p&gt;Raft 通过选举一个高贵的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目，把日志条目复制到其他服务器上，并且当保证安全性的时候告诉其他的服务器应用日志条目到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可以宕机，可以和其他服务器失去连接，这时一个新的领导人会被选举出来。&lt;/p&gt;

&lt;p&gt;通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;领导选举&lt;/strong&gt;：一个新的领导人需要被选举出来，当现存的领导人宕机的时候（章节 5.2）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;日志复制&lt;/strong&gt;：领导人必须从客户端接收日志然后复制到集群中的其他节点，并且强制要求其他节点的日志保持和自己相同。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;安全性&lt;/strong&gt;：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到一个额外的选举机制（5.2 节）上的限制。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在展示一致性算法之后，这一章节会讨论可用性的一些问题和系统中的候选人角色的问题。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;状态&lt;/strong&gt;：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;状态&lt;/th&gt;
      &lt;th&gt;所有服务器上持久存在的&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;currentTerm&lt;/td&gt;
      &lt;td&gt;服务器最后一次知道的任期号（初始化为 0，持续递增）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;votedFor&lt;/td&gt;
      &lt;td&gt;在当前获得选票的候选人的 Id&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;log[]&lt;/td&gt;
      &lt;td&gt;日志条目集；每一个条目包含一个用户状态机执行的指令，和收到时的任期号&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;状态&lt;/th&gt;
      &lt;th&gt;所有服务器上经常变的&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;commitIndex&lt;/td&gt;
      &lt;td&gt;已知的最大的已经被提交的日志条目的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastApplied&lt;/td&gt;
      &lt;td&gt;最后被应用到状态机的日志条目索引值（初始化为 0，持续递增）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;状态&lt;/th&gt;
      &lt;th&gt;在领导人里经常改变的 （选举后重新初始化）&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;nextIndex[]&lt;/td&gt;
      &lt;td&gt;对于每一个服务器，需要发送给他的下一个日志条目的索引值（初始化为领导人最后索引值加一）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;matchIndex[]&lt;/td&gt;
      &lt;td&gt;对于每一个服务器，已经复制给他的日志的最高索引值&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;附加日志 RPC&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;由领导人负责调用来复制日志指令；也会用作heartbeat&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;领导人的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;leaderId&lt;/td&gt;
      &lt;td&gt;领导人的 Id，以便于跟随者重定向请求&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;prevLogIndex&lt;/td&gt;
      &lt;td&gt;新的日志条目紧随之前的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;prevLogTerm&lt;/td&gt;
      &lt;td&gt;prevLogIndex 条目的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;entries[]&lt;/td&gt;
      &lt;td&gt;准备存储的日志条目（表示心跳时为空；一次性发送多个是为了提高效率）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;leaderCommit&lt;/td&gt;
      &lt;td&gt;领导人已经提交的日志的索引值&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;返回值&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;当前的任期号，用于领导人去更新自己&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;success&lt;/td&gt;
      &lt;td&gt;跟随者包含了匹配上 prevLogIndex 和 prevLogTerm 的日志时为真&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;接收者实现：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果 &lt;code class=&quot;highlighter-rouge&quot;&gt;term &amp;lt; currentTerm&lt;/code&gt; 就返回 false （5.1 节）&lt;/li&gt;
  &lt;li&gt;如果日志在 prevLogIndex 位置处的日志条目的任期号和 prevLogTerm 不匹配，则返回 false （5.3 节）&lt;/li&gt;
  &lt;li&gt;如果已经存在的日志条目和新的产生冲突（索引值相同但是任期号不同），删除这一条和之后所有的 （5.3 节）&lt;/li&gt;
  &lt;li&gt;附加任何在已有的日志中不存在的条目&lt;/li&gt;
  &lt;li&gt;如果 &lt;code class=&quot;highlighter-rouge&quot;&gt;leaderCommit &amp;gt; commitIndex&lt;/code&gt;，令 commitIndex 等于 leaderCommit 和 新日志条目索引值中较小的一个&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;请求投票 RPC&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;由候选人负责调用用来征集选票（5.2 节）&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;候选人的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;candidateId&lt;/td&gt;
      &lt;td&gt;请求选票的候选人的 Id&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastLogIndex&lt;/td&gt;
      &lt;td&gt;候选人的最后日志条目的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastLogTerm&lt;/td&gt;
      &lt;td&gt;候选人最后日志条目的任期号&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;返回值&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;当前任期号，以便于候选人去更新自己的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;voteGranted&lt;/td&gt;
      &lt;td&gt;候选人赢得了此张选票时为真&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;接收者实现：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果&lt;code class=&quot;highlighter-rouge&quot;&gt;term &amp;lt; currentTerm&lt;/code&gt;返回 false （5.2 节）&lt;/li&gt;
  &lt;li&gt;如果 votedFor 为空或者就是 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;所有服务器需遵守的规则&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;所有服务器：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果&lt;code class=&quot;highlighter-rouge&quot;&gt;commitIndex &amp;gt; lastApplied&lt;/code&gt;，那么就 lastApplied 加一，并把&lt;code class=&quot;highlighter-rouge&quot;&gt;log[lastApplied]&lt;/code&gt;应用到状态机中（5.3 节）&lt;/li&gt;
  &lt;li&gt;如果接收到的 RPC 请求或响应中，任期号&lt;code class=&quot;highlighter-rouge&quot;&gt;T &amp;gt; currentTerm&lt;/code&gt;，那么就令 currentTerm 等于 T，并切换状态为跟随者（5.1 节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;跟随者（5.2 节）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;响应来自候选人和领导者的请求&lt;/li&gt;
  &lt;li&gt;如果在超过选举超时时间的情况之前都没有收到领导人的心跳，或者是候选人请求投票的，就自己变成候选人&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;候选人（5.2 节）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在转变成候选人后就立即开始选举过程
    &lt;ul&gt;
      &lt;li&gt;自增当前的任期号（currentTerm）&lt;/li&gt;
      &lt;li&gt;给自己投票&lt;/li&gt;
      &lt;li&gt;重置选举超时计时器&lt;/li&gt;
      &lt;li&gt;发送请求投票的 RPC 给其他所有服务器&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果接收到大多数服务器的选票，那么就变成领导人&lt;/li&gt;
  &lt;li&gt;如果接收到来自新的领导人的附加日志 RPC，转变成跟随者&lt;/li&gt;
  &lt;li&gt;如果选举过程超时，再次发起一轮选举&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;领导人：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一旦成为领导人：发送空的附加日志 RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以阻止跟随者超时（5.2 节）&lt;/li&gt;
  &lt;li&gt;如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）&lt;/li&gt;
  &lt;li&gt;如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex，那么：发送从 nextIndex 开始的所有日志条目：
    &lt;ul&gt;
      &lt;li&gt;如果成功：更新相应跟随者的 nextIndex 和 matchIndex&lt;/li&gt;
      &lt;li&gt;如果因为日志不一致而失败，减少 nextIndex 重试&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;如果存在一个满足&lt;code class=&quot;highlighter-rouge&quot;&gt;N &amp;gt; commitIndex&lt;/code&gt;的 N，并且大多数的&lt;code class=&quot;highlighter-rouge&quot;&gt;matchIndex[i] ≥ N&lt;/code&gt;成立，并且&lt;code class=&quot;highlighter-rouge&quot;&gt;log[N].term == currentTerm&lt;/code&gt;成立，那么令 commitIndex 等于这个 N （5.3 和 5.4 节）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE2.png&quot; alt=&quot;图 2 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;特性&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;选举安全特性&lt;/td&gt;
      &lt;td&gt;对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;领导人只附加原则&lt;/td&gt;
      &lt;td&gt;领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;日志匹配原则&lt;/td&gt;
      &lt;td&gt;如果两个日志在相同的索引位置的日志条目的任期号相同，那么我们就认为这个日志从头到这个索引位置之间全部完全相同（5.3 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;领导人完全特性&lt;/td&gt;
      &lt;td&gt;如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;状态机安全特性&lt;/td&gt;
      &lt;td&gt;如果一个领导人已经在给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会提交一个不同的日志（5.4.3 节）&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE3.png&quot; alt=&quot;图 3 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 3：Raft 在任何时候都保证以上的各个特性。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;51-raft-基础&quot;&gt;5.1 Raft 基础&lt;/h3&gt;

&lt;p&gt;一个 Raft 集群包含若干个服务器节点；通常是 5 个，这允许整个系统容忍 2 个节点的失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导者或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE4.png&quot; alt=&quot;图 4 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导者。在一个任期内，领导人一直都会是领导人直到自己宕机了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE5.png&quot; alt=&quot;图 5 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 5：时间被划分成一个个的任期，每个任期开始都是一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Raft 把时间分割成任意长度的&lt;strong&gt;任期&lt;/strong&gt;，如图 5。任期用连续的整数标记。每一段任期从一次&lt;strong&gt;选举&lt;/strong&gt;开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导者。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导者。&lt;/p&gt;

&lt;p&gt;不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，这会允许服务器节点查明一些过期的信息比如陈旧的领导者。每一个节点存储一个当前任期号，这一编号在整个时期内单调的增长。当服务器之间通信的时候会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的编号到较大的编号值。如果一个候选人或者领导者发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。&lt;/p&gt;

&lt;p&gt;Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节  5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。&lt;/p&gt;

&lt;h3 id=&quot;52-领导人选举&quot;&gt;5.2 领导人选举&lt;/h3&gt;

&lt;p&gt;Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选者处接收到有效的 RPCs。领导者周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加日志项 RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是&lt;strong&gt;选举超时&lt;/strong&gt;，那么他就会认为系统中没有可用的领导者,并且发起选举以选出新的领导者。&lt;/p&gt;

&lt;p&gt;要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行的向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导者，(c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。&lt;/p&gt;

&lt;p&gt;当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。&lt;/p&gt;

&lt;p&gt;在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。&lt;/p&gt;

&lt;p&gt;第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。&lt;/p&gt;

&lt;p&gt;Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。&lt;/p&gt;

&lt;p&gt;领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。&lt;/p&gt;

&lt;h3 id=&quot;53-日志复制&quot;&gt;5.3 日志复制&lt;/h3&gt;

&lt;p&gt;一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行的发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全的复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE6.png&quot; alt=&quot;图 6 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全的被应用到状态机中去的时候，就认为是可以提交了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。&lt;/p&gt;

&lt;p&gt;领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为&lt;strong&gt;已提交&lt;/strong&gt;。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。&lt;/p&gt;

&lt;p&gt;我们设计了 Raft 的日志机制来维护一个不同服务器的日志之间的高层次的一致性。这么做不仅简化了系统的行为也使得更加可预计，同时他也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些同时也组成了图 3 中的日志匹配特性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。&lt;/li&gt;
  &lt;li&gt;如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查保护了日志匹配特性当日志扩展的时候。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。&lt;/p&gt;

&lt;p&gt;在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同的方式。跟随者可能会丢失一些在新的领导人中有的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE7.png&quot; alt=&quot;图 7 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在 Raft 算法中，领导人处理不一致是通过强制跟随者直接复制自己的日志来解决了。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。&lt;/p&gt;

&lt;p&gt;要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除从那个点之后的所有日志条目，发送自己的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 &lt;strong&gt;nextIndex&lt;/strong&gt;，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的index加1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。&lt;/p&gt;

&lt;p&gt;如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以包含冲突的条目的任期号和自己存储的那个任期的最早的索引地址。借助这些信息，领导人可以减小 nextIndex 越过所有那个任期冲突的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。&lt;/p&gt;

&lt;p&gt;通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能自动的在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。&lt;/p&gt;

&lt;p&gt;日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。&lt;/p&gt;

&lt;h3 id=&quot;54-安全性&quot;&gt;5.4 安全性&lt;/h3&gt;

&lt;p&gt;前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。&lt;/p&gt;

&lt;p&gt;这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于领导人完整特性的简要证明，并且说明领导人是如何领导复制状态机的做出正确行为的。&lt;/p&gt;

&lt;h4 id=&quot;541-选举限制&quot;&gt;5.4.1 选举限制&lt;/h4&gt;

&lt;p&gt;在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导者。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证所有之前的任期号中已经提交的日志条目在选举的时候都会出现在新的领导人中，不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。&lt;/p&gt;

&lt;p&gt;Raft 使用投票的方式来阻止一个候选人赢得选举除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票 RPC 实现了这样的限制： RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。&lt;/p&gt;

&lt;p&gt;Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。&lt;/p&gt;

&lt;h4 id=&quot;542-提交之前任期内的日志条目&quot;&gt;5.4.2 提交之前任期内的日志条目&lt;/h4&gt;

&lt;p&gt;如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE8.png&quot; alt=&quot;图 8 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导者，部分的复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。&lt;/p&gt;

&lt;p&gt;当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。&lt;/p&gt;

&lt;h4 id=&quot;543-安全性论证&quot;&gt;5.4.3 安全性论证&lt;/h4&gt;

&lt;p&gt;在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE9.png&quot; alt=&quot;图 9 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 9：如果 S1 （任期 T 的领导者）提交了一条新的日志在它的任期里，然后 S5 在之后的任期 U 里被选举为领导人，然后至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。&lt;/li&gt;
  &lt;li&gt;领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人T 的日志条目，并且给领导人U 投票了，如图 9。这个投票者是产生这个矛盾的关键。&lt;/li&gt;
  &lt;li&gt;这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。&lt;/li&gt;
  &lt;li&gt;投票者在给领导人 U 投票时依然保有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有和领导人冲突的时候才会删除条目。&lt;/li&gt;
  &lt;li&gt;投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。&lt;/li&gt;
  &lt;li&gt;首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。&lt;/li&gt;
  &lt;li&gt;除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交当然日志，这里产生矛盾。&lt;/li&gt;
  &lt;li&gt;这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。&lt;/li&gt;
  &lt;li&gt;日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (d) 中的索引 2。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果已经服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。&lt;/p&gt;

&lt;p&gt;最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。&lt;/p&gt;

&lt;h3 id=&quot;55-跟随者和候选人崩溃&quot;&gt;5.5 跟随者和候选人崩溃&lt;/h3&gt;

&lt;p&gt;到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单的通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。&lt;/p&gt;

&lt;h3 id=&quot;56-时间和可用性&quot;&gt;5.6 时间和可用性&lt;/h3&gt;

&lt;p&gt;Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。&lt;/p&gt;

&lt;p&gt;领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;广播时间（broadcastTime）  «  选举超时时间（electionTimeout） «  平均故障间隔时间（MTBF）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。&lt;/p&gt;

&lt;p&gt;广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。&lt;/p&gt;

&lt;h2 id=&quot;6-集群成员变化&quot;&gt;6 集群成员变化&lt;/h2&gt;

&lt;p&gt;到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。&lt;/p&gt;

&lt;p&gt;为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人同时被选举成功在同一个任期里。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性自动的转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE10.png&quot; alt=&quot;图 10 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;日志条目被复制给集群中新、老配置的所有服务器。&lt;/li&gt;
  &lt;li&gt;新、旧配置的服务器都可以成为领导人。&lt;/li&gt;
  &lt;li&gt;达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程人依然响应客户端的请求。&lt;/p&gt;

&lt;p&gt;集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用  C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。&lt;/p&gt;

&lt;p&gt;一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，在没有经过他人批准的情况下都不可能做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE11.png&quot; alt=&quot;图 11 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目，实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和  C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在  C-new 和 C-old 可以同时做出决定的时间点。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新的时候使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。&lt;/p&gt;

&lt;p&gt;第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。&lt;/p&gt;

&lt;p&gt;第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。&lt;/p&gt;

&lt;p&gt;为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。特别的，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。&lt;/p&gt;

&lt;h2 id=&quot;7-日志压缩&quot;&gt;7 日志压缩&lt;/h2&gt;

&lt;p&gt;Raft 的日志在正常操作中不断的增长，但是在实际的系统中，日志不能无限制的增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。&lt;/p&gt;

&lt;p&gt;快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。&lt;/p&gt;

&lt;p&gt;增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE12.png&quot; alt=&quot;图 12 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;图 12 展示了 Raft 中快照的基础思想。每个服务器独立的创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：&lt;strong&gt;最后被包含索引&lt;/strong&gt;指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），&lt;strong&gt;最后被包含的任期&lt;/strong&gt;指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要最后的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。&lt;/p&gt;

&lt;p&gt;尽管通常服务器都是独立的创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;安装快照 RPC&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;在领导人发送快照给跟随者时使用到。领导人总是按顺序发送。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;领导人的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;leaderId&lt;/td&gt;
      &lt;td&gt;领导人的 Id，以便于跟随者重定向请求&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastIncludedIndex&lt;/td&gt;
      &lt;td&gt;快照中包含的最后日志条目的索引值&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;lastIncludedTerm&lt;/td&gt;
      &lt;td&gt;快照中包含的最后日志条目的任期号&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;offset&lt;/td&gt;
      &lt;td&gt;分块在快照中的偏移量&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;data[]&lt;/td&gt;
      &lt;td&gt;原始数据&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;done&lt;/td&gt;
      &lt;td&gt;如果这是最后一个分块则为 true&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;结果&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;term&lt;/td&gt;
      &lt;td&gt;当前任期号，便于领导人更新自己&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;接收者实现&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果&lt;code class=&quot;highlighter-rouge&quot;&gt;term &amp;lt; currentTerm&lt;/code&gt;就立即回复&lt;/li&gt;
  &lt;li&gt;如果是第一个分块（offset 为 0）就创建一个新的快照&lt;/li&gt;
  &lt;li&gt;在指定偏移量写入数据&lt;/li&gt;
  &lt;li&gt;如果 done 是 false，则继续等待更多的数据&lt;/li&gt;
  &lt;li&gt;保存快照文件，丢弃索引值小于快照的日志&lt;/li&gt;
  &lt;li&gt;如果现存的日志拥有相同的最后任期号和索引值，则后面的数据继续保持&lt;/li&gt;
  &lt;li&gt;丢弃整个日志&lt;/li&gt;
  &lt;li&gt;使用快照重置状态机&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE13.png&quot; alt=&quot;图 13 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者直接丢弃他所有的日志；这些会被快照所取代，但是可能会和没有提交的日志产生冲突。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照之后的条目必须正确和保留。&lt;/p&gt;

&lt;p&gt;这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。&lt;/p&gt;

&lt;p&gt;我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。&lt;/p&gt;

&lt;p&gt;还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。&lt;/p&gt;

&lt;p&gt;第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。&lt;/p&gt;

&lt;h2 id=&quot;8-客户端交互&quot;&gt;8 客户端交互&lt;/h2&gt;

&lt;p&gt;这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。&lt;/p&gt;

&lt;p&gt;Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。&lt;/p&gt;

&lt;p&gt;我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可以执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。&lt;/p&gt;

&lt;p&gt;只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为领导人响应客户端请求时可能已经被新的领导人作废了，但是他还不知道。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道那些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。&lt;/p&gt;

&lt;h2 id=&quot;9-算法实现和评估&quot;&gt;9 算法实现和评估&lt;/h2&gt;

&lt;p&gt;我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。&lt;/p&gt;

&lt;p&gt;这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。&lt;/p&gt;

&lt;h3 id=&quot;91-可理解性&quot;&gt;9.1 可理解性&lt;/h3&gt;

&lt;p&gt;为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者独立的区别从第一个算法处学来的经验。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。&lt;/p&gt;

&lt;p&gt;我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些  Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;关心&lt;/th&gt;
      &lt;th&gt;缓和偏见采取的手段&lt;/th&gt;
      &lt;th&gt;可供查看的材料&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;相同的讲课质量&lt;/td&gt;
      &lt;td&gt;两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。&lt;/td&gt;
      &lt;td&gt;视频&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;相同的测验难度&lt;/td&gt;
      &lt;td&gt;问题以难度分组，在两个测验里成对出现。&lt;/td&gt;
      &lt;td&gt;小测验&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;公平评分&lt;/td&gt;
      &lt;td&gt;使用红字标题。随机顺序打分，两个测验交替进行。&lt;/td&gt;
      &lt;td&gt;红字标题&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。一对 t -测试表明，拥有 95% 的可信度，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE14.png&quot; alt=&quot;图 14 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型显示，对小测验的选择会产生 12.5 分的差别在对  Raft 的好感度上。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于   Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进性 Paxos 小测验的人而言，Raft 的小测验得分会比 Paxos 低 6.3 分；我们不知道为什么，但这在统计学上是这样的。&lt;/p&gt;

&lt;p&gt;我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE15.png&quot; alt=&quot;图 15 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;关于 Raft 用户学习有一个更加详细的讨论。&lt;/p&gt;

&lt;h3 id=&quot;92-正确性&quot;&gt;9.2 正确性&lt;/h3&gt;

&lt;p&gt;在第 5 节，我们已经进行了一个正式的说明，和对一致性机制的安全性证明。这个正式说明让图 2 中的信息非常清晰通过 TLA+ 说明语言。大约 400 行说明充当了证明的主题。同时对于任何想实现的人也是十分有用的。我们非常机械的证明了日志完全特性通过 TLA 证明系统。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明这个说明中的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性质是完备的，并且是相当清晰的（大约 3500 个词）。&lt;/p&gt;

&lt;h3 id=&quot;93-性能&quot;&gt;9.3 性能&lt;/h3&gt;

&lt;p&gt;Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。&lt;/p&gt;

&lt;p&gt;我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/raft/raft-%E5%9B%BE16.png&quot; alt=&quot;图 16 &quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。&lt;/p&gt;

&lt;p&gt;图 16 上面的图表表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。&lt;/p&gt;

&lt;p&gt;图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。&lt;/p&gt;

&lt;h2 id=&quot;10-相关工作&quot;&gt;10 相关工作&lt;/h2&gt;

&lt;p&gt;已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。&lt;/li&gt;
  &lt;li&gt;关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。&lt;/li&gt;
  &lt;li&gt;实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。&lt;/li&gt;
  &lt;li&gt;Paxos 可以应用的性能优化。&lt;/li&gt;
  &lt;li&gt;Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。&lt;/p&gt;

&lt;p&gt;像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。&lt;/p&gt;

&lt;p&gt;和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 中不同的消息类型，相对的，Raft 只有 4 中消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。&lt;/p&gt;

&lt;p&gt;Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。&lt;/p&gt;

&lt;p&gt;一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。&lt;/p&gt;

&lt;h2 id=&quot;11-结论&quot;&gt;11 结论&lt;/h2&gt;

&lt;p&gt;算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。&lt;/p&gt;

&lt;p&gt;在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；这个过程是我们发现我们最终很少有技术上的重复，例如问题分解和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。&lt;/p&gt;

&lt;h2 id=&quot;12-感谢&quot;&gt;12 感谢&lt;/h2&gt;

&lt;p&gt;这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;p&gt;略&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>My Contribution To Apache Spark</title>
   <link href="http://turbofei.github.io/spark/2019/05/18/my-contribution-to-apache-spark"/>
   <updated>2019-05-18T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2019/05/18/my-contribution-to-apache-spark</id>
   <content type="html">
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-27637&quot; id=&quot;markdown-toc-spark-27637&quot;&gt;SPARK-27637&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#description&quot; id=&quot;markdown-toc-description&quot;&gt;Description&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#solution&quot; id=&quot;markdown-toc-solution&quot;&gt;Solution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#link&quot; id=&quot;markdown-toc-link&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-27562in-progress&quot; id=&quot;markdown-toc-spark-27562in-progress&quot;&gt;SPARK-27562(In Progress)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#description-1&quot; id=&quot;markdown-toc-description-1&quot;&gt;Description&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#solution-1&quot; id=&quot;markdown-toc-solution-1&quot;&gt;Solution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#link-1&quot; id=&quot;markdown-toc-link-1&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-27716in-progress&quot; id=&quot;markdown-toc-spark-27716in-progress&quot;&gt;SPARK-27716(In Progress)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#description-2&quot; id=&quot;markdown-toc-description-2&quot;&gt;Description&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#solution-2&quot; id=&quot;markdown-toc-solution-2&quot;&gt;Solution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#link-2&quot; id=&quot;markdown-toc-link-2&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#to-be-continued&quot; id=&quot;markdown-toc-to-be-continued&quot;&gt;To Be Continued~&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;简单记录一下对spark的PR。Slowly, but always forward~&lt;/p&gt;

&lt;h3 id=&quot;spark-27637&quot;&gt;SPARK-27637&lt;/h3&gt;

&lt;h4 id=&quot;description&quot;&gt;Description&lt;/h4&gt;

&lt;p&gt;在spark中有两种shuffle client，自带的blockTransferService和externalShuffleClient。&lt;/p&gt;

&lt;p&gt;如果spark.shuffle.service.enabled=true,那么spark使用external shuffle client进行拉取shuffle block data，使用 nettyBlockTransferService进行拉取broadcast block data。&lt;/p&gt;

&lt;p&gt;如果spark.shuffle.service.enabled=false，那么shuffle block data 和broadcast block data 都由nettyBlockTransterService进行拉取。&lt;/p&gt;

&lt;p&gt;ExternalShuffleService(ESS)是一个shuffle服务，它可以忽视executor是否存活，保管executor的shuffle数据，就算executor是dead，也可以去ESS去取数据，因此在开启ESS情况下，是可以回收executor的，因此，如果要使用动态分配executor，必须开启ESS。&lt;/p&gt;

&lt;p&gt;而如果不使用ESS，那么就需要spark的executor自己去管理shuffle 数据，因此取shuffle数据就是通过直接连接BlockManager的ip:port进行。&lt;/p&gt;

&lt;p&gt;Broadcast数据是首先executor会访问其他executor去取，如果无法取到，则去向driver进行请求，由于这些broadcast数据必定是由executor管理，而不能委托给ESS，因此必须需要使用nettyBlockTransferService,无论ESS是否开启。&lt;/p&gt;

&lt;p&gt;在spark.shuffle.service.enabled=true且spark.executor.dynamicAllocation.enabled=true 时，由于executor可以被动态回收；如果在取broadcast数据的时候成功连接对应的executor，但是在开始取数据时候，executor被回收掉，那么必然造成取数据的失败。&lt;/p&gt;

&lt;p&gt;Spark中有一个RetryingBlockFetcher，如果在连接失败之后，会抛出java.io.IOException，之后会进行校验是否shouldRetry。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shouldRetry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isIOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCause&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCause&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasRemainingRetries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retryCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxRetries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isIOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasRemainingRetries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出这里只是判断是否是IOException并且还有剩余的重试此处，如果满足，就进行重试，之后也是必然的失败。如果这里设置的最大重试为10次，超时为30s，那么这里将会浪费掉五分钟的时间。因此，这里的校验是不合理的。&lt;/p&gt;

&lt;h4 id=&quot;solution&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;解决方案很简单，简单描述一下：&lt;/p&gt;

&lt;p&gt;在超时之后，如果是IOException，则向driverEndPoint发送rpc请求，判断这个executor是否存活。如果executor已经dead，则抛出ExecutorDeadException, 这就会造成 shouldRetry为false(因为isIOException == false). 核心代码如下: 具体参考PR.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;         &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OneForOneBlockFetcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listener&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;transportConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tempFileManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;driverEndPointRef&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;askSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IsExecutorAlive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutorDeadException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The relative remote executor(Id: $execId), &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;&quot;which maintains the block data to fetch is dead.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Ps: 感谢社区大佬对我代码的review，非常佩服他们的代码功力，受益匪浅.&lt;/p&gt;

&lt;h4 id=&quot;link&quot;&gt;Link&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27637&quot;&gt;ISSUE SPARK-27637&lt;/a&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24533&quot;&gt;PR SPARK-27637&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-27562in-progress&quot;&gt;SPARK-27562(In Progress)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;这个PR应该是改动太多了，不太好review，所以没有committer进行review，但是个人认为这个PR非常有意义。特别是针对之后的RemoteShuffleService(一个用于计算存储分离架构的ExternalShuffleService).&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;description-1&quot;&gt;Description&lt;/h4&gt;

&lt;p&gt;参考&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4105&quot;&gt;ISSUE SPARK-4105&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;shuffle是spark应用中一个重要的操作。 shuffle是map端的数据进行重新分区，然后reduce端去拉取每个map端对应的分区数据。因此在shuffle过程中，数据会进行网络传输。而网络传输面临着数据传输出错的风险，spark本身有一种校验shuffle传输数据的机制。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;SPARK-26089 对应PR&lt;/a&gt;合入之前的校验机制&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个机制是当shuffle数据有压缩编码，比如snappy，lz4时，判断shuffle数据的大小，如果数据大小小于一个阈值，比如16m，则对这个数据进行校验，校验方法为将数据输入流，拷贝到输出流再转为输入流，如果在流拷贝中没有出错，则表示数据没有损坏。&lt;/p&gt;

&lt;p&gt;但是这个校验机制存在一定的限制：&lt;/p&gt;

&lt;p&gt;1、 非压缩的数据无法校验（非压缩数据也存在传输出错风险）&lt;/p&gt;

&lt;p&gt;2、shuffle数据超过阈值则无法校验&lt;/p&gt;

&lt;p&gt;3、流拷贝消耗内存&lt;/p&gt;

&lt;p&gt;因此，目前的校验机制存在shuffle数据传输出错，导致shuffle read 端task由于数据出错造成任务出错的风险。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;SPARK-26089 对应PR&lt;/a&gt;合入之后的校验机制&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个PR对shuffle校验机制进行了一些优化：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;针对大的shuffle block会校验开头的部分数据，如果没出错，则通过校验，进入执行阶段&lt;/li&gt;
  &lt;li&gt;不再采用流拷贝操作，不会浪费内存。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是也存在一些问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果大的shuffle block中间的数据出错，依然会造成task出错，而无法重新fetch&lt;/li&gt;
  &lt;li&gt;依然不会对未使用codec的数据进行校验。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;solution-1&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;首先，我们选取crc作为我们的校验方式，crc同时也是hadoop使用的通信校验方式，它简单且快速。这也是我们对比了其他校验方式，例如md5， sha系列算法之后的结果。&lt;/p&gt;

&lt;p&gt;在shuffle write阶段，我们在获得 mapTask对应的partitionedFile之后，根据索引，计算出每个分区的crc值，然后跟随各个分区的长度索引，一起写入到shuffle.index文件中。关于shuffle的机制可以参考&lt;a href=&quot;/spark/2016/12/26/spark源码分析Shuffle实现&quot;&gt;我之前的文章，shuffle源码分析&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;spark 的shuffle writer分为三种，bypassShuffleWriter， SortShuffleWriter以及UnsafeShuffleWriter。其中bypassShuffleWriter是在reducer的数量小于阈值(默认200)时候使用，他的特点是每个mapTask创建reducerNum个shuffle文件，所以需要在reducer个数小时使用，否则会造成很多小文件。&lt;/p&gt;

&lt;p&gt;而SortShuffleWriter和UnsafeShuffleWriter都是只创建一个PartitionedFile。所以在根据每个partition长度进行计算crc值时是很快的。&lt;/p&gt;

&lt;p&gt;之后我们将计算好的crc值与partition index一起写入shuffle 索引文件。&lt;/p&gt;

&lt;p&gt;在之后fetchBlock时，我们将每个partition的crc值随数据一起发送， 然后在shuffle read端，对拉取到的数据进行重新计算crc值，与原来的crc进行比对，如果相同，则数据不存在问题。&lt;/p&gt;

&lt;p&gt;在shuffle read端，数据一般都是在内存中，计算crc是很快的，在计算完之后，对这个内存中的inputStream进行reset操作，就可以重新进行后面的执行操作，如果数据是落在磁盘中，则代表数据较大，  crc的计算效率是经过实战考验的，我们也做了相应测试，由于文件创建的inputStream不支持reset操作，我们在计算完crc值之后，重新根据文件创建inputStream.&lt;/p&gt;

&lt;p&gt;这一套方案可以校验所有的数据，不论他是否进行压缩，是否太大， 都可以很好的计算，并且经过我们的是，性能没有下降。&lt;/p&gt;

&lt;p&gt;具体还有其他细节:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原来的indexFile是写partitionNum+1 个long值，长度为8的倍数，crc值也是long值，我们加入一个1位的标志位，来区别是否进行了crc计算。&lt;/li&gt;
  &lt;li&gt;在写crc时的一致性保证。&lt;/li&gt;
  &lt;li&gt;在shuffle read端在发现crc值与原来的crc不同时的处理等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;link-1&quot;&gt;Link&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27562&quot;&gt;ISSUE SPARK-27562&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/24447&quot;&gt;PR SPARK-27562&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-27716in-progress&quot;&gt;SPARK-27716(In Progress)&lt;/h3&gt;

&lt;h4 id=&quot;description-2&quot;&gt;Description&lt;/h4&gt;

&lt;p&gt;使用jdbc 的DataSource，我们可以将一个RDD保存到database中。比如mysql，greenplum。&lt;/p&gt;

&lt;p&gt;这些操作的主要逻辑由&lt;code class=&quot;highlighter-rouge&quot;&gt;JdbcUtils&lt;/code&gt;中的&lt;code class=&quot;highlighter-rouge&quot;&gt;saveTable&lt;/code&gt;函数完成,该函数的注释如下.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  /**
   * Saves the RDD to the database in a single transaction.
   */
  def saveTable(
      df: DataFrame,
      tableSchema: Option[StructType],
      isCaseSensitive: Boolean,
      options: JdbcOptionsInWrite)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;事实上这个注释的描述是错的，注释中说saveTable操作是在单个事务中完成。&lt;/p&gt;

&lt;p&gt;其实saveTable是调用savePartition操作来将每个分区的数据保存在数据库中，而savePartition的操作是在单个事务完成，而针对整体的saveTable却并不是单个事务。&lt;/p&gt;

&lt;p&gt;可能会存在某个分区出错，但是saveTable却处于一个中间状态的情况，这不符合事务的要求。&lt;/p&gt;

&lt;p&gt;在使用jdbc的数据传输操作可以分为以下几种。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;case1: append数据到一个已经存在的表中。&lt;/li&gt;
  &lt;li&gt;case2：overwrite一张表，但是这个表是级联表，如果将这个表drop会牵连到其他的表，因此只能将这个表清空，再append数据。&lt;/li&gt;
  &lt;li&gt;case3：overwrite一张表，该表存在且不是级联表，因此可以先drop表。&lt;/li&gt;
  &lt;li&gt;case4：要保存的表不存在。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这个PR中，我对case3和case4进行了事务支持。&lt;/p&gt;

&lt;h4 id=&quot;solution-2&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;针对case3和case4，我们可以先将数据保存到一个临时表中。&lt;/p&gt;

&lt;p&gt;我们使用一个累加器来记录成功savePartition的分区数。累加器是spark中的一个分布式的计数器。&lt;/p&gt;

&lt;p&gt;来每个分区都执行savePartition之后，我们拿累加器的值和分区的数目做比较，如果所有分区都成功的savePartition，那么我们可以在driver上面drop destination table if exists,然后对临时表做rename操作，将其rename到最终的表。&lt;/p&gt;

&lt;p&gt;由于drop table 和rename table 都是原子操作，所以我们可以保证case3和case4是在单事务进行。&lt;/p&gt;

&lt;p&gt;如果有分区savePartition失败，那么我们将在driver端抛出一个分区失败的异常，提醒user。&lt;/p&gt;

&lt;p&gt;在finally模块，我们将会进行删除临时表的操作，最大重试次数为三次，确保不会产生一些垃圾数据。&lt;/p&gt;

&lt;h4 id=&quot;link-2&quot;&gt;Link&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/24610&quot;&gt;PR SPARK-27716&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27716&quot;&gt;ISSUE SPARK-27716&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;to-be-continued&quot;&gt;To Be Continued~&lt;/h3&gt;
</content>
 </entry>
 
 <entry>
   <title>Scala Concurrent Programing: Promise And Forkjoinpool</title>
   <link href="http://turbofei.github.io/coding/2019/05/18/scala-concurrent-programing-Promise-And-ForkJoinPool"/>
   <updated>2019-05-18T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/coding/2019/05/18/scala-concurrent-programing:-Promise-And-ForkJoinPool</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#promise&quot; id=&quot;markdown-toc-promise&quot;&gt;Promise&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#nonfatal--controlthrowable&quot; id=&quot;markdown-toc-nonfatal--controlthrowable&quot;&gt;Nonfatal &amp;amp; ControlThrowable&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#try&quot; id=&quot;markdown-toc-try&quot;&gt;Try&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#forkjoinpool&quot; id=&quot;markdown-toc-forkjoinpool&quot;&gt;ForkJoinPool&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#work-steamling机制&quot; id=&quot;markdown-toc-work-steamling机制&quot;&gt;work-steamling机制&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;关于并发编程的一些总结与思考，包括promise, forkJoinPool, and etc.
在使用scala进行并发编程时，常用的一个就是Promise，Promise和Future是相关的。在生产中，Promise往往和Thread结合一起用，在一个线程中去执行Promise.trySuccess.提到线程就不得不提线程池，而ForkJoinPool是一个特殊的线程池，它比较适合计算密集型的场景。&lt;/p&gt;

&lt;h3 id=&quot;promise&quot;&gt;Promise&lt;/h3&gt;

&lt;p&gt;Promise是scala中独有的，java中没有。中文意思就是承诺，它可以在获得承诺的value时成功结束，也可以在遇到异常时失败。
一个Promise只能承诺一次，如果它已经完成承诺，或者失败，或者超时，再对它进行调用就会抛出IllegalStateException。在promize中有很多方法,如下&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tryFailureWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryFailure&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;isCompleted&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这些方法有所不同，例如complete系列(包括tryComplete， tryCompleteWith)是可以返回值，也可以是异常的。&lt;/p&gt;

&lt;p&gt;而failure系列只能是异常，而success系列智能是返回value。因此，complete系列更像是一个对后两者的并集。&lt;/p&gt;

&lt;p&gt;在使用中，我们可以按照自己的需求去选择这些方法。&lt;/p&gt;

&lt;p&gt;比如我们可以直接使用complete系列将所有系列包容，也可以使用trySuccess 然后在捕获异常之后，将异常直接给failure方法。&lt;/p&gt;

&lt;p&gt;isComplete是用于判断Promise是否已经完成，而future是一个包含Promise结果的Future。&lt;/p&gt;

&lt;p&gt;我们通常将Promise和Await一起用。如果Promise在执行中出现了异常，Await是可以将其抛出，而如果Promise没有在规定时间内返回，那么将会抛出TimeoutException.&lt;/p&gt;

&lt;p&gt;例子如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.duration.Duration&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.Try&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.control.NonFatal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestPromise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/**
     * 此处是为了校验超时异常
     * 以及执行中异常.
     */&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Thread.sleep(13000)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// throw new Exception(&quot;this is an exception&quot;)
&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NonFatal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//            promisedLong.tryFailure(e)
&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;12s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;nonfatal--controlthrowable&quot;&gt;Nonfatal &amp;amp; ControlThrowable&lt;/h4&gt;

&lt;p&gt;上面的例子中提到了Nonfatal，这在生产中是一个常用的类。&lt;/p&gt;

&lt;p&gt;顾名思义，Nonfatal代表非致命的，方法体也很短.&lt;/p&gt;

&lt;p&gt;可以看出致命的错误有，虚拟机Error，ThreadDeath，中断异常，链接Error，以及&lt;code class=&quot;highlighter-rouge&quot;&gt;ControlThrowable&lt;/code&gt;。除了这几种，其他都是非致命的。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NonFatal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;cm&quot;&gt;/**
    * Returns true if the provided `Throwable` is to be considered non-fatal, or false if it is to be considered fatal
    */&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;// VirtualMachineError includes OutOfMemoryError and other fatal errors
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;VirtualMachineError&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ThreadDeath&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LinkageError&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ControlThrowable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Returns Some(t) if NonFatal(t) == true, otherwise None
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unapply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;一般在程序中，都是对Nonfatal进行catch处理， 而致命的就不catch了。&lt;/p&gt;

&lt;p&gt;那么什么是&lt;code class=&quot;highlighter-rouge&quot;&gt;ControlThrowable&lt;/code&gt;呢？&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ControlThrowable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NoStackTrace&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到它继承了NoStackTrace类，也就是说这个异常栈是不能打印的。ControlThrowable代表这个Throwable是被放在控制流中。因为这个异常时作为控制流异常（比如BreadControl等等）， 因此发生这种异常，需要propagate，而不能catch，不过这一切都被封装在了Nonfatal，我们在编程中只要判断Nonfatal就可以。&lt;/p&gt;

&lt;h4 id=&quot;try&quot;&gt;Try&lt;/h4&gt;

&lt;p&gt;关于Try，它和try catch中的try不同，它代表执行一个程序块，通常和match，以及Success， Failure一起使用。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testTry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//      throw new Exception(&quot;this is an exception&quot;)
&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getMessage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;forkjoinpool&quot;&gt;ForkJoinPool&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;其实看源码中注释是理解源码最好的方式。&lt;/strong&gt;
ForkJoinPool是一个用于运行ForkJoinTask的线程池. ForkJoinPool和其他的ExecutorService不同，他有一套work-窃取机制，每个线程都可以尝试去find和执行pool中或者其他task提交的任务，这样就可以更加高效，因为每个线程的执行都不是限制死的，如果它空闲了就可以去窃取其他forkJointask的任务，这样也减少了线程的上下文切换，所以对于计算密集型的任务效率会很高，所以，如果你的任务是计算密集型，不妨试一下ForkJoinPool。相当于大家同心协力去把pool中的所有task运行完，这样避免了因为倾斜带来的低效。&lt;/p&gt;

&lt;p&gt;asyncMode默认是false，当设为true，这更适合于事件类型的任务，从来不会有join。&lt;/p&gt;

&lt;p&gt;下面是一个计算从1到n和的一个程序，采用了普通线程池和ForkJoinPool来实现，实验证明，forkjoinpool性能领先很大。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestForkJoinPool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sumWithExecutorService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cost Time is:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ms!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executeWithForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ForkJoinPoll Cost Time is:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ms!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sumWithExecutorService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ExecutorService&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Executors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newFixedThreadPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;cm&quot;&gt;/**
             * 这里，如果前面不进行强制类型转换，那么除了之后就是一个int
             * 就没有必要取ceil 了，切记。
             */&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))));&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignore&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executeWithForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;invoke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecursiveTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

        &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;work-steamling机制&quot;&gt;work-steamling机制&lt;/h4&gt;

&lt;p&gt;ForkJoinPool中的fork和join是unix中创建线程的方法，在Unix中使用fork可以创建一个子进程，然后join是让父进程等待子进程执行完毕才进行。但是在ForkJoinPool中并不是每次fork都要创建一个子线程，我们可以设置poolSize，规定线程数目的上限。&lt;/p&gt;

&lt;p&gt;ForkJoinPool中的每个线程会维护一个工作队列.这个队列是双端队列，在每次执行自己队列的任务时会尝试随机窃取一个task，窃取对应队列的顺序是FIFO，而执行自己队列中的任务在同步模式下是LIFO。可以看到fork函数是将task放置在队列的尾部。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;externalPush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而join操作呢?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;判断该任务是否已经完成，如果完成返回，否则2&lt;/li&gt;
  &lt;li&gt;这个任务是自己的工作队列中，如果在，则执行，等待其完成。&lt;/li&gt;
  &lt;li&gt;如果不在自己的工作队列中，则已经被小偷窃取。&lt;/li&gt;
  &lt;li&gt;找到小偷，窃取他队列中的任务，FIFO方式窃取，帮助他早日完成任务。&lt;/li&gt;
  &lt;li&gt;如果小偷已经做完自己的任务，自己在等待被其他小偷窃取走的任务时，帮助他。&lt;/li&gt;
  &lt;li&gt;递归5，直到返回结果。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;WorkQueue&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Thread.currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tryUnpush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;wt.pool.awaitJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;externalAwaitDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/**
     * Blocks a non-worker-thread until completion.
     * @return status upon completion
     */&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;externalAwaitDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CountedCompleter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// try helping
&lt;/span&gt;                 &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;externalHelpComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                     &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CountedCompleter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;?&amp;gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
                 &lt;span class=&quot;kt&quot;&gt;ForkJoinPool.common.tryExternalUnpush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;doExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compareAndSwapInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;STATUS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SIGNAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ie&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;notifyAll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interrupt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Transactions Suuport For Spark Greenlum</title>
   <link href="http://turbofei.github.io/spark/2019/05/12/transactions-suuport-for-spark-greenlum"/>
   <updated>2019-05-12T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2019/05/12/transactions-suuport-for-spark-greenlum</id>
   <content type="html">
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;spark-greenplum是一个spark DataSource为greenplum的实现。通过使用postgresql copy命令的方式从dataframe分区向greenplum拷贝数据，相较于spark sql本身jbdc DataSource的速度提升了上百倍。本文讲解关于实现从spark sql向gp拷贝数据事务的实现。&lt;/p&gt;

&lt;p&gt;相关PR为:&lt;a href=&quot;https://github.com/yaooqinn/spark-greenplum/7&quot;&gt;SPARK-GREENPLUM-4&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-greenplum&quot;&gt;Spark-greenplum&lt;/h3&gt;

&lt;p&gt;Spark-greenplum的项目地址为:https://github.com/yaooqinn/spark-greenplum.&lt;/p&gt;

&lt;p&gt;spark本身有jdbc的DataSource支持，可以进行spark sql 到greenplum的传输，但是速度慢。
查看JdbcUtils中的savePartition方法，其中的拷贝模块为:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numFields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isNullAt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nullTypes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;setters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addBatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batchSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executeBatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里看到，他是针对迭代器进行遍历，达到batchSize（默认为1000）之后进行一次insert操作，因此针对大批量的拷贝操作，速度较慢。&lt;/p&gt;

&lt;p&gt;在postgresql中，有一个copy命令，可以参考文档：https://www.postgresql.org/docs/9.2/sql-copy.html.&lt;/p&gt;

&lt;p&gt;下面的命令为将一个文件中的数据拷贝到一个表中.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;column_name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'filename'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;STDIN&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;option&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这是一个原子操作，这个copy的速度相较于jdbc DataSource中的按批插入，性能提升极大。&lt;/p&gt;

&lt;p&gt;通过将每个dataFrame中partition的数据写入一个文件，然后使用copy from命令将这个文件中的数据拷贝到greenplum表中，针对每个分区中的copy操作分别是原子操作，但是如何针对所有分区实现事务呢？事务对于生产环境中是非常必要的。&lt;/p&gt;

&lt;p&gt;在讲解事务实现之前，先讲下在针对文件中一些特殊字符的处理.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Backslash characters (\) can be used in the COPY data to quote data characters that might otherwise be taken as row or column delimiters. In particular, the following characters must be preceded by a backslash if they appear as part of a column value: backslash itself, newline, carriage return, and the current delimiter character.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;从sparksql 写数据到文件的过程是将每个Row写到文件中的一行，而且各个column之间使用指定的delimiter间隔。因此，在写文件时需要对于一些特殊字符进行处理，比如换行符合回车符，这些肯定是需要特殊处理的，因此不处理，就会导致一个row写了多行，之后copy命令就无法正确识别，其次就是 row中如果有column的值包含和delimiter相同的字符也要进行转义，不然copy命令就无法通过delimiter识别出列的值，除此之外还有’\‘需要特殊处理，因为对delimiter的处理是在demiter前加’\‘因此，也要针对’\‘进行处理避免与delimiter的处理方式混淆。&lt;/p&gt;

&lt;h3 id=&quot;事务实现&quot;&gt;事务实现&lt;/h3&gt;

&lt;p&gt;前面提到针对每个partition的copy命令都是原子操作，但是针对整体的partition如何实现原子操作呢？&lt;/p&gt;

&lt;p&gt;从spark sql向greenplum插入数据分为以下几种情况:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;gp表存在，是overwrite操作，但是这个表是一个级联删除表，因此我们不能使用drop再create的操作，只能truncate再进行append。&lt;/li&gt;
  &lt;li&gt;gp表存在，向表中append数据。&lt;/li&gt;
  &lt;li&gt;gp表存在，是overwrite操作，是非级联表，因此可以对该表进行drop再create的操作。&lt;/li&gt;
  &lt;li&gt;gp表不存在，可以直接进行create操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面四种情况，可以分为两种:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;可以drop if exists，再导入数据&lt;/li&gt;
  &lt;li&gt;必须append数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;case1&quot;&gt;case1&lt;/h4&gt;

&lt;p&gt;针对第一种情况，实现事务很简单，方案如下:&lt;/p&gt;

&lt;p&gt;首先创建一个临时表，然后针对每个分区，使用copy命令，将各个分区的数据拷贝到这个临时表中。最后，如果所有分区都成功拷贝。&lt;/p&gt;

&lt;p&gt;那么在driver中进行以下两步操作:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;drop $table if exists&lt;/li&gt;
  &lt;li&gt;alter table $tempTable rename to $table&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果这两步都成功，那么则完成了事务。&lt;/p&gt;

&lt;p&gt;如果有分区未成功拷贝，或者在以上两步中失败，则进行删除临时表的操作。并且抛出异常，提醒用户，事务未成功。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何判断分区成功数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如何判断分区是否全部成功呢？我们使用 &lt;strong&gt;LongAccmulator&lt;/strong&gt;来实现，在driver中注册一个累加器，然后每个分区成功时则累加器加一，如果最终累加器的值，等于dataFrame的分区数，那么代表全部成功，否则是部分失败。&lt;/p&gt;

&lt;p&gt;关于LongAccmulator，想了解的可以去搜索了解，相当于一个分布式的atomicLong.&lt;/p&gt;

&lt;h4 id=&quot;case2&quot;&gt;case2&lt;/h4&gt;

&lt;p&gt;针对第二种情况，我们添加一个transactionOn 的option。如果为true，那么我们将dataFrame进行coalesce(1)的操作，这样dataFrame就只有一个分区，针对这个分区中copy操作就是原子性的，这样就保证了事务。&lt;/p&gt;

&lt;p&gt;关于coalesce操作，它与reparation操作不同。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def coalesce(numPartitions: Int, shuffle: Boolean = false,
               partitionCoalescer: Option[PartitionCoalescer] = Option.empty)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;对于coalesce操作，从m个分区编程n个分区，如果m&amp;lt;n是一定要进行shuffle的，如果m&amp;gt;n, 则如果非指定shuffle为true，则不需要进行shuffle。&lt;/p&gt;

&lt;p&gt;因此coalesce(1)操作，不会造成shuffle压力，而且rdd操作是迭代读取，之后进行落盘(参考&lt;a href=&quot;https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1&quot;&gt;rdd-basic&lt;/a&gt;）。只是每个partition分区的数据都发向一个节点，数据拷贝需要进行串行，然后就是可能造成磁盘压力，如果存储不够的话就很尴尬。&lt;/p&gt;

&lt;p&gt;如果transactionOn为false，则不保障事务。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Spark External Shuffle Service</title>
   <link href="http://turbofei.github.io/spark/2018/12/10/spark-external-shuffle-service"/>
   <updated>2018-12-10T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2018/12/10/spark-external-shuffle-service</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#what-is-external-shuffle-service&quot; id=&quot;markdown-toc-what-is-external-shuffle-service&quot;&gt;What is external shuffle service?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#why-need-external-shuffle-service&quot; id=&quot;markdown-toc-why-need-external-shuffle-service&quot;&gt;Why need external shuffle service?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-it-works&quot; id=&quot;markdown-toc-how-it-works&quot;&gt;How it works？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reference&quot; id=&quot;markdown-toc-reference&quot;&gt;Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;External shuffle service(ESS)是独立运行一个外部shuffle服务，用于管理spark的shuffle数据，本文讲解为什么要使用ESS，以及需要注意的地方.此处特指yarnShuffleService.&lt;/p&gt;

&lt;h2 id=&quot;what-is-external-shuffle-service&quot;&gt;What is external shuffle service?&lt;/h2&gt;

&lt;p&gt;首先，什么是外部shuffle服务。&lt;/p&gt;

&lt;p&gt;在工作之前，我没有使用过spark on yarn，都是在standalone模式下跑实验。所以之前没有注意到External shuffle service。&lt;/p&gt;

&lt;p&gt;那首先聊一下shuffle service。 shuffle分为两部分，shuffle write和shuffle read，在write端，对每个task的数据，按照key值进行hash，得到新的partitionId，然后将这些数据写到一个partitionFile里面，在paritionFile里面的数据是partitionId有序的，外加会生成一个索引，索引每个partitionFile对应偏移量和长度。&lt;/p&gt;

&lt;p&gt;而shuffle read 端就是从这些partitionFile里面拉取相应partitionId的数据，注意是拉取所有partitionFile的相应部分。&lt;/p&gt;

&lt;p&gt;External shuffle Service就是管理这些shuffle write端生成的shuffle数据，ESS是和yarn一起使用的， 在yarn集群上的每一个nodemanager上面都运行一个ESS，是一个常驻进程。一个ESS管理每个nodemanager上的executor生成的shuffle数据。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;cm&quot;&gt;/** Registers a new Executor with all the configuration we need to find its shuffle files. */&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;registerExecutor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;ExecutorShuffleInfo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executorInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在注册executor时，使用appId, execId和ExecutorShuffleInfo(localDirs, shuffleManager类型).所以说ESS维护的是一个索引，这些shuffle数据会在application运行结束之后，清除这些localDirs来删除。&lt;/p&gt;

&lt;p&gt;针对每个App， 都会有一个LoadingCache来保存Shuffle 的IndexFile，默认是100m, 由&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.service.index.cache.size&lt;/code&gt;控制。因此这个参数不能设置太大， 如果太大，在nodemanager上有多个应用运行，势必造成ESS的压力。&lt;/p&gt;

&lt;h2 id=&quot;why-need-external-shuffle-service&quot;&gt;Why need external shuffle service?&lt;/h2&gt;

&lt;p&gt;Spark系统在运行含shuffle过程的应用时，Executor进程除了运行task，还要负责写shuffle 数据，给其他Executor提供shuffle数据。当Executor进程任务过重，导致GC而不能为其他Executor提供shuffle数据时，会影响任务运行。同时，ESS的存在也使得，即使executor挂掉或者回收，都不影响其shuffle数据，因此只有在ESS开启情况下才能开启动态调整executor数目。&lt;/p&gt;

&lt;p&gt;因此，spark提供了external shuffle service这个接口，常见的就是spark on yarn中的，YarnShuffleService。这样，在yarn的nodemanager中会常驻一个externalShuffleService服务进程来为所有的executor服务，默认为7337端口。&lt;/p&gt;

&lt;p&gt;其实在spark中shuffleClient有两种，一种是blockTransferService，另一种是externalShuffleClient。如果在ESS开启，那么externalShuffleClient用来fetch  shuffle数据，而blockTransferService用于获取broadCast等其他BlockManager保存的数据。&lt;/p&gt;

&lt;p&gt;如果ESS没有开启，那么spark就只能使用自己的blockTransferService来拉取所有数据，包括shuffle数据以及broadcast数据。&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How it works？&lt;/h2&gt;

&lt;p&gt;与外部shuffle service对应的参数有以下几个。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.service.enabled&lt;/code&gt;&lt;/th&gt;
      &lt;th&gt;false&lt;/th&gt;
      &lt;th&gt;Enables the external shuffle service. This service preserves the shuffle files written by executors so the executors can be safely removed. This must be enabled if &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.dynamicAllocation.enabled&lt;/code&gt; is “true”. The external shuffle service must be set up in order to enable it. See&lt;a href=&quot;http://spark.apache.org/docs/latest/job-scheduling.html#configuration-and-setup&quot;&gt;dynamic allocation configuration and setup documentation&lt;/a&gt; for more information.&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.service.port&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;7337&lt;/td&gt;
      &lt;td&gt;Port on which the external shuffle service will run.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.registration.timeout&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;5000&lt;/td&gt;
      &lt;td&gt;Timeout in milliseconds for registration to the external shuffle service.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.registration.maxAttempts&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;When we fail to register to the external shuffle service, we will retry for maxAttempts times.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;第一个参数是打开外部服务，这里看到描述里面写当打开动态分配时，必须设置为true，是为了让外部shuffle service管理shuffle output files，方便释放闲置的executor。&lt;/p&gt;

&lt;p&gt;第二个参数是设置shuffle 服务的端口。&lt;/p&gt;

&lt;p&gt;后面两个参数，就是注册超时时长与重试次数，在 shuffle需要传输大量数据时，shuffle service比较繁忙，回复这些注册信息的时延较高，因此可能会发生注册失败错误，此时要将这两个参数调大。&lt;/p&gt;

&lt;p&gt;在spark on yarn中，会设置以下参数。&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;property&amp;gt;

&amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;

&amp;lt;value&amp;gt;spark_shuffle&amp;lt;/value&amp;gt;

&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;

&amp;lt;name&amp;gt;yarn.nodemanager.aux-services.spark_shuffle.class&amp;lt;/name&amp;gt;

&amp;lt;value&amp;gt;org.apache.spark.network.yarn.YarnShuffleService&amp;lt;/value&amp;gt;

&amp;lt;/property&amp;gt;

&amp;lt;property&amp;gt;

&amp;lt;name&amp;gt;spark.shuffle.service.port&amp;lt;/name&amp;gt;

&amp;lt;value&amp;gt;7337&amp;lt;/value&amp;gt;

&amp;lt;/property&amp;gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://spark.apache.org/docs/latest/configuration.html&quot;&gt;Spark Configuration&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-ExternalShuffleService.html&quot;&gt;External Shuffle Service&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Spark Cbo Code Analysis</title>
   <link href="http://turbofei.github.io/spark/2018/12/04/spark-cbo-code-analysis"/>
   <updated>2018-12-04T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2018/12/04/spark-cbo-code-analysis</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-cbo-源码分析&quot; id=&quot;markdown-toc-spark-cbo-源码分析&quot;&gt;Spark CBO 源码分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#统计信息类&quot; id=&quot;markdown-toc-统计信息类&quot;&gt;统计信息类&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#statistics的计算&quot; id=&quot;markdown-toc-statistics的计算&quot;&gt;Statistics的计算&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#拿到数据之后怎么用&quot; id=&quot;markdown-toc-拿到数据之后怎么用&quot;&gt;拿到数据之后怎么用&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#costbasedjoinreorder&quot; id=&quot;markdown-toc-costbasedjoinreorder&quot;&gt;CostBasedJoinReorder&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#joinselection&quot; id=&quot;markdown-toc-joinselection&quot;&gt;JoinSelection&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;对Spark的CBO(cost based optimization) 进行源码分析&lt;/p&gt;

&lt;h2 id=&quot;spark-cbo-源码分析&quot;&gt;Spark CBO 源码分析&lt;/h2&gt;

&lt;p&gt;CBO是基于Cost来优化plan。&lt;/p&gt;

&lt;p&gt;要计算cost就需要统计一些参与计算的表的相关信息，因此spark添加了&lt;code class=&quot;highlighter-rouge&quot;&gt;Statistics和ColumnStat&lt;/code&gt;类来统计相关信息。&lt;/p&gt;

&lt;p&gt;CBO主要是针对join来计算cost,目前spark-2.3 版本中与CBO相关的参数如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;默认值&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enables CBO for estimation of plan statistics when set true.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enables join reorder in CBO.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Applies star-join filter heuristics to cost based join enumeration.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;The maximum number of joined nodes allowed in the dynamic programming algorithm.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.starSchemaDetection&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;When true, it enables join reordering based on star schema detection.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;下文按照逻辑顺序分析spark cbo 源码。&lt;/p&gt;

&lt;h2 id=&quot;统计信息类&quot;&gt;统计信息类&lt;/h2&gt;

&lt;p&gt;CBO相关的统计信息类有两个，一个是ColumnStat,代表的是表中列的详细，例如最大值，最小值，空值个数，平均长度，最大长度。另外一个类是Statistics，这个类是对应一个LogicalPlan的统计信息，例如join，aggregate，logicalRelation。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Scala&quot;&gt;case class Statistics(
    sizeInBytes: BigInt,
    rowCount: Option[BigInt] = None,
    attributeStats: AttributeMap[ColumnStat] = AttributeMap(Nil),
    hints: HintInfo = HintInfo()) 

case class ColumnStat(
    distinctCount: BigInt,
    min: Option[Any],
    max: Option[Any],
    nullCount: BigInt,
    avgLen: Long,
    maxLen: Long,
    histogram: Option[Histogram] = None) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如上所示，可以看到ColumnStat表示列的详细信息。&lt;/p&gt;

&lt;p&gt;而Statistics，中的sizeInBytes和rowCount就代表这个logicalPlan输出数据的大小和行数，而attributeStats 代表这个logicalPlan涉及到的列的统计信息（一个expressID到列信息的映射），和hints。&lt;/p&gt;

&lt;p&gt;对于join来说，它的Statistics里的信息就代表join操作输出的大小，行数以及attributeStats。&lt;/p&gt;

&lt;p&gt;对于logicalRelation，它的Statistics代表其对应表中schema相关数据的大小，行数，attributeStats。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CatalogStatistics&lt;/code&gt;这个类表示存储在外部catalog(例如hive metastore）中的表的信息.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CatalogStatistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;colStats&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;ColumnStat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这些表的信息需要使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;analyze table&lt;/code&gt;命令来计算，然后存储到catalog里。&lt;/p&gt;

&lt;p&gt;每种LogicalPlan计算Statistics的方法是不同的。&lt;/p&gt;

&lt;p&gt;对于LogicalRelation来说，它是读取对应表中schema，使用CatalogStatistics类的toPlanStats可以生成Statistics。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;toPlanStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Attribute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isDefined&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AttributeMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Estimate size as number of rows * row size.
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EstimationUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOutputSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attributeStats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// When CBO is disabled or the table doesn't have other statistics, we apply the size-only
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// estimation strategy and only propagate sizeInBytes in statistics.
&lt;/span&gt;    &lt;span class=&quot;nc&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;下面将介绍其他LogicalPlan的Statistics计算。&lt;/p&gt;

&lt;h2 id=&quot;statistics的计算&quot;&gt;Statistics的计算&lt;/h2&gt;

&lt;p&gt;看LogicalPlanStats类，可以看出，这里，判断cbo是否开启，如果cbo打开，则采用BasicStatsPlanVisitor类来计算相关的Statistics，如果没有cbo，则使用SizeInBytesOnlyStatsPlanVisitor来计算。&lt;/p&gt;

&lt;p&gt;从类的名字就可以看出来，只有cbo开启，才会计算rowCount以及attributeStats信息，如果没有cbo,SizeInBytesOnlyStatsPlanVisitor只会计算 size信息。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalPlanStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrElse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BasicStatsPlanVisitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;visit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SizeInBytesOnlyStatsPlanVisitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;visit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其实在BasicStatsPlanVisitor类中对于大部分类型的LogicalPlan都还是调用SizeInBytesOnlyStatsPlanVisitor的方法来计算。&lt;/p&gt;

&lt;p&gt;只有针对Aggregate，Join，Filter，Project有另外的计算方法。&lt;/p&gt;

&lt;p&gt;这里讲下join操作的Statistics计算过程。&lt;/p&gt;

&lt;p&gt;如果没有开启CBO，join操作首先判断是否是 leftAntiJoin或者是LeftSemiJoin，如果是，则把leftChild的sizeInBytes作为计算结果，因为对于leftAntiJoin和leftSemiJoin来说，join之后表的大小是小于leftChild的。而对于其他类型的join，把左右child的sizeInBytes相乘作为join之后的大小，并且关闭掉broadcastHint，因为这些join类型可能造成很大的output。而这种粗糙的代价估计造成的结果就是，对代价估计不准确，如果该join是可以进行broadcastjoin，也可能由于粗糙的代价估计变得不可进行。&lt;/p&gt;

&lt;p&gt;如果开启了CBO，对于join操作就不止计算sizeInBytes，还需要计算rowCount，AttributeStats。&lt;/p&gt;

&lt;p&gt;代码如下，首先是判断join类型，如果是 inner,cross,leftOuter,RightOuter,FullOuter中的一种，则使用estimateInnerOuterJoin方法。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimate&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Inner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cross&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftOuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RightOuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FullOuter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;estimateInnerOuterJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftSemi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftAnti&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;estimateLeftSemiAntiJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;logDebug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[CBO] Unsupported join type: ${join.joinType}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里只针对针对estimateInnerOuterJoin方法，用语言描述一下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果是equiJoin:&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;1、首先估算被equi条件选择的记录条数,即等于innerJoin选择的条数，命名为numInnerJoinedRows；以及这些equi涉及的key在join之后的stats。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;即在join中，存在类似 a.co1=b.co1, a.co2=b.co2 这些类似条件，现在是估计满足这些相等条件的记录条数。&lt;/p&gt;

      &lt;p&gt;使用的公式是： T(A J B) = T(A) * T(B) / max(V(A.ki), V(B.ki)).&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;2、 预估得到结果的行数。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;因为即使满足这些相等条件，也不会只输出这些满足条件的记录。&lt;/p&gt;

      &lt;p&gt;如果是leftOuterJoin，则会对左边表中所有记录都会输出，不管右边匹配是否为空。&lt;/p&gt;

      &lt;p&gt;因此，对于leftOuterJoin来说，输出的记录条数等于max(左边表条数，numInnerJoinedRows)。&lt;/p&gt;

      &lt;p&gt;同样还有rightOuterJoin,输出记录条数=max(右边表条数，numInnerJoinedRows)。&lt;/p&gt;

      &lt;p&gt;对于全连接，输出记录条数=max(左边表条数，numInnerJoinedRows)+max(右边表条数，numInnerJoinedRows)-numInnerJoinedRows。即类似于A与B的并集-A与B的交集。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;3、然后是根据前面的计算结果更新Statistics，包括attributeStats。&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;如果不是equiJoin：&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;则按照笛卡尔积来计算，输出行数为两个表行数的乘积&lt;/p&gt;

  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;拿到数据之后怎么用&quot;&gt;拿到数据之后怎么用&lt;/h2&gt;

&lt;p&gt;这些Statistics的结果，会怎么运用呢？&lt;/p&gt;

&lt;p&gt;spark sql中plan的处理过程可以参考&lt;a href=&quot;./spark-sql-catalyst.md&quot;&gt;Spark sql catalyst过程详解&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;在unresolvedLogicalPlan-&amp;gt;resolvedLogicalPlan过程中收集Statistics，然后在&lt;/p&gt;

&lt;p&gt;resolvedLogicalPlan-&amp;gt;optimizedLogicalPlan过程中，基于这些统计信息，进行costBasedJoinRecorder，即基于统计信息，对join顺序重排序，寻求最优join方案。&lt;/p&gt;

&lt;p&gt;在optimizedLogicalPlan-&amp;gt;phsicalPlan过程中，基于Statistics中的sizeInBytes信息以及hint选择合适的join策略(broadcastJoin,hashShuffledJoin,sortMergeJoin).&lt;/p&gt;

&lt;h4 id=&quot;costbasedjoinreorder&quot;&gt;CostBasedJoinReorder&lt;/h4&gt;

&lt;p&gt;这是一个使用plan的stats信息，来选择合适的join顺序的类。&lt;/p&gt;

&lt;p&gt;类&lt;code class=&quot;highlighter-rouge&quot;&gt;Optimizer&lt;/code&gt;中有两个跟join 顺序有关的rule，一个是reoderJoin，另外一个是CostBasedJoinRecorder。reorderjoin是没有cbo也会触发的rule，这个不会使用统计的信息，只是负责将filter下推，这样最底层的join至少会有一个filter。如果这些join已经每个都有一条condition，那么这些plan就不会变化，因此reorder join不涉及基于代价的优化。&lt;/p&gt;

&lt;p&gt;首先看下对cost的定义。cost是有一个基数，是rowCount，然后一个sizeInBytes。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
 * This class defines the cost model for a plan.
 * @param card Cardinality (number of rows).
 * @param size Size in bytes.
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而判断cost的方法是：&lt;/p&gt;

&lt;p&gt;A: Cost(ac,as)  B: Cost(bc,bs)&lt;/p&gt;

&lt;p&gt;如果&lt;/p&gt;

&lt;p&gt;(ac/bc)*joinReorderCardWeight +(as/bs)*(1-joinReorderCardWeight)&amp;lt;1，&lt;/p&gt;

&lt;p&gt;则认为A比B好。&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.cbo.joinReorder.card.weight&lt;/code&gt;默认为0.7。代码如下：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betterThan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;JoinPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relativeRows&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relativeSize&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;relativeRows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinReorderCardWeight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;relativeSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinReorderCardWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;costBasedJoinReorder是使用一个动态规划来进行选择合适的join顺序。&lt;/p&gt;

&lt;p&gt;下面讲一个这个动态规划算法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;假设有  a j b j c j d   a.k1=b.k1 and b.k2 = c.k2 and c.k3=d.k3&lt;/p&gt;

  &lt;p&gt;将会分为4层来进行：&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;level 0: p({A}), p({B}), p({C}), p({D})
level 1: p({A, B}), p({B, C}), p({C, D})
level 2: p({A, B, C}), p({B, C, D})
level 3: p({A, B, C, D})&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;首先就是生成第0层，第0层的founfPlans={p{a},p{b},p{c},p{d}}.&lt;/p&gt;

  &lt;p&gt;如果设层级为level，那么每层的任务就是找到（level+1)个plan进行join最优的版本。&lt;/p&gt;

  &lt;p&gt;因此 k层和level-k层的所包含的表的个数之和，就是(k+1+level-k+1)=level+2，也就是说是level+1层所需要的foundPlan。&lt;/p&gt;

  &lt;p&gt;而我们在每次生成新的join之后，就判断他的itemSet是否已经存在，如果不存在就存储；如果存在，就取出其对应的plan，对比看是不是优于之前的plan（betterThan)，保存最优的。&lt;/p&gt;

  &lt;p&gt;这样。每个level里面保存的都是相应个数个多join最优的plan，最终也得到了最优的plan。&lt;/p&gt;

  &lt;p&gt;当然，在形成plan时有很多判断，比如在level1 里面，就不能形成p({A,C})。&lt;/p&gt;

  &lt;p&gt;因为不存在condition 使得A,C可以进行join。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，在动态规划进行search的时候，有一个filter。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是一个星型join过滤器，用来确保star schema 中的tables是被plan在一起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;代表在dp进行costbasedReorder时，最多支持的表的数量。&lt;/p&gt;

&lt;p&gt;**spark.sql.cbo.starSchemaDetection  **&lt;/p&gt;

&lt;p&gt;这个参数是在reorderJoin中触发，而且只在&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.cbo.starSchemaDetection=true spark.sql.cbo.enabled=false&lt;/code&gt;时才触发，很奇怪，这个参数以cbo命名，但是却在cbo.enable=false才触发。&lt;/p&gt;

&lt;p&gt;这个是用来观察是否存在starJoin。&lt;/p&gt;

&lt;h4 id=&quot;joinselection&quot;&gt;JoinSelection&lt;/h4&gt;

&lt;p&gt;在SparkPlanner类中，有几个优化策略会对LogicalPlan进行优化。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkPlanner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;experimentalMethods&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExperimentalMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategies&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Strategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;experimentalMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extraStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;extraPlanningStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;DataSourceV2Strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;FileSourceStrategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;DataSourceStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;SpecialLimits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Aggregation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;JoinSelection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;InMemoryScans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;BasicOperators&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;里面有一个JoinSelection方法，这个方法是主要是用来判断是否可以使用broadcastjoin，然后决定是使用broadcastJoin，还是shuffledHashJoin还是sortMergeJoin。&lt;/p&gt;

&lt;p&gt;broadcastjoin可以避免shuffle，如果使用得当，可以提升程序的性能。&lt;code class=&quot;highlighter-rouge&quot;&gt;这是针对一个大表和一个极小表&lt;/code&gt;在spark中有一个参数是，&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，这个参数是一个数字，单位字节，代表如果一个表的szie小于这个数值，就可以进行broadcastjoin。但是这里只使用size作为估计是不准确的，还应该使用rowCount作为参考，因为在join中，join的结果是与两个表的条数强相关，只使用size做判断是不准确的。&lt;/p&gt;

&lt;p&gt;在spark中，有BroadCastHint，前面也提到过，如果没有开启cbo，那么如果判断join类型是非leftAntiJoin和leftSemiJoin，则会觉得join之后的大小无法估测，可能会爆炸式增长，因此会关掉BroadcastHint。&lt;/p&gt;

&lt;p&gt;对于shuffledHashJoin，&lt;code class=&quot;highlighter-rouge&quot;&gt;这是针对一个大表和一个小表（判断标准为a.stats.sizeInBytes * 3 &amp;lt;= b.stats.sizeInBytes)&lt;/code&gt;，简单描述一下过程就是两个表A和B，首先，选择一个表进行shuffle write操作，即针对每个分区，按照key的hash值进行排序，将相同hash值的key放在一起，形成一个partitionFile，然后在read端拉取write端所有相应key的数据，作为localhashMap和另外一个标的分区进行join。&lt;/p&gt;

&lt;p&gt;这里也使用stats进行判断，如果&lt;code class=&quot;highlighter-rouge&quot;&gt;plan.stats.sizeInBytes &amp;lt; conf.autoBroadcastJoinThreshold * conf.numShufflePartitions&lt;/code&gt;，则判断该表的size可以满足每个分区构建localhashMap的可能，可以看到这里也是以&lt;code class=&quot;highlighter-rouge&quot;&gt;autoBroadcastJoinThreshold&lt;/code&gt;作为衡量标准。&lt;/p&gt;

&lt;p&gt;如果是两张大表，则需要使用sortmergeJoin，类似于先排序，即按照keypair排序，然后进行归并。&lt;/p&gt;

&lt;p&gt;这些join selection的操作，不管是否开启CBO都会进行。但是和CBO相关的是，这些数据的统计是和CBO有关，前面提过，如果开启CBO则使用BasicStatsPlanVisitor来进行统计。&lt;/p&gt;

&lt;p&gt;上述的这些估测，都是基于size信息。但是即使是基于size信息，如果没有开启cbo，这些信息也是粗糙的，没有CBO那种更细致的估计，因此可能会造成Join种类选择不合适。&lt;/p&gt;

&lt;p&gt;上述的判断，很多是基于&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，因此在运行环境中，一定要结合集群环境设置合适的值。&lt;/p&gt;

&lt;p&gt;而且，在joinSelection中，也应该基于rowCount来判断join的种类。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Spark Sql Catalyst</title>
   <link href="http://turbofei.github.io/spark/2018/08/01/spark-sql-catalyst"/>
   <updated>2018-08-01T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2018/08/01/spark-sql-catalyst</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql-catalyst&quot; id=&quot;markdown-toc-spark-sql-catalyst&quot;&gt;Spark Sql Catalyst&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#treenode-and-rule&quot; id=&quot;markdown-toc-treenode-and-rule&quot;&gt;TreeNode And Rule&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#treenode&quot; id=&quot;markdown-toc-treenode&quot;&gt;TreeNode&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#rule&quot; id=&quot;markdown-toc-rule&quot;&gt;Rule&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#catalyst-in-spark-sql&quot; id=&quot;markdown-toc-catalyst-in-spark-sql&quot;&gt;Catalyst In Spark Sql&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#analysis&quot; id=&quot;markdown-toc-analysis&quot;&gt;Analysis&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#logical-optimizations&quot; id=&quot;markdown-toc-logical-optimizations&quot;&gt;Logical Optimizations&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#物理计划&quot; id=&quot;markdown-toc-物理计划&quot;&gt;物理计划&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#code-generation&quot; id=&quot;markdown-toc-code-generation&quot;&gt;Code Generation&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#添加自己的rule&quot; id=&quot;markdown-toc-添加自己的rule&quot;&gt;添加自己的Rule&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#参考文献&quot; id=&quot;markdown-toc-参考文献&quot;&gt;参考文献&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;关于spark的catalyst&lt;/p&gt;

&lt;h1 id=&quot;spark-sql-catalyst&quot;&gt;Spark Sql Catalyst&lt;/h1&gt;

&lt;p&gt;Catalyst是spark官方为spark sql设计的query优化框架， 基于函数式编程语言Scala实现。Catalyst有一个优化规则库，可以针对spark sql语句进行自动分析优化。而且Catalyst利用Scala的强大语言特性，例如模式匹配和运行时元程序设计(&lt;a href=&quot;https://docs.scala-lang.org/overviews/quasiquotes/intro.html&quot;&gt;基于scala quasiquotes&lt;/a&gt;)，使得开发者可以简单方便的定制优化规则。&lt;/p&gt;

&lt;h3 id=&quot;treenode-and-rule&quot;&gt;TreeNode And Rule&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TreeNode&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;Rule&lt;/code&gt;是Catalyst重要的两种类型。&lt;/p&gt;

&lt;h4 id=&quot;treenode&quot;&gt;TreeNode&lt;/h4&gt;

&lt;p&gt;在sql语句中，每条sql语句都会被解析为一个AST(abstract syntax tree)，而TreeNode就是spark sql抽象语法树中的节点。&lt;/p&gt;

&lt;p&gt;TreeNode是一个抽象类，子类有很多种，比如可以是Projection，Attribute, Literal(常量)，或者是一个操作(比如Sum,Add)，或者是join,hashAggregate这些，或者filter,scan等等。&lt;/p&gt;

&lt;p&gt;比如下面这条sql语句。&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;   &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;ta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; 
 &lt;span class=&quot;n&quot;&gt;tb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;90&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tmp&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;它会解析为一个AST。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Parsed Logical Plan ==
'Project [unresolvedalias('sum('v), None)]
+- 'SubqueryAlias tmp
   +- 'Project ['ta.key, ((1 + 2) + 'ta.value) AS v#12]
      +- 'Filter (('ta.key = 'tb.key) &amp;amp;&amp;amp; ('tb.value &amp;gt; 90))
         +- 'Join Inner
            :- 'UnresolvedRelation `ta`
            +- 'UnresolvedRelation `tb`
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-catalyst/sql-ast.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;rule&quot;&gt;Rule&lt;/h4&gt;

&lt;p&gt;而Rule就是运用在这个AST上面的规则。通过规则对树里面的TreeNode进行转化。&lt;/p&gt;

&lt;p&gt;观察TreeNode，里面有一个很重要的方法：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rule&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PartialFunction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BaseType&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;BaseType&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BaseType&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transformDown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;默认是对树中的TreeNode使用前序遍历方式（transformDown)进行转化，也可以使用后续遍历(transformUp)对TreeNode进行转化。&lt;/p&gt;

&lt;p&gt;查看Rule的子类，发现有很多规则, 这些规则是很多种，在AST转换的各个阶段的规则都有，比如列裁剪，谓词下推，合并filter，展开projection等等。&lt;/p&gt;

&lt;p&gt;RuleExecutor是一个用来执行rule的执行器，里面有一个batch字段，是一系列的rule，这些是作用在treeNode组成的tree之上，rule的执行策略有两种，一种是Once，只执行一次，另外一种是fixedPoint，意思是在rule一直作用在tree之上，直到tree达到一个不动点，不再改变。&lt;/p&gt;

&lt;h3 id=&quot;catalyst-in-spark-sql&quot;&gt;Catalyst In Spark Sql&lt;/h3&gt;

&lt;p&gt;spark sql是 apache spark的其中一个模块，主要用于进行结构化数据的处理。spark sql的底层执行还是调用rdd来执行。一条sql语句从String到RddChain的过程如下图所示。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/imgs/spark-catalyst/catalyst.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;SQL语句到转换为rdd总共分为以下阶段，&lt;a href=&quot;./Spark-sql-Analysis.md&quot;&gt;具体参考Spark sql 执行流程-从sql string 到 rdd&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SQL 语句经过 SqlParser(ANTLR4) 解析成 Unresolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 analyzer 结合数据数据字典 (catalog) 进行绑定, 生成 resolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;对 resolved LogicalPlan 进行优化, 生成 optimized LogicalPlan;&lt;/li&gt;
  &lt;li&gt;将 LogicalPlan 转换成 PhysicalPlan;&lt;/li&gt;
  &lt;li&gt;将 PhysicalPlan 转换成可执行物理计划;&lt;/li&gt;
  &lt;li&gt;使用 execute() 执行可执行物理计划;&lt;/li&gt;
  &lt;li&gt;生成 RDD。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;而Catalyst参与其中的四个阶段，分别是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;将Unresolved Logical Plan转化为resolved logical plan&lt;/li&gt;
  &lt;li&gt;logical plan 到optimized logical plan&lt;/li&gt;
  &lt;li&gt;optimized logical plan 到physical plan&lt;/li&gt;
  &lt;li&gt;code generation(在转换为可执行物理计划阶段)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在生成physical plan阶段，可能会使用CBO(cost based optimization，目前是用于join策略的选择),其他阶段都是RBO(rule based optimization)。&lt;/p&gt;

&lt;h4 id=&quot;analysis&quot;&gt;Analysis&lt;/h4&gt;

&lt;p&gt;Analysis阶段的输入是一个AST(抽象语法树)或者是一个DataFrame，称之为unresolved logic plan。因为这些plan中的元素属性都是未知的。比如上面举例的sql语句，是否存在ta这个表，ta这个表有没有key 和 value字段，以及这些字段的类型都是未知的。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;org.apache.spark.sql.catalyst.analysisAnalyzer&lt;/code&gt;是一个用于执行analysis的类，这个类继承RuleExecutor，其中定义了一系列的解析规则顺序执行来解析这些字段和函数等里面的属性。&lt;/p&gt;

&lt;p&gt;Spark sql使用Catalyst规则和catalog来查询这些表是否存在，并来获得查询需要的具体属性。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;向catalog查询relations&lt;/li&gt;
  &lt;li&gt;根据属性的名字做映射&lt;/li&gt;
  &lt;li&gt;对名字相同的attribute给unique id标注：例如前面sql语句的ta.key =  tb.key， 会被解析为 key#1 = key#6&lt;/li&gt;
  &lt;li&gt;对expressions的类型做解析：例如 (cast((1 + 2) as bigint) + value#1L),  sum(v#12L) AS sum(v)#28L&lt;/li&gt;
  &lt;li&gt;如果有UDF，还要解析UDF&lt;/li&gt;
  &lt;li&gt;等等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;下面就是resolved logical plan：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Analyzed Logical Plan ==
sum(v): bigint
Aggregate [sum(v#12L) AS sum(v)#28L]
+- SubqueryAlias tmp
   +- Project [key#0, (cast((1 + 2) as bigint) + value#1L) AS v#12L]
      +- Filter ((key#0 = key#6) &amp;amp;&amp;amp; (value#7L &amp;gt; cast(90 as bigint)))
         +- Join Inner
            :- SubqueryAlias ta, `ta`
            :  +- Relation[key#0,value#1L] json
            +- SubqueryAlias tb, `tb`
               +- Relation[key#6,value#7L] json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出，每个attribute都有一个Unique ID，例如 key#0, sum(v)#28L&lt;/p&gt;

&lt;h4 id=&quot;logical-optimizations&quot;&gt;Logical Optimizations&lt;/h4&gt;

&lt;p&gt;在获得resolved logical plan之后，就对这个plan进行优化。&lt;/p&gt;

&lt;p&gt;这个其实类似analyzer，&lt;code class=&quot;highlighter-rouge&quot;&gt;org.apache.spark.sql.catalyst.optimizer.Optimizer&lt;/code&gt;同样是继承RuleExecutor，然后里面包含了一系列的优化策略。然后每个策略对Tree进行transform。主要的优化策略列表如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;PushProjectionThroughUnion,
ReorderJoin,
EliminateOuterJoin,
PushPredicateThroughJoin,
PushDownPredicate,
LimitPushDown,
ColumnPruning,
InferFiltersFromConstraints,
// Operator combine
CollapseRepartition,
CollapseProject,
CollapseWindow,
CombineFilters,
CombineLimits,
CombineUnions,
// Constant folding and strength reduction
NullPropagation,
FoldablePropagation,
OptimizeIn(conf),
ConstantFolding,
ReorderAssociativeOperator,
LikeSimplification,
BooleanSimplification,
SimplifyConditionals,
RemoveDispensableExpressions,
SimplifyBinaryComparison,
PruneFilters,
EliminateSorts,
SimplifyCasts,
SimplifyCaseConversionExpressions,
RewriteCorrelatedScalarSubquery,
EliminateSerialization,
RemoveRedundantAliases,
RemoveRedundantProject
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;常见的谓词下推啊，常数合并，filter合并等等。&lt;/p&gt;

&lt;p&gt;在我们上面的那条sql语句中，用到了谓词下推和常数合并，以及添加了isNotNull判断和filter合并等。下面就是优化之后逻辑计划。&lt;/p&gt;

&lt;p&gt;我们可以看到在resolved logical plan中，filter条件在join之上，在优化之后，filter条件下推，这样可以提早过滤掉一部分数据，减小join部分的压力。&lt;/p&gt;

&lt;p&gt;还有就是之前的&lt;code class=&quot;highlighter-rouge&quot;&gt;1+2&lt;/code&gt;在这里已经转化为3，还有就是在filter里面都加了 &lt;code class=&quot;highlighter-rouge&quot;&gt;isNotNull&lt;/code&gt;判断。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Optimized Logical Plan ==
Aggregate [sum(v#12L) AS sum(v)#28L]
+- Project [(3 + value#1L) AS v#12L]
   +- Join Inner, (key#0 = key#6)
      :- Filter isnotnull(key#0)
      :  +- Relation[key#0,value#1L] json
      +- Project [key#6]
         +- Filter ((isnotnull(value#7L) &amp;amp;&amp;amp; (value#7L &amp;gt; 90)) &amp;amp;&amp;amp; isnotnull(key#6))
            +- Relation[key#6,value#7L] json
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;物理计划&quot;&gt;物理计划&lt;/h4&gt;

&lt;p&gt;在获得 optimized logical plan之后，接下来就要准备可以执行的物理计划。观察上面的优化之后的逻辑计划，只说了join，但是怎么join，是broadcastJoin 还是 SortMergeJoin。 只有Relation[key#6,value#7L] json，但是去哪里获得数据，等等。物理计划就是要完善这部分。&lt;/p&gt;

&lt;p&gt;同前面几个阶段相同，这个阶段也是一系列的策略：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def strategies: Seq[Strategy] =
    extraStrategies ++ (
    FileSourceStrategy ::
    DataSourceStrategy ::
    DDLStrategy ::
    SpecialLimits ::
    Aggregation ::
    JoinSelection ::
    InMemoryScans ::
    BasicOperators :: Nil)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出这些策略是选择输入源相关，DDL策略相关，join等等。&lt;/p&gt;

&lt;p&gt;前面部分粗略的提到过，Spark sql关于其他阶段的优化都是RBO，而join选择是基于CBO。目前CBO还在逐渐完善，可以关注&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-16026&quot;&gt;相关JIRA&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;因为join的选择必须要基于表的大小相关的信息，才能做出好的选择。关注这个JoinSelection策略。&lt;/p&gt;

&lt;p&gt;此处就选择一个方法，不再展开。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;canBroadcast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isBroadcastable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoBroadcastJoinThreshold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看到这个方法判断是否能够broadcast的规则就是通过统计的数据, statistics中的sizeInBytes大小，来判断这个表的大小是否超过broadcast参数设置的阈值，如果小于阈值，则选用broadcastJoin，这样可以避免shuffle。&lt;/p&gt;

&lt;h4 id=&quot;code-generation&quot;&gt;Code Generation&lt;/h4&gt;

&lt;p&gt;上面的物理计划阶段得到的只是一个中间阶段的物理计划，要想物理计划阶段得以运行还要进行一系列操作，这部分体现在&lt;code class=&quot;highlighter-rouge&quot;&gt;org.apache.spark.sql.execution.QueryExecution类的preparations方法中&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/** A sequence of rules that will be applied in order to the physical plan before execution. */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;preparations&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Rule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ExtractPythonUDFs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;PlanSubqueries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;EnsureRequirements&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;CollapseCodegenStages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ReuseExchange&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nc&quot;&gt;ReuseSubquery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkSession&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sessionState&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里会添加排序，分区策略，codegen。&lt;/p&gt;

&lt;p&gt;排序，分区就是类似于 spark core中的shuffle阶段。而codegen是Catalyst中的重要内容。&lt;/p&gt;

&lt;p&gt;由于spark sql是操纵内存中的datasets，cpu是一个重要的瓶颈，因此codegen就是为了生成高效的代码，来加速性能。Catalyst的codegen依赖scala的一个特性 &lt;a href=&quot;https://docs.scala-lang.org/overviews/quasiquotes/intro.html&quot;&gt;quasiquotes&lt;/a&gt;来使得codegen变得简单。&lt;/p&gt;

&lt;p&gt;codeGen是给一些可以进行codeGen的例子，制定了一套通用的模板，固定的部分是相同的，定制的部分传入一些具体的参数，然后可以运行时编程运行，如下。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
  public Object generate(Object[] references) {
    return new GeneratedIterator(references);
  }

  ${ctx.registerComment(s&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Codegend&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipeline&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;treeString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;)}
  final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {

    private Object[] references;
    private scala.collection.Iterator[] inputs;
    ${ctx.declareMutableStates()}

    public GeneratedIterator(Object[] references) {
      this.references = references;
    }

    public void init(int index, scala.collection.Iterator[] inputs) {
      partitionIndex = index;
      this.inputs = inputs;
      ${ctx.initMutableStates()}
      ${ctx.initPartition()}
    }

    ${ctx.declareAddedFunctions()}

    protected void processNext() throws java.io.IOException {
      ${code.trim}
    }
  }
  &quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trim&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;最终得到可执行的物理计划，如下所示。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Physical Plan ==
*HashAggregate(keys=[], functions=[sum(v#12L)], output=[sum(v)#28L])
+- Exchange SinglePartition
   +- *HashAggregate(keys=[], functions=[partial_sum(v#12L)], output=[sum#30L])
      +- *Project [(3 + value#1L) AS v#12L]
         +- *BroadcastHashJoin [key#0], [key#6], Inner, BuildRight
            :- *Project [key#0, value#1L]
            :  +- *Filter isnotnull(key#0)
            :     +- *FileScan json [key#0,value#1L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/Users/bbw/todo/sparkApp/data/kv.json], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct&amp;lt;key:string,value:bigint&amp;gt;
            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))
               +- *Project [key#6]
                  +- *Filter ((isnotnull(value#7L) &amp;amp;&amp;amp; (value#7L &amp;gt; 90)) &amp;amp;&amp;amp; isnotnull(key#6))
                     +- *FileScan json [key#6,value#7L] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/Users/bbw/todo/sparkApp/data/kv.json], PartitionFilters: [], PushedFilters: [IsNotNull(value), GreaterThan(value,90), IsNotNull(key)], ReadSchema: struct&amp;lt;key:string,value:bigint&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出，可执行计划里给了Location，到哪里去读数据。broadcastExchange，怎么分配数据。BroadcastHashJoin，进行什么种类的join等等。&lt;/p&gt;

&lt;p&gt;后面就可以转化为RDD。&lt;/p&gt;

&lt;h3 id=&quot;添加自己的rule&quot;&gt;添加自己的Rule&lt;/h3&gt;

&lt;p&gt;这里有一个查询，如下：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.functions._&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tableA&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;'a)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tableB&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;'b)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tableA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tableB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupBy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;物理计划如下，耗时33秒：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Physical Plan ==
*HashAggregate(keys=[], functions=[count(1)])
+- Exchange SinglePartition
   +- *HashAggregate(keys=[], functions=[partial_count(1)])
      +- *Project
         +- *SortMergeJoin [id#0L], [id#4L], Inner
            :- *Sort [id#0L ASC NULLS FIRST], false, 0
            :  +- Exchange hashpartitioning(id#0L, 200)
            :     +- *Range (0, 20000000, step=1, splits=Some(1))
            +- *Sort [id#4L ASC NULLS FIRST], false, 0
               +- Exchange hashpartitioning(id#4L, 200)
                  +- *Range (0, 10000000, step=1, splits=Some(1))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;tableA 和tableB 都是一个range，一个是[0,19999999]，另外一个[0,9999999],让两个表求交集。&lt;/p&gt;

&lt;p&gt;其实可以添加优化规则，判断两个range的start 和 end，来求区间的交集。&lt;/p&gt;

&lt;p&gt;因此我们添加了一个Rule，如下。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.SparkConf&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.SparkSession&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.execution.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RangeExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.Strategy&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.expressions.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Alias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EqualTo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.plans.Inner&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.sql.catalyst.plans.logical.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntervalJoin&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Strategy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Serializable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;SparkPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plan&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Inner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;EqualTo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;semanticEquals&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;part1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;part2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrElse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RangeExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Range&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;part&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;twoColumns&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProjectExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
          &lt;span class=&quot;nc&quot;&gt;Alias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exprId&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exprId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;twoColumns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;


  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;//添加规则到外部规则列表中， spark is a spark session
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extraStrategies&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;IntervalJoin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;物理计划如下，耗时0.5s:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;== Physical Plan ==
*HashAggregate(keys=[], functions=[count(1)])
+- Exchange SinglePartition
   +- *HashAggregate(keys=[], functions=[partial_count(1)])
      +- *Project
         +- *Project [id#0L AS id#0L]
            +- *Range (0, 10000000, step=1, splits=Some(1))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;参考文献&quot;&gt;参考文献&lt;/h3&gt;

&lt;p&gt;https://databricks.com/session/a-deep-dive-into-spark-sqls-catalyst-optimizer&lt;/p&gt;

&lt;p&gt;https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html&lt;/p&gt;

&lt;p&gt;https://databricks.com/blog/2017/08/31/cost-based-optimizer-in-apache-spark-2-2.html&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Spark Sql Analysis</title>
   <link href="http://turbofei.github.io/spark/2018/07/27/Spark-Sql-Analysis"/>
   <updated>2018-07-27T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2018/07/27/Spark-Sql-Analysis</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql概述&quot; id=&quot;markdown-toc-spark-sql概述&quot;&gt;Spark Sql概述&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#源码跟踪&quot; id=&quot;markdown-toc-源码跟踪&quot;&gt;源码跟踪&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sql-语句--unresolved-logicalplan&quot; id=&quot;markdown-toc-sql-语句--unresolved-logicalplan&quot;&gt;sql 语句-&amp;gt; Unresolved LogicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#resolved-logicalplan&quot; id=&quot;markdown-toc-resolved-logicalplan&quot;&gt;Resolved LogicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#optimizedlogicalplan&quot; id=&quot;markdown-toc-optimizedlogicalplan&quot;&gt;OptimizedLogicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#physicalplan&quot; id=&quot;markdown-toc-physicalplan&quot;&gt;PhysicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#可执行的物理计划&quot; id=&quot;markdown-toc-可执行的物理计划&quot;&gt;可执行的物理计划&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#执行&quot; id=&quot;markdown-toc-执行&quot;&gt;执行&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;从源码层面解释一个sparkSql语句是如何执行的，从sql到与底层RDD如何对接&lt;/p&gt;

&lt;h2 id=&quot;spark-sql概述&quot;&gt;Spark Sql概述&lt;/h2&gt;

&lt;p&gt;spark sql是 apache spark的其中一个模块，主要用于进行结构化数据的处理。spark sql的底层执行还是调用rdd，在之前的文章中提过rdd的执行流程，因此本文主要讲解一下从sql到底层rdd的对接。通过观察spark sql 模块的源码，源码分为四个部分，如下图。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/public/img/spark-sql/sql-model.png&quot; title=&quot;sql-model&quot; width=&quot;60%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;在官方github的sql模块readme文件有如下描述。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Catalyst (sql/catalyst) - An implementation-agnostic framework for manipulating trees of relational operators and expressions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Execution (sql/core) - A query planner / execution engine for translating Catalyst’s logical query plans into Spark RDDs. This component also includes a new public interface, SQLContext, that allows users to execute SQL or LINQ statements against existing RDDs and Parquet files.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hive Support (sql/hive) - Includes an extension of SQLContext called HiveContext that allows users to write queries using a subset of HiveQL and access data from a Hive Metastore using Hive SerDes. There are also wrappers that allow users to run queries that include Hive UDFs, UDAFs, and UDTFs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveServer and CLI support (sql/hive-thriftserver) - Includes support for the SQL CLI (bin/spark-sql) and a HiveServer2 (for JDBC/ODBC) compatible server.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文主要讲解core和catalyst模块。首先给一个spark sql语句执行流程，来方便对后续内容进行整体把握。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SQL 语句经过 SqlParser 解析成 Unresolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 analyzer 结合数据数据字典 (catalog) 进行绑定, 生成 resolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 optimizer 对 resolved LogicalPlan 进行优化, 生成 optimized LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 SparkPlan 将 LogicalPlan 转换成 PhysicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 prepareForExecution() 将 PhysicalPlan 转换成可执行物理计划;&lt;/li&gt;
  &lt;li&gt;使用 execute() 执行可执行物理计划;&lt;/li&gt;
  &lt;li&gt;生成 RDD。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;源码跟踪&quot;&gt;源码跟踪&lt;/h2&gt;

&lt;p&gt;首先是要创建sparkSession然后导入数据，此处不赘述。我们从执行sql语句开始跟踪。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val teenagersDF = spark.sql(&quot;SELECT SUM(v) FROM (SELECT score.id, 100+80+ score.math_score +score.english_score AS v FROM people JOIN score WHERE  people.id=score.id AND people.age &amp;gt;100) tmp&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;sql-语句--unresolved-logicalplan&quot;&gt;sql 语句-&amp;gt; Unresolved LogicalPlan&lt;/h3&gt;

&lt;p&gt;此部分主要是对sql语句进行解析。判断一条sql语句是否符合要求，并且进行各部分的划分，比如哪些是操作，哪些是得到的结果等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/parser.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样一句sql 调用，跟进去。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def sql(sqlText: String): DataFrame = {
  Dataset.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到sql语句会返回一个&lt;code class=&quot;highlighter-rouge&quot;&gt;dataFrame&lt;/code&gt;。而在spark中DataFrame的定义就是&lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset[Row]&lt;/code&gt; .值得一提的是，在spark源码中用到了许多&lt;code class=&quot;highlighter-rouge&quot;&gt;lazy&lt;/code&gt;变量，这些变量虽然是声明在类中，但是并不是在创建对象的时候就初始化这些变量，而是在第一次调用是才进行初始化，因此在跟踪源码时一定要注意这些lazy变量的调用，因为很多lazy变量的初始化都涉及到一系列函数的调用。如果不注意，会失去对很多函数的跟踪。具体lazy变量的介绍，&lt;a href=&quot;https://stackoverflow.com/questions/7484928/what-does-a-lazy-val-do&quot;&gt;可以参考&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sqlParser: ParserInterface = new SparkSqlParser(conf)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看到sqlParser就是一个lazy变量，它会创建一个解析器。上述的sql函数在创建解析器之后调用parsePlan函数，如下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Creates LogicalPlan for a given SQL string. */
override def parsePlan(sqlText: String): LogicalPlan = parse(sqlText) { parser =&amp;gt;
  astBuilder.visitSingleStatement(parser.singleStatement()) match {
    case plan: LogicalPlan =&amp;gt; plan
    case _ =&amp;gt;
      val position = Origin(None, None)
      throw new ParseException(Option(sqlText), &quot;Unsupported SQL statement&quot;, position, position)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个函数是使用了Scala柯里化特性。其实是调用的parse函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  protected def parse[T](command: String)(toResult: SqlBaseParser =&amp;gt; T): T = {
    logInfo(s&quot;Parsing command: $command&quot;)
    val lexer = new SqlBaseLexer(new ANTLRNoCaseStringStream(command))
    lexer.removeErrorListeners()
    lexer.addErrorListener(ParseErrorListener)
    val tokenStream = new CommonTokenStream(lexer)
    val parser = new SqlBaseParser(tokenStream)
    parser.addParseListener(PostProcessor)
    parser.removeErrorListeners()
    parser.addErrorListener(ParseErrorListener)

    try {
      try {
        // first, try parsing with potentially faster SLL mode
        parser.getInterpreter.setPredictionMode(PredictionMode.SLL)
        toResult(parser)
      }
      catch {
     ...
      }
    }
    catch {
      ...
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而此处的parse函数是使用的Antlr(一个开源语法分析器)来对sql语句进行解析，lexer是其词法分析器，然后spark使用自身的sqlBaseParser对sql语句进行语法分析，结合parse和parsePlan函数，得到了sql语句的&lt;code class=&quot;highlighter-rouge&quot;&gt;UnresolvedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;resolved-logicalplan&quot;&gt;Resolved LogicalPlan&lt;/h3&gt;

&lt;p&gt;此部分是对之前得到的逻辑计划进行分析，比如这个字段到底应该是什么类型，等等，不是很熟悉编译。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/analysis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;进入到Dataset类的ofRows函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def ofRows(sparkSession: SparkSession, logicalPlan: LogicalPlan): DataFrame = {
  val qe = sparkSession.sessionState.executePlan(logicalPlan)
  qe.assertAnalyzed()
  new Dataset[Row](sparkSession, qe, RowEncoder(qe.analyzed.schema))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个函数很短，跟踪executePlan函数，可以看到它是创建了一个queryExecution对象。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def executePlan(plan: LogicalPlan): QueryExecution = new QueryExecution(sparkSession, plan)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个对象是很重要的一个对象,涉及到前面的&lt;code class=&quot;highlighter-rouge&quot;&gt;UnresolvedLogicalPlan&lt;/code&gt;的分析、优化、转物理计划以及ToRDD所有操作。&lt;/p&gt;

&lt;p&gt;ofRows函数第二行是对逻辑计划进行确认分析，里面涉及到分析操作，分析是对之前逻辑计划里面的属性进行分析。分析的源码我就不贴了，分析是使用一套既定的规则，然后进行多次迭代，知道分析结果达到一个固定点或者到达最高迭代次数停止。得到&lt;code class=&quot;highlighter-rouge&quot;&gt;resolvedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;optimizedlogicalplan&quot;&gt;OptimizedLogicalPlan&lt;/h3&gt;

&lt;p&gt;此部分主要是对逻辑计划进行优化， 例如谓词下推等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/optimizer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后第三行，就是生成一个Dataset[Row]，前面提到过，其实这就是dataFrame。&lt;/p&gt;

&lt;p&gt;跟踪进入Dataset的this函数。里面有一个变量会在创建对象时执行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@transient private[sql] val logicalPlan: LogicalPlan = {
  def hasSideEffects(plan: LogicalPlan): Boolean = plan match {
    case _: Command |
         _: InsertIntoTable =&amp;gt; true
    case _ =&amp;gt; false
  }

  queryExecution.analyzed match {
    // For various commands (like DDL) and queries with side effects, we force query execution
    // to happen right away to let these side effects take place eagerly.
    case p if hasSideEffects(p) =&amp;gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case Union(children) if children.forall(hasSideEffects) =&amp;gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case _ =&amp;gt;
      queryExecution.analyzed
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看到里面有一行调用了LogicalRDD函数，第一个参数是输出位置，第一个参数，queryExecution.toRdd. 一系列的lazy变量。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val optimizedPlan: LogicalPlan = sparkSession.sessionState.optimizer.execute(withCachedData)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里调用了一些列，调用到optimizedPlan，其实也是进行规则优化，基于一系列规则，到不动点或者最大迭代次数退出优化。这就得到了&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;physicalplan&quot;&gt;PhysicalPlan&lt;/h3&gt;

&lt;p&gt;回到前面的sparkPlan懒变量，最后一句，planner.plan对之前的 &lt;code class=&quot;highlighter-rouge&quot;&gt;optimizedLogicalPlan&lt;/code&gt;进行转化生成phsicalPlan。此处的next是操作是获得返回的physicalPlan迭代器中的第一个physicalPlan。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里的planner为SparkPlanner，类中有一系列的策略，还可以从外部加策略。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def strategies: Seq[Strategy] =
    extraStrategies ++ (
    FileSourceStrategy ::
    DataSourceStrategy ::
    DDLStrategy ::
    SpecialLimits ::
    Aggregation ::
    JoinSelection ::
    InMemoryScans ::
    BasicOperators :: Nil)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后进行转化的函数如下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def plan(plan: LogicalPlan): Iterator[PhysicalPlan] = {
  // Obviously a lot to do here still...

  // Collect physical plan candidates.
  val candidates = strategies.iterator.flatMap(_(plan))

  // The candidates may contain placeholders marked as [[planLater]],
  // so try to replace them by their child plans.
  val plans = candidates.flatMap { candidate =&amp;gt;
    val placeholders = collectPlaceholders(candidate)

    if (placeholders.isEmpty) {
      // Take the candidate as is because it does not contain placeholders.
      Iterator(candidate)
    } else {
      // Plan the logical plan marked as [[planLater]] and replace the placeholders.
      placeholders.iterator.foldLeft(Iterator(candidate)) {
        case (candidatesWithPlaceholders, (placeholder, logicalPlan)) =&amp;gt;
          // Plan the logical plan for the placeholder.
          val childPlans = this.plan(logicalPlan)

          candidatesWithPlaceholders.flatMap { candidateWithPlaceholders =&amp;gt;
            childPlans.map { childPlan =&amp;gt;
              // Replace the placeholder by the child plan
              candidateWithPlaceholders.transformUp {
                case p if p == placeholder =&amp;gt; childPlan
              }
            }
          }
      }
    }
  }

  val pruned = prunePlans(plans)
  assert(pruned.hasNext, s&quot;No plan for $plan&quot;)
  pruned
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;没看明白，知识欠缺。大概就是得到一系列physicalPlan，然后进行剪枝，筛除掉性能不好的，这就得到了&lt;code class=&quot;highlighter-rouge&quot;&gt;physicalPlan&lt;/code&gt;迭代器，然后通过前面说的next函数，得到迭代器头部的&lt;code class=&quot;highlighter-rouge&quot;&gt;physicalPlan&lt;/code&gt;，应该是最好的那个。&lt;/p&gt;

&lt;h3 id=&quot;可执行的物理计划&quot;&gt;可执行的物理计划&lt;/h3&gt;

&lt;p&gt;在得到物理计划sparkPlan之后会执行下面的函数，prepareForExecution(sparkPlan)，得到可执行的物理计划。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Prepares a planned [[SparkPlan]] for execution by inserting shuffle operations and internal
 * row format conversions as needed.
 */
protected def prepareForExecution(plan: SparkPlan): SparkPlan = {
  preparations.foldLeft(plan) { case (sp, rule) =&amp;gt; rule.apply(sp) }
}

/** A sequence of rules that will be applied in order to the physical plan before execution. */
protected def preparations: Seq[Rule[SparkPlan]] = Seq(
  python.ExtractPythonUDFs,
  PlanSubqueries(sparkSession),
  EnsureRequirements(sparkSession.sessionState.conf),
  CollapseCodegenStages(sparkSession.sessionState.conf),
  ReuseExchange(sparkSession.sessionState.conf),
  ReuseSubquery(sparkSession.sessionState.conf))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看注释以及源码，理解，就是又是一些规则，然后对逻辑计划不断使用这些规则进行完善，就是把规则按顺序运用一遍，&lt;a href=&quot;https://blog.csdn.net/oopsoom/article/details/23447317&quot;&gt;scala的 foldleft用法参考这里&lt;/a&gt;,不得不说scala语法真多。&lt;/p&gt;

&lt;h3 id=&quot;执行&quot;&gt;执行&lt;/h3&gt;

&lt;p&gt;可以看到在获得获得可执行计划之后就是执行，&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def execute(): RDD[InternalRow] = executeQuery {
  doExecute()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//class sparkPlan
protected def doExecute(): RDD[InternalRow]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个函数对应很多子类，每个子类的第一句基本都是&lt;code class=&quot;highlighter-rouge&quot;&gt;child.execute()&lt;/code&gt;,可见这是在构建lineage。也就是一条链，把所有可执行计划串联起来。&lt;/p&gt;

&lt;p&gt;这里的doExecute返回的是一个中间类型的RDD。&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Rdd Basics</title>
   <link href="http://turbofei.github.io/spark/2018/07/12/rdd-basics"/>
   <updated>2018-07-12T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2018/07/12/rdd-basics</id>
   <content type="html">
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;从RDD入手, 对Spark进行深入理解&lt;/p&gt;

&lt;h3 id=&quot;正文&quot;&gt;正文&lt;/h3&gt;
&lt;p&gt;是之前做的html格式的PPT，&lt;a href=&quot;https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1&quot;&gt;链接&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Deca项目总结</title>
   <link href="http://turbofei.github.io/essay/2017/07/01/deca%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93"/>
   <updated>2017-07-01T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/essay/2017/07/01/deca项目总结</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;Deca项目是研究生期间参加的重要科研项目，项目主要是采用去对象化的思想，减少大数据平台在运行过程中，数据的占有空间与对象的数量，从而减小内存的压力，也减小GC的压力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;实现的功能&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;deca主要实现的功能就是减小了大数据平台在运行任务过程中的数据在内存中的占用量以及在运行过程中对象的数量。&lt;/p&gt;

&lt;p&gt;当前的主流分布式内存计算系统均采用&lt;code class=&quot;highlighter-rouge&quot;&gt;高级托管语言&lt;/code&gt;开发，这样开发进度快，方便部署和维护。&lt;/p&gt;

&lt;p&gt;GC是托管语言（JAVA,SCALA等）的运行时系统自主管理对象的基础，GC操作会检索当前堆中存活的对象，并释放已经死亡对象的空间。&lt;/p&gt;

&lt;p&gt;大量数据均以对象形式存放在内存中，这对导致两个问题&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;内存膨胀问题&lt;/p&gt;

    &lt;p&gt;对象形式的内存布局会存储大量引用结构和元数据（对象头），而不是直接存储数据，空间利用率较低。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Full GC 问题&lt;/p&gt;

    &lt;p&gt;内存膨胀会导致JVM更加频繁的触发full gc（检索整个JVM堆内存），而GC开销与&lt;code class=&quot;highlighter-rouge&quot;&gt;存活对象数量&lt;/code&gt;成正比，导致GC时间过长。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里引申一下gc的分类，gc分为minor gc, major gc 和 full gc。其中minor是清理年轻代，major是清理老年代，而full是清理整个堆空间。&lt;/p&gt;

&lt;p&gt;因此在面临使用内存空间有限的情况下，必须在软件层面对内存管理进行优化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术和架构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;问题分析&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;spark是开源系统中主导的数据并行计算框架，提供函数式编程模型RDD，并增加了基于shuffle的GroupBy系列运算符扩展，支持中间数据的内存缓存和基于哈希的shuffle聚合操作。&lt;/p&gt;

&lt;p&gt;spark将数据封装在RDD中，然后通过action划分job，再通过shuffle操作划分stage，然后在jvm中运行数据。&lt;/p&gt;

&lt;p&gt;因此spark中的内存主要分为三部分。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cache RDD到内存&lt;/p&gt;

    &lt;p&gt;这部分内存需要一直维护，只要用户进行unpersist操作，所以这部分内存生命周期较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;shuffle操作(生命周期是一个stage)&lt;/p&gt;

    &lt;p&gt;shuffle操作需要落磁盘，进行磁盘I/O,因此需要维护所有磁盘I/O的数据，生命周期也长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;stage内部的操作&lt;/p&gt;

    &lt;p&gt;产生大量的临时对象，属于内存中的临时对象，很快会被gc回收。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;长时间存活对象&lt;/code&gt;会一直活在内存中，每次Full GC 要扫描的对象数量很多，计算开销很大。而且对象一直存活，会大量占用内存，频繁导致full gc。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;方法设计&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;核心思想是减少数据&lt;code class=&quot;highlighter-rouge&quot;&gt;对象的数量&lt;/code&gt;，而非数据的大小。&lt;/p&gt;

&lt;p&gt;使用对象拆解，暴露出数据对象中的&lt;code class=&quot;highlighter-rouge&quot;&gt;裸数据&lt;/code&gt;：原生字段类型；去除对象头和引用结构。&lt;/p&gt;

&lt;p&gt;基于生命周期的内存管理：将相同/相近生命周期的一组数据对象中的裸数据存放在连续的内存块（数组）中。&lt;/p&gt;

&lt;p&gt;数据无需访问时即可一次回收整个内存块空间。&lt;/p&gt;

&lt;p&gt;这样GC的索引由大量的对象变为少量的容器，gc开销大大减小。&lt;/p&gt;

&lt;p&gt;将UDT(用户定义类型）分为三类：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;静态定长：原生类型及其组合，如int, long, (int, long)&lt;/li&gt;
  &lt;li&gt;动态定长：原生类型的数组及组合，如int[], (int[], long)&lt;/li&gt;
  &lt;li&gt;变长对象和递归类型对象：实例化对象长度不确定，如TreeNode（TreeNode里面有一个TreeNode引用的left,right)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;前两种可以安全拆解，第三种不行。&lt;/p&gt;

&lt;p&gt;针对以上的三种内存，其中cache RDD，当cache的数据对象可以拆解时候，可以拆解为Bytes数组依次存放在page中，同时根据page对象中对象offset可以获得对象成员变量。&lt;/p&gt;

&lt;p&gt;而针对shuffle内存，也是放在page里面，针对shuffle阶段的排序，使用指针，避免大量数据的移动。&lt;/p&gt;

&lt;p&gt;在shuffle 阶段存在很多变长的成员，在shuffle阶段，reduceByKey尚能拆解，因为reduce之后的value依然是定长的。但是针对groupByKey这个算子，他的操作对象是（K,combinerBuffer)，combiner是变长的，group之后也是变长，是不确定的。&lt;/p&gt;

&lt;p&gt;Spark-1.4里groupByKey在shuffle write端可以利用到堆外的内存，也就是tungsten-sort，所有的数据都会写在堆外并在堆外排序，但是shuffle-read端Spark默认还是用的HashShuffleReader,所有的聚合操作都在堆内完成，这个我们已经实现了read端的堆外版本，聚合操作运行在堆外。大致介绍下原理，这里就用到了VST拆解的原理，我们知道shuffle read端读出来的(K,C)对的基本类型，于是先实现了一个简易的map(UnsafeUnfixedWidthAggregationFlintMap),嗯名字略长。。这是一个针对系统的定制的map，也是用到了Hash原理，不过所有操作都是在堆外进行。这个map用于存储key和&lt;strong&gt;valueAddress&lt;/strong&gt;，这个&lt;strong&gt;valueAddress&lt;/strong&gt;是一个long型值，我们会将K对应的一组Value在堆外开辟一片疆土用于存储他们，当然每次新来value时我们会检查是否扩容，若扩容会改变这块疆土(堆外空间)的起始地址，因为涉及到内存的拷贝，所以map中的&lt;strong&gt;valueAddress&lt;/strong&gt;就是这块存储区域的初始偏移地址。&lt;strong&gt;valueAddress&lt;/strong&gt;指向的存储区域结构为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://kzx1025.github.io/img/map.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果每个partition相同的key不多，而且每个key存在大量value时，采用mapsideCombine的groupBykey是一个不错的选择。如果不存在hot key，那收益就很小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;担当的责任&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;主要是担任shuffle groupByKey read 阶段的内存优化，我实现了read端的堆外版本，聚合操作运行在堆外。大致介绍下原理，这里就用到了VST拆解的原理，我们知道shuffle read端读出来的(K,C)对的基本类型，于是先实现了一个简易的map(UnsafeUnfixedWidthAggregationFlintMap),嗯名字略长。。这是一个针对系统的定制的map，也是用到了Hash原理，不过所有操作都是在堆外进行。这个map用于存储key和&lt;strong&gt;valueAddress&lt;/strong&gt;，这个&lt;strong&gt;valueAddress&lt;/strong&gt;是一个long型值，我们会将K对应的一组Value在堆外开辟一片疆土用于存储他们，当然每次新来value时我们会检查是否扩容，若扩容会改变这块疆土(堆外空间)的起始地址，因为涉及到内存的拷贝，所以map中的&lt;strong&gt;valueAddress&lt;/strong&gt;就是这块存储区域的初始偏移地址。&lt;/p&gt;

&lt;p&gt;这样就处理了变长类型的处理，之前是只实现了reduceBykey的。&lt;/p&gt;

&lt;p&gt;后面我们也尝试了&lt;code class=&quot;highlighter-rouge&quot;&gt;列式存储&lt;/code&gt;，把之前page中的数组形式，转换为列式存储。&lt;/p&gt;

&lt;p&gt;同时负责实验的设计，实验过程中遇到bug的解决以及gc统计分析的工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;难点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;spark是惰性执行，代码中充满着各种各样的迭代器，追踪代码时都不知道哪个迭代器被调用了。修改代码需要连环的修改多个文件。&lt;/p&gt;

&lt;p&gt;然后就是有时候单机测试可以通过，但是分布式时候就。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;收获&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mark&lt;/code&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Spark源码分析shuffle实现</title>
   <link href="http://turbofei.github.io/spark/2016/12/26/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90Shuffle%E5%AE%9E%E7%8E%B0"/>
   <updated>2016-12-26T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2016/12/26/spark源码分析Shuffle实现</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#shuffle&quot; id=&quot;markdown-toc-shuffle&quot;&gt;Shuffle&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#bypassmergesortshufflewriter&quot; id=&quot;markdown-toc-bypassmergesortshufflewriter&quot;&gt;BypassMergeSortShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sortshufflewriter&quot; id=&quot;markdown-toc-sortshufflewriter&quot;&gt;SortShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#unsafeshufflewriter&quot; id=&quot;markdown-toc-unsafeshufflewriter&quot;&gt;unsafeShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#blockstoreshufflereader&quot; id=&quot;markdown-toc-blockstoreshufflereader&quot;&gt;BlockStoreShuffleReader&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark shuff部分是spark源码的重要组成部分，shuffle发生在stage的交界处，对于spark的性能有重要影响，源码更新后，spark的shuffle机制也不一样，本文分析spark2.0的shuffle实现。&lt;/p&gt;

&lt;p&gt;本文基于spark2.0。&lt;/p&gt;

&lt;h2 id=&quot;shuffle&quot;&gt;Shuffle&lt;/h2&gt;

&lt;p&gt;shuffle是Mapreduce框架中一个特定的phase，介于Map和Reduce之间。shuffle的英文意思是混洗，包含两个部分，shuffle write 和shuffle read。这里有一篇文章:&lt;a href=&quot;http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/&quot;&gt;详细探究Spark的shuffle实现&lt;/a&gt;，这篇文章写于2014年，讲的是早期版本的shuffle实现。随着源码的更新，shuffle机制也做出了相应的优化，下面分析spark-2.0的shuffle机制。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;shuffleWriter&lt;/code&gt;是一个抽象类，具体实现有三种，&lt;code class=&quot;highlighter-rouge&quot;&gt;BypassMergeSortShuffleWriter&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;sortShuffleWriter&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;UnsafeShuffleWriter&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;bypassmergesortshufflewriter&quot;&gt;BypassMergeSortShuffleWriter&lt;/h3&gt;

&lt;p&gt;-_-,我先翻译下这个类开头给的注释，注释是很好的全局理解代码的工具，要好好理解。如下：&lt;/p&gt;

&lt;p&gt;这个类实现了基于sort-shuffle的hash风格的shuffle fallback path（回退路径？怎么翻）。这个write路径把数据写到不同的文件里，每个文件对应一个reduce分区，然后把这些文件整合到一个单独的文件，这个文件的不同区域服务不同的reducer。数据不是缓存在内存中。这个类本质上和之前的&lt;code class=&quot;highlighter-rouge&quot;&gt;HashShuffleReader&lt;/code&gt;，除了这个类的输出格式可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;org.apache.spark.shuffle.IndexShuffleBlockResolver&lt;/code&gt;来调用。这个写路径对于有许多reduce分区的shuffle来说是不高效的，因为他同时打开很多serializers和文件流。因此只有在以下情况下才会选择这个路径：&lt;/p&gt;

&lt;p&gt;1、没有排序  2、没有聚合操作  3、partition的数量小于bypassMergeThreshold&lt;/p&gt;

&lt;p&gt;这个代码曾经是ExternalSorter的一部分，但是为了减少代码复杂度就独立了出来。好，翻译结束。-_-&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void write(Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  assert (partitionWriters == null);
  if (!records.hasNext()) {
    partitionLengths = new long[numPartitions];
    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, null);
    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);
    return;
  }
  final SerializerInstance serInstance = serializer.newInstance();
  final long openStartTime = System.nanoTime();
  partitionWriters = new DiskBlockObjectWriter[numPartitions];
  for (int i = 0; i &amp;lt; numPartitions; i++) {
    final Tuple2&amp;lt;TempShuffleBlockId, File&amp;gt; tempShuffleBlockIdPlusFile =
      blockManager.diskBlockManager().createTempShuffleBlock();
    final File file = tempShuffleBlockIdPlusFile._2();
    final BlockId blockId = tempShuffleBlockIdPlusFile._1();
    partitionWriters[i] =
      blockManager.getDiskWriter(blockId, file, serInstance, fileBufferSize, writeMetrics);
  }
  // Creating the file to write to and creating a disk writer both involve interacting with
  // the disk, and can take a long time in aggregate when we open many files, so should be
  // included in the shuffle write time.
  writeMetrics.incWriteTime(System.nanoTime() - openStartTime);

  while (records.hasNext()) {
    final Product2&amp;lt;K, V&amp;gt; record = records.next();
    final K key = record._1();
    partitionWriters[partitioner.getPartition(key)].write(key, record._2());
  }

  for (DiskBlockObjectWriter writer : partitionWriters) {
    writer.commitAndClose();
  }

  File output = shuffleBlockResolver.getDataFile(shuffleId, mapId);
  File tmp = Utils.tempFileWith(output);
  try {
    partitionLengths = writePartitionedFile(tmp);
    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, tmp);
  } finally {
    if (tmp.exists() &amp;amp;&amp;amp; !tmp.delete()) {
      logger.error(&quot;Error while deleting temp file {}&quot;, tmp.getAbsolutePath());
    }
  }
  mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;前面都很好理解，就是根据key的哈希值写到不同的文件里面，然后就是&lt;code class=&quot;highlighter-rouge&quot;&gt;writePartitionedFile&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;writeIndexFileAndCommit&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Concatenate all of the per-partition files into a single combined file.
 *
 * @return array of lengths, in bytes, of each partition of the file (used by map output tracker).
 */
private long[] writePartitionedFile(File outputFile) throws IOException {
  // Track location of the partition starts in the output file
  final long[] lengths = new long[numPartitions];
  if (partitionWriters == null) {
    // We were passed an empty iterator
    return lengths;
  }

  final FileOutputStream out = new FileOutputStream(outputFile, true);
  final long writeStartTime = System.nanoTime();
  boolean threwException = true;
  try {
    for (int i = 0; i &amp;lt; numPartitions; i++) {
      final File file = partitionWriters[i].fileSegment().file();
      if (file.exists()) {
        final FileInputStream in = new FileInputStream(file);
        boolean copyThrewException = true;
        try {
          lengths[i] = Utils.copyStream(in, out, false, transferToEnabled);
          copyThrewException = false;
        } finally {
          Closeables.close(in, copyThrewException);
        }
        if (!file.delete()) {
          logger.error(&quot;Unable to delete file for partition {}&quot;, i);
        }
      }
    }
    threwException = false;
  } finally {
    Closeables.close(out, threwException);
    writeMetrics.incWriteTime(System.nanoTime() - writeStartTime);
  }
  partitionWriters = null;
  return lengths;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个就是按顺序把之前写的分区文件里的数据合并到一个大文件里面，然后返回每个分区文件的长度。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Write an index file with the offsets of each block, plus a final offset at the end for the
 * end of the output file. This will be used by getBlockData to figure out where each block
 * begins and ends.
 *
 * It will commit the data and index file as an atomic operation, use the existing ones, or
 * replace them with new ones.
 *
 * Note: the `lengths` will be updated to match the existing index file if use the existing ones.
 * */
def writeIndexFileAndCommit(
    shuffleId: Int,
    mapId: Int,
    lengths: Array[Long],
    dataTmp: File): Unit = {
  val indexFile = getIndexFile(shuffleId, mapId)
  val indexTmp = Utils.tempFileWith(indexFile)
  try {
    val out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(indexTmp)))
    Utils.tryWithSafeFinally {
      // We take in lengths of each block, need to convert it to offsets.
      var offset = 0L
      out.writeLong(offset)
      for (length &amp;lt;- lengths) {
        offset += length
        out.writeLong(offset)
      }
    } {
      out.close()
    }

    val dataFile = getDataFile(shuffleId, mapId)
    // There is only one IndexShuffleBlockResolver per executor, this synchronization make sure
    // the following check and rename are atomic.
    synchronized {
      val existingLengths = checkIndexAndDataFile(indexFile, dataFile, lengths.length)
      if (existingLengths != null) {
        // Another attempt for the same task has already written our map outputs successfully,
        // so just use the existing partition lengths and delete our temporary map outputs.
        System.arraycopy(existingLengths, 0, lengths, 0, lengths.length)
        if (dataTmp != null &amp;amp;&amp;amp; dataTmp.exists()) {
          dataTmp.delete()
        }
        indexTmp.delete()
      } else {
        // This is the first successful attempt in writing the map outputs for this task,
        // so override any existing index and data files with the ones we wrote.
        if (indexFile.exists()) {
          indexFile.delete()
        }
        if (dataFile.exists()) {
          dataFile.delete()
        }
        if (!indexTmp.renameTo(indexFile)) {
          throw new IOException(&quot;fail to rename file &quot; + indexTmp + &quot; to &quot; + indexFile)
        }
        if (dataTmp != null &amp;amp;&amp;amp; dataTmp.exists() &amp;amp;&amp;amp; !dataTmp.renameTo(dataFile)) {
          throw new IOException(&quot;fail to rename file &quot; + dataTmp + &quot; to &quot; + dataFile)
        }
      }
    }
  } finally {
    if (indexTmp.exists() &amp;amp;&amp;amp; !indexTmp.delete()) {
      logError(s&quot;Failed to delete temporary index file at ${indexTmp.getAbsolutePath}&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解释下这段代码，上来先写indexTmp，是把分区文件长度写进去，便于索引需要的那部分数据。然后就判断这个任务是不是第一次执行到这里，如果之前执行成功过，那就不用写了，直接用以前的结果就行。&lt;/p&gt;

&lt;p&gt;如果是第一次执行到这里，那么就把之前的indexTmp重命名为indexFile，dataTmp重命名为dataFile然后返回。&lt;/p&gt;

&lt;p&gt;这里要注意下，每个executor上面只有一个&lt;code class=&quot;highlighter-rouge&quot;&gt;IndexShuffleBlockResolver&lt;/code&gt;，这个管理这个executor上所有的indexFile.&lt;/p&gt;

&lt;p&gt;等这个indexFile也写好之后，就返回&lt;code class=&quot;highlighter-rouge&quot;&gt;mapStatus&lt;/code&gt;。shuffleWrite就结束了。&lt;/p&gt;

&lt;h3 id=&quot;sortshufflewriter&quot;&gt;SortShuffleWriter&lt;/h3&gt;

&lt;p&gt;首先描述下大概。因为是sort，所以要排序，这里就用到了ExternalSoter这个数据结构。然后把要处理的数据全部插入到ExternalSorter里面，在插入的过程中是不排序的，就是插入，插入数据是(partitionId,key,value)。然后是调用&lt;code class=&quot;highlighter-rouge&quot;&gt; sorter.writePartitionedFile&lt;/code&gt;,在这里会排序，会按照partitionId和key（或者key的hashcode）进行排序，其他的就和上面bypassShuffleWriter的差不多了，最后也是写到一个indexFile里面。返回mapStatus。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Write a bunch of records to this task's output */
override def write(records: Iterator[Product2[K, V]]): Unit = {
  sorter = if (dep.mapSideCombine) {
    require(dep.aggregator.isDefined, &quot;Map-side combine without Aggregator specified!&quot;)
    new ExternalSorter[K, V, C](
      context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer)
  } else {
    // In this case we pass neither an aggregator nor an ordering to the sorter, because we don't
    // care whether the keys get sorted in each partition; that will be done on the reduce side
    // if the operation being run is sortByKey.
    new ExternalSorter[K, V, V](
      context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer)
  }
  sorter.insertAll(records)

  // Don't bother including the time to open the merged output file in the shuffle write time,
  // because it just opens a single file, so is typically too fast to measure accurately
  // (see SPARK-3570).
  val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)
  val tmp = Utils.tempFileWith(output)
  try {
    val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID)
    val partitionLengths = sorter.writePartitionedFile(blockId, tmp)
    shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp)
    mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths)
  } finally {
    if (tmp.exists() &amp;amp;&amp;amp; !tmp.delete()) {
      logError(s&quot;Error while deleting temp file ${tmp.getAbsolutePath}&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里面ExternalSorter是核心。看它的源码，它存数据是使用的两种数据结构。&lt;code class=&quot;highlighter-rouge&quot;&gt;PartitionedAppendOnlyMap&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;PartitionedPairBuffer&lt;/code&gt;，其中有聚合操作使用map，没有聚合操作使用buffer。PartitionedAppendOnlyMap 继承了SizeTrackingAppendOnlyMap 和WritablePartitionedPairCollection 。 其中SizeTrackingAppendOnlyMap是用于预测空间（SizeTracker），然后加存储数据（AppendOnlyMap）,然后WritablePartitionedPairCollection是用于插入数据时候插入partitionId（insert(partition: Int, key: K, value: V)）加上里面实现了对数据按照partitionId和Key排序的方法。&lt;/p&gt;

&lt;p&gt;我主要是对AppendOnlyMap怎么存储数据比较感兴趣。看下AppendOnlyMap。&lt;/p&gt;

&lt;p&gt;看源码，它存储数据是&lt;code class=&quot;highlighter-rouge&quot;&gt;private var data = new Array[AnyRef](2 * capacity)&lt;/code&gt;,是使用数组存储的，key和value挨着，这样做是为了节省空间。&lt;/p&gt;

&lt;p&gt;然后map的Update和changeValue函数是差不多的，只不过后者的changeValue是由计算函数计算的value，所以我们就看update方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Set the value for a key */
def update(key: K, value: V): Unit = {
  assert(!destroyed, destructionMessage)
  val k = key.asInstanceOf[AnyRef]
  if (k.eq(null)) {
    if (!haveNullValue) {
      incrementSize()
    }
    nullValue = value
    haveNullValue = true
    return
  }
  var pos = rehash(key.hashCode) &amp;amp; mask
  var i = 1
  while (true) {
    val curKey = data(2 * pos)
    if (curKey.eq(null)) {
      data(2 * pos) = k
      data(2 * pos + 1) = value.asInstanceOf[AnyRef]
      incrementSize()  // Since we added a new key
      return
    } else if (k.eq(curKey) || k.equals(curKey)) {
      data(2 * pos + 1) = value.asInstanceOf[AnyRef]
      return
    } else {
      val delta = i
      pos = (pos + delta) &amp;amp; mask
      i += 1
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看源码可以看出，这里插入数据，采用的二次探测法。java.util.collection的HashMap在hash冲突时候采用的是链接法，而这里的二次探测法缺点就是删除元素时候比较复杂，不能简单的把数组中的相应位置设为null，这样就没办法查找元素，通常是把被删除的元素标记为已删除，但是又需要占据额外的空间。但是此处是appendOnlyMap，也就是只会追加（插入或者更新），不会删除，所以这个自定义的map更省内存。&lt;/p&gt;

&lt;p&gt;然后这个AppendOnlyMap会在growMap的时候重新hash。在sorter.insertall时候是不排序的。&lt;/p&gt;

&lt;p&gt;然后writePartitionedFile 里面调用&lt;code class=&quot;highlighter-rouge&quot;&gt;collection.destructiveSortedWritablePartitionedIterator(comparator)	&lt;/code&gt;会对数据排序，之后就跟上一小节里面的writePartitionedFile差不多了，无非就是把内存里面的数据和spill的数据合并之后写入大文件里面，之后的writeIndexFile是一样的，就不细说。&lt;/p&gt;

&lt;h3 id=&quot;unsafeshufflewriter&quot;&gt;unsafeShuffleWriter&lt;/h3&gt;

&lt;p&gt;这里之所以叫作unsafe，是因为要操纵堆外内存，把数据写到堆外，堆外内存是不受jvm控制的，需要手动进行申请内存与释放内存空间，所以是unsafe的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void write(scala.collection.Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  // Keep track of success so we know if we encountered an exception
  // We do this rather than a standard try/catch/re-throw to handle
  // generic throwables.
  boolean success = false;
  try {
    while (records.hasNext()) {
      insertRecordIntoSorter(records.next());
    }
    closeAndWriteOutput();
    success = true;
  } finally {
    if (sorter != null) {
      try {
        sorter.cleanupResources();
      } catch (Exception e) {
        // Only throw this error if we won't be masking another
        // error.
        if (success) {
          throw e;
        } else {
          logger.error(&quot;In addition to a failure during writing, we failed during &quot; +
                       &quot;cleanup.&quot;, e);
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;除了是写到堆外，其他应该跟sortShuffleWriter 差不多吧，懒得写了，以后发现有什么特别之处再补充。&lt;/p&gt;

&lt;h3 id=&quot;blockstoreshufflereader&quot;&gt;BlockStoreShuffleReader&lt;/h3&gt;

&lt;p&gt;前面三个shuffleWriter，shuffle分为shuffleWriter和shuffleReader。shuffleReadr只有一个具体实现类就是BlockStoreShuffleReader。看开头注释为：读取（startPartition和endPartition）之间的partition的数据，从其他节点。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Read the combined key-values for this reduce task */
override def read(): Iterator[Product2[K, C]] = {
  val blockFetcherItr = new ShuffleBlockFetcherIterator(
    context,
    blockManager.shuffleClient,
    blockManager,
    mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition),
    // Note: we use getSizeAsMb when no suffix is provided for backwards compatibility
    SparkEnv.get.conf.getSizeAsMb(&quot;spark.reducer.maxSizeInFlight&quot;, &quot;48m&quot;) * 1024 * 1024,
    SparkEnv.get.conf.getInt(&quot;spark.reducer.maxReqsInFlight&quot;, Int.MaxValue))

  // Wrap the streams for compression based on configuration
  val wrappedStreams = blockFetcherItr.map { case (blockId, inputStream) =&amp;gt;
    serializerManager.wrapForCompression(blockId, inputStream)
  }

  val serializerInstance = dep.serializer.newInstance()

  // Create a key/value iterator for each stream
  val recordIter = wrappedStreams.flatMap { wrappedStream =&amp;gt;
    // Note: the asKeyValueIterator below wraps a key/value iterator inside of a
    // NextIterator. The NextIterator makes sure that close() is called on the
    // underlying InputStream when all records have been read.
    serializerInstance.deserializeStream(wrappedStream).asKeyValueIterator
  }

  // Update the context task metrics for each record read.
  val readMetrics = context.taskMetrics.createTempShuffleReadMetrics()
  val metricIter = CompletionIterator[(Any, Any), Iterator[(Any, Any)]](
    recordIter.map { record =&amp;gt;
      readMetrics.incRecordsRead(1)
      record
    },
    context.taskMetrics().mergeShuffleReadMetrics())

  // An interruptible iterator must be used here in order to support task cancellation
  val interruptibleIter = new InterruptibleIterator[(Any, Any)](context, metricIter)

  val aggregatedIter: Iterator[Product2[K, C]] = if (dep.aggregator.isDefined) {
    if (dep.mapSideCombine) {
      // We are reading values that are already combined
      val combinedKeyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, C)]]
      dep.aggregator.get.combineCombinersByKey(combinedKeyValuesIterator, context)
    } else {
      // We don't know the value type, but also don't care -- the dependency *should*
      // have made sure its compatible w/ this aggregator, which will convert the value
      // type to the combined type C
      val keyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, Nothing)]]
      dep.aggregator.get.combineValuesByKey(keyValuesIterator, context)
    }
  } else {
    require(!dep.mapSideCombine, &quot;Map-side combine without Aggregator specified!&quot;)
    interruptibleIter.asInstanceOf[Iterator[Product2[K, C]]]
  }

  // Sort the output if there is a sort ordering defined.
  dep.keyOrdering match {
    case Some(keyOrd: Ordering[K]) =&amp;gt;
      // Create an ExternalSorter to sort the data. Note that if spark.shuffle.spill is disabled,
      // the ExternalSorter won't spill to disk.
      val sorter =
        new ExternalSorter[K, C, C](context, ordering = Some(keyOrd), serializer = dep.serializer)
      sorter.insertAll(aggregatedIter)
      context.taskMetrics().incMemoryBytesSpilled(sorter.memoryBytesSpilled)
      context.taskMetrics().incDiskBytesSpilled(sorter.diskBytesSpilled)
      context.taskMetrics().incPeakExecutionMemory(sorter.peakMemoryUsedBytes)
      CompletionIterator[Product2[K, C], Iterator[Product2[K, C]]](sorter.iterator, sorter.stop())
    case None =&amp;gt;
      aggregatedIter
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;首先是建立一个&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleBlockFetcherIterator&lt;/code&gt;，传入的参数有&lt;code class=&quot;highlighter-rouge&quot;&gt;mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition)&lt;/code&gt;,这个是必须的，只取需要的partition的数据。&lt;/p&gt;

&lt;p&gt;点进去ShuffleBlockFetcherIterator这个类，发现这个类会自动调用initialize()方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[this] def initialize(): Unit = {
  // Add a task completion callback (called in both success case and failure case) to cleanup.
  context.addTaskCompletionListener(_ =&amp;gt; cleanup())

  // Split local and remote blocks.
  val remoteRequests = splitLocalRemoteBlocks()
  // Add the remote requests into our queue in a random order
  fetchRequests ++= Utils.randomize(remoteRequests)
  assert ((0 == reqsInFlight) == (0 == bytesInFlight),
    &quot;expected reqsInFlight = 0 but found reqsInFlight = &quot; + reqsInFlight +
    &quot;, expected bytesInFlight = 0 but found bytesInFlight = &quot; + bytesInFlight)

  // Send out initial requests for blocks, up to our maxBytesInFlight
  fetchUpToMaxBytes()

  val numFetches = remoteRequests.size - fetchRequests.size
  logInfo(&quot;Started &quot; + numFetches + &quot; remote fetches in&quot; + Utils.getUsedTimeMs(startTime))

  // Get Local Blocks
  fetchLocalBlocks()
  logDebug(&quot;Got local blocks in &quot; + Utils.getUsedTimeMs(startTime))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个方法里面会&lt;code class=&quot;highlighter-rouge&quot;&gt;fetchUpToMaxBytes()&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;fetchLocalBlocks()&lt;/code&gt;,一个是取远程数据一个是取本地数据。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def fetchUpToMaxBytes(): Unit = {
  // Send fetch requests up to maxBytesInFlight
  while (fetchRequests.nonEmpty &amp;amp;&amp;amp;
    (bytesInFlight == 0 ||
      (reqsInFlight + 1 &amp;lt;= maxReqsInFlight &amp;amp;&amp;amp;
        bytesInFlight + fetchRequests.front.size &amp;lt;= maxBytesInFlight))) {
    sendRequest(fetchRequests.dequeue())
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里会设置一个阈值，避免过度负载的。&lt;code class=&quot;highlighter-rouge&quot;&gt;sendRequest&lt;/code&gt;来请求数据。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[this] def sendRequest(req: FetchRequest) {
  logDebug(&quot;Sending request for %d blocks (%s) from %s&quot;.format(
    req.blocks.size, Utils.bytesToString(req.size), req.address.hostPort))
  bytesInFlight += req.size
  reqsInFlight += 1

  // so we can look up the size of each blockID
  val sizeMap = req.blocks.map { case (blockId, size) =&amp;gt; (blockId.toString, size) }.toMap
  val remainingBlocks = new HashSet[String]() ++= sizeMap.keys
  val blockIds = req.blocks.map(_._1.toString)

  val address = req.address
  shuffleClient.fetchBlocks(address.host, address.port, address.executorId, blockIds.toArray,
    new BlockFetchingListener {
      override def onBlockFetchSuccess(blockId: String, buf: ManagedBuffer): Unit = {
        // Only add the buffer to results queue if the iterator is not zombie,
        // i.e. cleanup() has not been called yet.
        ShuffleBlockFetcherIterator.this.synchronized {
          if (!isZombie) {
            // Increment the ref count because we need to pass this to a different thread.
            // This needs to be released after use.
            buf.retain()
            remainingBlocks -= blockId
            results.put(new SuccessFetchResult(BlockId(blockId), address, sizeMap(blockId), buf,
              remainingBlocks.isEmpty))
            logDebug(&quot;remainingBlocks: &quot; + remainingBlocks)
          }
        }
        logTrace(&quot;Got remote block &quot; + blockId + &quot; after &quot; + Utils.getUsedTimeMs(startTime))
      }

      override def onBlockFetchFailure(blockId: String, e: Throwable): Unit = {
        logError(s&quot;Failed to get block(s) from ${req.address.host}:${req.address.port}&quot;, e)
        results.put(new FailureFetchResult(BlockId(blockId), address, e))
      }
    }
  )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;后面一大堆代码，反正就是取数据吗，就不细看了。&lt;/p&gt;

&lt;p&gt;取完数据之后，就通过dep.mapSideCombine判断是否在map端做了聚合操作，如果做了聚合操作，这里的(k,v)的v就是CompactBuffer类型，就调用combineCombinersByKey，如果在map端没有聚合，就还是value类型，就combineValuesByKey。&lt;/p&gt;

&lt;p&gt;之后就判断是否定义了排序，如果需要排序就用ExternalSorter排序。&lt;/p&gt;

&lt;p&gt;到这里shuffle过程就结束啦。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;前两种shuffleWriter（UnsafeShuffleWriter没细看）里的shuffleWrite端最后得到的文件都只是一个IndexFile，这跟&lt;a href=&quot;http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/&quot;&gt;早期的shuffle机制&lt;/a&gt;还是不一样的。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Spark内存预测</title>
   <link href="http://turbofei.github.io/spark/2016/12/26/spark%E5%86%85%E5%AD%98%E9%A2%84%E6%B5%8B"/>
   <updated>2016-12-26T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2016/12/26/spark内存预测</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sizetracker&quot; id=&quot;markdown-toc-sizetracker&quot;&gt;sizeTracker&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sizeestimator&quot; id=&quot;markdown-toc-sizeestimator&quot;&gt;SizeEstimator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark是一个内存计算框架，因此内存是重要的资源，合理的使用的内存在spark应用在执行过程中非常重要。在使用内存的过程，spark会采用抽样的方法预测出所需要的内存，并预先分配内存。本文会就内存预测机制进行源码的解读。&lt;/p&gt;

&lt;h2 id=&quot;sizetracker&quot;&gt;sizeTracker&lt;/h2&gt;

&lt;p&gt;spark里面内存预测有一个trait，叫做&lt;code class=&quot;highlighter-rouge&quot;&gt; SizeTracker&lt;/code&gt;，然后有一些类实现了它，比如PartitionedAppendOnlyMap、SizeTrackingAppendOnlyMap。&lt;/p&gt;

&lt;p&gt;SizeTracker的estimateSize方法就是预测当前集合的size。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Estimate the current size of the collection in bytes. O(1) time.
 */
def estimateSize(): Long = {
  assert(samples.nonEmpty)
  val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates)
  (samples.last.size + extrapolatedDelta).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其实这个sizeTracker类有四个方法，其他三个方法分别是&lt;code class=&quot;highlighter-rouge&quot;&gt;resetSamples&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;afterUpdate&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;takeSample&lt;/code&gt;.看了下SizeTrackingAppendOnlyMap的流程，afterUpdata方法是在update或者changeValue之后会调用，其实updata和changeValue没有什么区别，只不过一个是直接更新k-v，另一个是使用一个函数计算后更新k-v。然后resetSamples是在growTable之后调用（SizeTrackingAppendOnlyMap的growTable就是空间翻一倍）。&lt;/p&gt;

&lt;p&gt;看下sizeTracker里面的参数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Controls the base of the exponential which governs the rate of sampling.
 * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.
 */
private val SAMPLE_GROWTH_RATE = 1.1

/** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */
private val samples = new mutable.Queue[Sample]

/** The average number of bytes per update between our last two samples. */
private var bytesPerUpdate: Double = _

/** Total number of insertions and updates into the map since the last resetSamples(). */
private var numUpdates: Long = _

/** The value of 'numUpdates' at which we will take our next sample. */
private var nextSampleNum: Long = _
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SAMPLE_GROWTH_RATE&lt;/code&gt;是一个斜率，代表下次抽样时候更新的次数应该是这次抽样更新次数的1.1倍，比如上次是更新10000次时候抽样，下次抽样就得是更新11000次时候再抽样，可以避免每次更新都抽样，减少抽样花销。&lt;code class=&quot;highlighter-rouge&quot;&gt;samples&lt;/code&gt;是一个队列， 里面的类型是样例类&lt;code class=&quot;highlighter-rouge&quot;&gt;sample&lt;/code&gt;。然后&lt;code class=&quot;highlighter-rouge&quot;&gt;bytesPerUpdate&lt;/code&gt;是抽样之后得到区间增长量/个数增长量，就是一个斜率。然后&lt;code class=&quot;highlighter-rouge&quot;&gt;numUpdates&lt;/code&gt;就是代表抽样集合里面元素个数，&lt;code class=&quot;highlighter-rouge&quot;&gt;nextSampleNum&lt;/code&gt;代表下次要抽样的时候集合的个数，前面说过，就是此次抽样时候的个数*1.1.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Reset samples collected so far.
 * This should be called after the collection undergoes a dramatic change in size.
 */
protected def resetSamples(): Unit = {
  numUpdates = 1
  nextSampleNum = 1
  samples.clear()
  takeSample()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;resetSamples会在每次翻倍增长后，重置抽样参数，没啥好说的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Callback to be invoked after every update.
 */
protected def afterUpdate(): Unit = {
  numUpdates += 1
  if (nextSampleNum == numUpdates) {
    takeSample()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个是每次更新后，都更新次数+1，然后当他等于下次抽样次数时候就进行抽样。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Take a new sample of the current collection's size.
 */
private def takeSample(): Unit = {
  samples.enqueue(Sample(SizeEstimator.estimate(this), numUpdates))
  // Only use the last two samples to extrapolate
  if (samples.size &amp;gt; 2) {
    samples.dequeue()
  }
  val bytesDelta = samples.toList.reverse match {
    case latest :: previous :: tail =&amp;gt;
      (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates)
    // If fewer than 2 samples, assume no change
    case _ =&amp;gt; 0
  }
  bytesPerUpdate = math.max(0, bytesDelta)
  nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;抽样就是找出最近的两个sample，然后计算增长斜率，size增长量/num增长量，然后把下次抽样的次数*1.1更新下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Estimate the current size of the collection in bytes. O(1) time.
 */
def estimateSize(): Long = {
  assert(samples.nonEmpty)
  val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates)
  (samples.last.size + extrapolatedDelta).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后这个estimateSize 就是上次的size+增长率*增长量。增长率和size就是上次抽样得到的。&lt;/p&gt;

&lt;p&gt;可以看到在takeSample方法里面加入队列时候size的预测用到了&lt;code class=&quot;highlighter-rouge&quot;&gt;SizeEstimator.estimate&lt;/code&gt;.看下这个SizeEstimator类。&lt;/p&gt;

&lt;h2 id=&quot;sizeestimator&quot;&gt;SizeEstimator&lt;/h2&gt;

&lt;p&gt;看下这类的estimate方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def estimate(obj: AnyRef, visited: IdentityHashMap[AnyRef, AnyRef]): Long = {
  val state = new SearchState(visited)
  state.enqueue(obj)
  while (!state.isFinished) {
    visitSingleObject(state.dequeue(), state)
  }
  state.size
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里主要是调用visitSingleObject。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def visitSingleObject(obj: AnyRef, state: SearchState) {
  val cls = obj.getClass
  if (cls.isArray) {
    visitArray(obj, cls, state)
  } else if (cls.getName.startsWith(&quot;scala.reflect&quot;)) {
    // Many objects in the scala.reflect package reference global reflection objects which, in
    // turn, reference many other large global objects. Do nothing in this case.
  } else if (obj.isInstanceOf[ClassLoader] || obj.isInstanceOf[Class[_]]) {
    // Hadoop JobConfs created in the interpreter have a ClassLoader, which greatly confuses
    // the size estimator since it references the whole REPL. Do nothing in this case. In
    // general all ClassLoaders and Classes will be shared between objects anyway.
  } else {
    obj match {
      case s: KnownSizeEstimation =&amp;gt;
        state.size += s.estimatedSize
      case _ =&amp;gt;
        val classInfo = getClassInfo(cls)
        state.size += alignSize(classInfo.shellSize)
        for (field &amp;lt;- classInfo.pointerFields) {
          state.enqueue(field.get(obj))
        }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果是Array类型，就visitArray。如果是scala.reflect开头的类，因为这个包里面涉及全局反射对象，因此涉及很多其他的大对象，所以这种对象不做任何操作。然后如果是classLoader类型，hadoop 作业在解释器中创建了classLoader，因为涉及整个REPL（读取-求值-处理-循环），所以很难处理。一般，所有classLoader和classes都是共享的。然后有的就是已经预测过的，直接读取。然后其他类型，就是拆解，拆成实际对象和引用，实际对象算出size相加，然后指针类型就把它指向的对象加入state队列，然后再进入while循环。直到state isFinished。&lt;/p&gt;

&lt;p&gt;接下来看看visitArray.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Estimate the size of arrays larger than ARRAY_SIZE_FOR_SAMPLING by sampling.
private val ARRAY_SIZE_FOR_SAMPLING = 400
private val ARRAY_SAMPLE_SIZE = 100 // should be lower than ARRAY_SIZE_FOR_SAMPLING

private def visitArray(array: AnyRef, arrayClass: Class[_], state: SearchState) {
  val length = ScalaRunTime.array_length(array)
  val elementClass = arrayClass.getComponentType()

  // Arrays have object header and length field which is an integer
  var arrSize: Long = alignSize(objectSize + INT_SIZE)

  if (elementClass.isPrimitive) {
    arrSize += alignSize(length.toLong * primitiveSize(elementClass))
    state.size += arrSize
  } else {
    arrSize += alignSize(length.toLong * pointerSize)
    state.size += arrSize

    if (length &amp;lt;= ARRAY_SIZE_FOR_SAMPLING) {
      var arrayIndex = 0
      while (arrayIndex &amp;lt; length) {
        state.enqueue(ScalaRunTime.array_apply(array, arrayIndex).asInstanceOf[AnyRef])
        arrayIndex += 1
      }
    } else {
      // Estimate the size of a large array by sampling elements without replacement.
      // To exclude the shared objects that the array elements may link, sample twice
      // and use the min one to calculate array size.
      val rand = new Random(42)
      val drawn = new OpenHashSet[Int](2 * ARRAY_SAMPLE_SIZE)
      val s1 = sampleArray(array, state, rand, drawn, length)
      val s2 = sampleArray(array, state, rand, drawn, length)
      val size = math.min(s1, s2)
      state.size += math.max(s1, s2) +
        (size * ((length - ARRAY_SAMPLE_SIZE) / (ARRAY_SAMPLE_SIZE))).toLong
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这段代码，首先要把&lt;code class=&quot;highlighter-rouge&quot;&gt;Array 的object 头部,长度 filed&lt;/code&gt;算进去，然后如果array里面的元素是基本类型，那么长度就固定，就可以直接算出来。&lt;/p&gt;

&lt;p&gt;如果不是基本类型，&lt;code class=&quot;highlighter-rouge&quot;&gt;就有指向对象的引用？&lt;/code&gt;所以代码里面先把length个指针占用的空间加上。&lt;/p&gt;

&lt;p&gt;如果这时候数组长度，小于采样时候数组长度那个界限，就把数组里面引用指向的对象加入state队列，也就是小于界限就全部计算size。&lt;/p&gt;

&lt;p&gt;如果数组长度大于采样时候数组长度的界限，就准备采样。然后采样两组，两组采样数据都是不重复的。计算公式如下:&lt;code class=&quot;highlighter-rouge&quot;&gt;math.max(s1, s2) + (math.min(s1, s2) * ((length - ARRAY_SAMPLE_SIZE) / (ARRAY_SAMPLE_SIZE)))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这个计算公式不知道有什么合理的地方，反正spark用这个公式，应该是有一定道理。&lt;/p&gt;

&lt;p&gt;就是  &lt;code class=&quot;highlighter-rouge&quot;&gt;math.min(s1,s2)*(length-ARRAY_SAMPLE_SIZE)+abs(s1-s2)&lt;/code&gt;，这应该是为了不让内存预估过大，以免占用太多，同时用一个小的增量对这个偏小的预估进行补偿。&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Spark应用执行流程</title>
   <link href="http://turbofei.github.io/spark/2016/12/22/spark%E5%BA%94%E7%94%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B"/>
   <updated>2016-12-22T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2016/12/22/spark应用执行流程</id>
   <content type="html">
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#word-count&quot; id=&quot;markdown-toc-word-count&quot;&gt;Word Count&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#理论剖析&quot; id=&quot;markdown-toc-理论剖析&quot;&gt;理论剖析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#源码剖析&quot; id=&quot;markdown-toc-源码剖析&quot;&gt;源码剖析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提交job&quot; id=&quot;markdown-toc-提交job&quot;&gt;提交job&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#划分stage&quot; id=&quot;markdown-toc-划分stage&quot;&gt;划分stage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提交tasks&quot; id=&quot;markdown-toc-提交tasks&quot;&gt;提交tasks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#执行task&quot; id=&quot;markdown-toc-执行task&quot;&gt;执行task&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#shufflemaptask&quot; id=&quot;markdown-toc-shufflemaptask&quot;&gt;ShuffleMapTask&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#resulttask&quot; id=&quot;markdown-toc-resulttask&quot;&gt;ResultTask&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#rdd-迭代链&quot; id=&quot;markdown-toc-rdd-迭代链&quot;&gt;rdd 迭代链&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#检查点&quot; id=&quot;markdown-toc-检查点&quot;&gt;检查点&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#compute-链&quot; id=&quot;markdown-toc-compute-链&quot;&gt;compute 链&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;从最简单的spark应用WordCount入手，分析rdd链，分析job如何提交，task如何提交，从全局了解spark应用的执行流程。&lt;/p&gt;

&lt;h2 id=&quot;word-count&quot;&gt;Word Count&lt;/h2&gt;

&lt;p&gt;word count是spark 最基本的小程序，主要功能就是统计一个文件里面各个单词出现的个数。代码很简洁，如下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import org.apache.spark.{SparkConf, SparkContext}

object SparkWC {
  def main(args: Array[String]) {
    val sparkConf = new SparkConf()
    val sparkContext = new SparkContext(sparkConf)
    sparkContext.textFile(args(0))
          .flatMap(line =&amp;gt; line.split(&quot; &quot;))
          .map(word =&amp;gt; (word, 1))
          .reduceByKey(_ + _)
          .saveAsTextFile(args(1))
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;理论剖析&quot;&gt;理论剖析&lt;/h3&gt;
&lt;p&gt;里面的RDD链，用他们的操作表示，就是textFile-&amp;gt;flatMap-&amp;gt;map-&amp;gt;reduceBykey-&amp;gt;saveAsTextFile.&lt;/p&gt;

&lt;p&gt;spark里面有两种操作，&lt;code class=&quot;highlighter-rouge&quot;&gt;action&lt;/code&gt; 和&lt;code class=&quot;highlighter-rouge&quot;&gt;transformation&lt;/code&gt;，其中action会触发提交job的操作，transformation不会触发job，只是进行rdd的转换。而不同transformation操作的rdd链两端的依赖关系也不同，spark中的rdd依赖有两种，分别是&lt;code class=&quot;highlighter-rouge&quot;&gt;narrow dependency&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;wide dependency&lt;/code&gt; ,这两种依赖如下图所示。
&lt;br /&gt;
&lt;img src=&quot;http://ogk82bfkr.bkt.clouddn.com/upload/narrow-depen.png&quot; height=&quot;200&quot; width=&quot;200&quot; /&gt;
      
&lt;img src=&quot;http://ogk82bfkr.bkt.clouddn.com/upload/wide-depen.png&quot; height=&quot;200&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边图是窄依赖，右边图是宽依赖，窄依赖里面的partition的对应顺序是不变的，款依赖会涉及shuffle操作，会造成partition混洗，因此往往以款依赖划分stage。在上面的操作中，saveAsTextFile是action，reduceByKey是宽依赖，因此这个应用总共有1个job，两个stage，然后在不同的stage中会执行tasks。&lt;/p&gt;

&lt;h3 id=&quot;源码剖析&quot;&gt;源码剖析&lt;/h3&gt;

&lt;p&gt;从rdd链开始分析。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def textFile(
      path: String,
      minPartitions: Int = defaultMinPartitions): RDD[String] = withScope {
    assertNotStopped()
    hadoopFile(path, classOf[TextInputFormat], classOf[LongWritable], classOf[Text],
      minPartitions).map(pair =&amp;gt; pair._2.toString).setName(path)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;textFile 这个算子的返回结果是一个RDD，然后RDD链就开始了，可以看出来他调用了一些新的函数，比如hadoopFile啥的，这些我们都不管，因为他们都没有触发 commitJob，所以这些中间过程我们就省略，直到saveAsTextFile这个action。&lt;/p&gt;

&lt;h3 id=&quot;提交job&quot;&gt;提交job&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def saveAsTextFile(path: String): Unit = withScope {
    // https://issues.apache.org/jira/browse/SPARK-2075
    //
    // NullWritable is a `Comparable` in Hadoop 1.+, so the compiler cannot find an implicit
    // Ordering for it and will use the default `null`. However, it's a `Comparable[NullWritable]`
    // in Hadoop 2.+, so the compiler will call the implicit `Ordering.ordered` method to create an
    // Ordering for `NullWritable`. That's why the compiler will generate different anonymous
    // classes for `saveAsTextFile` in Hadoop 1.+ and Hadoop 2.+.
    //
    // Therefore, here we provide an explicit Ordering `null` to make sure the compiler generate
    // same bytecodes for `saveAsTextFile`.
    val nullWritableClassTag = implicitly[ClassTag[NullWritable]]
    val textClassTag = implicitly[ClassTag[Text]]
    val r = this.mapPartitions { iter =&amp;gt;
      val text = new Text()
      iter.map { x =&amp;gt;
        text.set(x.toString)
        (NullWritable.get(), text)
      }
    }
    RDD.rddToPairRDDFunctions(r)(nullWritableClassTag, textClassTag, null)
      .saveAsHadoopFile[TextOutputFormat[NullWritable, Text]](path)
  }
  
  
  //接下来调用这个
  def saveAsHadoopFile[F &amp;lt;: OutputFormat[K, V]](
      path: String)(implicit fm: ClassTag[F]): Unit = self.withScope {
    saveAsHadoopFile(path, keyClass, valueClass, fm.runtimeClass.asInstanceOf[Class[F]])
  }
  
//省略一部分调用过程
...
...

//最后调用这个函数
  def saveAsHadoopDataset(conf: JobConf): Unit = self.withScope {
    // Rename this as hadoopConf internally to avoid shadowing (see SPARK-2038).
    val hadoopConf = conf
    val outputFormatInstance = hadoopConf.getOutputFormat
    val keyClass = hadoopConf.getOutputKeyClass
    val valueClass = hadoopConf.getOutputValueClass
    if (outputFormatInstance == null) {
      throw new SparkException(&quot;Output format class not set&quot;)
    }
    if (keyClass == null) {
      throw new SparkException(&quot;Output key class not set&quot;)
    }
    if (valueClass == null) {
      throw new SparkException(&quot;Output value class not set&quot;)
    }
    SparkHadoopUtil.get.addCredentials(hadoopConf)

    logDebug(&quot;Saving as hadoop file of type (&quot; + keyClass.getSimpleName + &quot;, &quot; +
      valueClass.getSimpleName + &quot;)&quot;)

    if (isOutputSpecValidationEnabled) {
      // FileOutputFormat ignores the filesystem parameter
      val ignoredFs = FileSystem.get(hadoopConf)
      hadoopConf.getOutputFormat.checkOutputSpecs(ignoredFs, hadoopConf)
    }

    val writer = new SparkHadoopWriter(hadoopConf)
    writer.preSetup()

    val writeToFile = (context: TaskContext, iter: Iterator[(K, V)]) =&amp;gt; {
      // Hadoop wants a 32-bit task attempt ID, so if ours is bigger than Int.MaxValue, roll it
      // around by taking a mod. We expect that no task will be attempted 2 billion times.
      val taskAttemptId = (context.taskAttemptId % Int.MaxValue).toInt

      val outputMetricsAndBytesWrittenCallback: Option[(OutputMetrics, () =&amp;gt; Long)] =
        initHadoopOutputMetrics(context)

      writer.setup(context.stageId, context.partitionId, taskAttemptId)
      writer.open()
      var recordsWritten = 0L

      Utils.tryWithSafeFinallyAndFailureCallbacks {
        while (iter.hasNext) {
          val record = iter.next()
          writer.write(record._1.asInstanceOf[AnyRef], record._2.asInstanceOf[AnyRef])

          // Update bytes written metric every few records
          maybeUpdateOutputMetrics(outputMetricsAndBytesWrittenCallback, recordsWritten)
          recordsWritten += 1
        }
      }(finallyBlock = writer.close())
      writer.commit()
      outputMetricsAndBytesWrittenCallback.foreach { case (om, callback) =&amp;gt;
        om.setBytesWritten(callback())
        om.setRecordsWritten(recordsWritten)
      }
    }

    self.context.runJob(self, writeToFile)
    writer.commitJob()
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;上面是saveAstextFile的调用过程，中间省略了一个函数，看代码的最后两行。可以看出调用了&lt;code class=&quot;highlighter-rouge&quot;&gt; self.context.runJob()&lt;/code&gt;可以知道这里触发了job的提交。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def runJob[T, U: ClassTag](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      resultHandler: (Int, U) =&amp;gt; Unit): Unit = {
    if (stopped.get()) {
      throw new IllegalStateException(&quot;SparkContext has been shutdown&quot;)
    }
    val callSite = getCallSite
    val cleanedFunc = clean(func)
    logInfo(&quot;Starting job: &quot; + callSite.shortForm)
    if (conf.getBoolean(&quot;spark.logLineage&quot;, false)) {
      logInfo(&quot;RDD's recursive dependencies:\n&quot; + rdd.toDebugString)
    }
    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)
    progressBar.foreach(_.finishAll())
    rdd.doCheckpoint() //是否cache rdd
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出上面代码有 &lt;code class=&quot;highlighter-rouge&quot;&gt;dagScheduler.runJob&lt;/code&gt;，开始进行调度。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def runJob[T, U](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      callSite: CallSite,
      resultHandler: (Int, U) =&amp;gt; Unit,
      properties: Properties): Unit = {
    val start = System.nanoTime
    val waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)
    // Note: Do not call Await.ready(future) because that calls `scala.concurrent.blocking`,
    // which causes concurrent SQL executions to fail if a fork-join pool is used. Note that
    // due to idiosyncrasies in Scala, `awaitPermission` is not actually used anywhere so it's
    // safe to pass in null here. For more detail, see SPARK-13747.
    val awaitPermission = null.asInstanceOf[scala.concurrent.CanAwait]
    waiter.completionFuture.ready(Duration.Inf)(awaitPermission)
    waiter.completionFuture.value.get match {
      case scala.util.Success(_) =&amp;gt;
        logInfo(&quot;Job %d finished: %s, took %f s&quot;.format
          (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9))
      case scala.util.Failure(exception) =&amp;gt;
        logInfo(&quot;Job %d failed: %s, took %f s&quot;.format
          (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9))
        // SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.
        val callerStackTrace = Thread.currentThread().getStackTrace.tail
        exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)
        throw exception
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在 dagScheduler.runJob()里面有 &lt;code class=&quot;highlighter-rouge&quot;&gt;submitJob&lt;/code&gt;的操作，提交job。
看下面&lt;code class=&quot;highlighter-rouge&quot;&gt;submitJob&lt;/code&gt;的代码。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def submitJob[T, U](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      callSite: CallSite,
      resultHandler: (Int, U) =&amp;gt; Unit,
      properties: Properties): JobWaiter[U] = {
    // Check to make sure we are not launching a task on a partition that does not exist.
    val maxPartitions = rdd.partitions.length
    partitions.find(p =&amp;gt; p &amp;gt;= maxPartitions || p &amp;lt; 0).foreach { p =&amp;gt;
      throw new IllegalArgumentException(
        &quot;Attempting to access a non-existent partition: &quot; + p + &quot;. &quot; +
          &quot;Total number of partitions: &quot; + maxPartitions)
    }

    val jobId = nextJobId.getAndIncrement()
    if (partitions.size == 0) {
      // Return immediately if the job is running 0 tasks
      return new JobWaiter[U](this, jobId, 0, resultHandler)
    }

    assert(partitions.size &amp;gt; 0)
    val func2 = func.asInstanceOf[(TaskContext, Iterator[_]) =&amp;gt; _]
    val waiter = new JobWaiter(this, jobId, partitions.size, resultHandler)
    eventProcessLoop.post(JobSubmitted(
      jobId, rdd, func2, partitions.toArray, callSite, waiter,
      SerializationUtils.clone(properties)))
    waiter
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后eventProcessLoop.post(JobSubmitted … 然后就有循环程序处理 这个post。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def doOnReceive(event: DAGSchedulerEvent): Unit = event match {
  case JobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties) =&amp;gt;
    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;划分stage&quot;&gt;划分stage&lt;/h3&gt;

&lt;p&gt;提交完job之后，会对stage进行划分。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;handleJobSubmitted&lt;/code&gt;,如下代码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[scheduler] def handleJobSubmitted(jobId: Int,
    finalRDD: RDD[_],
    func: (TaskContext, Iterator[_]) =&amp;gt; _,
    partitions: Array[Int],
    callSite: CallSite,
    listener: JobListener,
    properties: Properties) {
  var finalStage: ResultStage = null
  try {
    // New stage creation may throw an exception if, for example, jobs are run on a
    // HadoopRDD whose underlying HDFS files have been deleted.
    finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)
  } catch {
    case e: Exception =&amp;gt;
      logWarning(&quot;Creating new stage failed due to exception - job: &quot; + jobId, e)
      listener.jobFailed(e)
      return
  }

  val job = new ActiveJob(jobId, finalStage, callSite, listener, properties)
  clearCacheLocs()
  logInfo(&quot;Got job %s (%s) with %d output partitions&quot;.format(
    job.jobId, callSite.shortForm, partitions.length))
  logInfo(&quot;Final stage: &quot; + finalStage + &quot; (&quot; + finalStage.name + &quot;)&quot;)
  logInfo(&quot;Parents of final stage: &quot; + finalStage.parents)
  logInfo(&quot;Missing parents: &quot; + getMissingParentStages(finalStage))

  val jobSubmissionTime = clock.getTimeMillis()
  jobIdToActiveJob(jobId) = job
  activeJobs += job
  finalStage.setActiveJob(job)
  val stageIds = jobIdToStageIds(jobId).toArray
  val stageInfos = stageIds.flatMap(id =&amp;gt; stageIdToStage.get(id).map(_.latestInfo))
  listenerBus.post(
    SparkListenerJobStart(job.jobId, jobSubmissionTime, stageInfos, properties))
  submitStage(finalStage)

  submitWaitingStages()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解释下这段代码，先是找到最后一个stage， finalStage，然后就生成stageId还有stage的一些信息，然后post 出job开始的消息，然后提交最后一个stage，最后一行是提交等待的stages。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Submits stage, but first recursively submits any missing parents. */
private def submitStage(stage: Stage) {
  val jobId = activeJobForStage(stage)
  if (jobId.isDefined) {
    logDebug(&quot;submitStage(&quot; + stage + &quot;)&quot;)
    if (!waitingStages(stage) &amp;amp;&amp;amp; !runningStages(stage) &amp;amp;&amp;amp; !failedStages(stage)) {
      val missing = getMissingParentStages(stage).sortBy(_.id)
      logDebug(&quot;missing: &quot; + missing)
      if (missing.isEmpty) {
        logInfo(&quot;Submitting &quot; + stage + &quot; (&quot; + stage.rdd + &quot;), which has no missing parents&quot;)
        submitMissingTasks(stage, jobId.get)
      } else {
        for (parent &amp;lt;- missing) {
          submitStage(parent)
        }
        waitingStages += stage
      }
    }
  } else {
    abortStage(stage, &quot;No active job for stage &quot; + stage.id, None)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解释下这段代码，就是递归提交之前都没有提交的stage，因为之前是提交最后一个stage吗，但是前面stage也没操作，所以要不断地提交parentStage，直到job的头部。如果说这个stage没有未完成的parentStage，那就代表它前面都执行完毕。&lt;/p&gt;

&lt;h3 id=&quot;提交tasks&quot;&gt;提交tasks&lt;/h3&gt;

&lt;p&gt;找到最开始还没完成的stage，那么提交这个stage的Tasks。调用的函数是&lt;code class=&quot;highlighter-rouge&quot;&gt;submitMissingTasks(stage,jobId.get)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;下面是 这个函数的代码，有点长。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def submitMissingTasks(stage: Stage, jobId: Int) {
  logDebug(&quot;submitMissingTasks(&quot; + stage + &quot;)&quot;)
  // Get our pending tasks and remember them in our pendingTasks entry
  stage.pendingPartitions.clear()

  // First figure out the indexes of partition ids to compute.
  val partitionsToCompute: Seq[Int] = stage.findMissingPartitions()

  // Use the scheduling pool, job group, description, etc. from an ActiveJob associated
  // with this Stage
  val properties = jobIdToActiveJob(jobId).properties

  runningStages += stage
  // SparkListenerStageSubmitted should be posted before testing whether tasks are
  // serializable. If tasks are not serializable, a SparkListenerStageCompleted event
  // will be posted, which should always come after a corresponding SparkListenerStageSubmitted
  // event.
  stage match {
    case s: ShuffleMapStage =&amp;gt;
      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - 1)
    case s: ResultStage =&amp;gt;
      outputCommitCoordinator.stageStart(
        stage = s.id, maxPartitionId = s.rdd.partitions.length - 1)
  }
  val taskIdToLocations: Map[Int, Seq[TaskLocation]] = try {
    stage match {
      case s: ShuffleMapStage =&amp;gt;
        partitionsToCompute.map { id =&amp;gt; (id, getPreferredLocs(stage.rdd, id))}.toMap
      case s: ResultStage =&amp;gt;
        val job = s.activeJob.get
        partitionsToCompute.map { id =&amp;gt;
          val p = s.partitions(id)
          (id, getPreferredLocs(stage.rdd, p))
        }.toMap
    }
  } catch {
    case NonFatal(e) =&amp;gt;
      stage.makeNewStageAttempt(partitionsToCompute.size)
      listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties))
      abortStage(stage, s&quot;Task creation failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)
  listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties))

  // TODO: Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.
  // Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast
  // the serialized copy of the RDD and for each task we will deserialize it, which means each
  // task gets a different copy of the RDD. This provides stronger isolation between tasks that
  // might modify state of objects referenced in their closures. This is necessary in Hadoop
  // where the JobConf/Configuration object is not thread-safe.
  var taskBinary: Broadcast[Array[Byte]] = null
  try {
    // For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).
    // For ResultTask, serialize and broadcast (rdd, func).
    val taskBinaryBytes: Array[Byte] = stage match {
      case stage: ShuffleMapStage =&amp;gt;
        JavaUtils.bufferToArray(
          closureSerializer.serialize((stage.rdd, stage.shuffleDep): AnyRef))
      case stage: ResultStage =&amp;gt;
        JavaUtils.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): AnyRef))
    }

    taskBinary = sc.broadcast(taskBinaryBytes)
  } catch {
    // In the case of a failure during serialization, abort the stage.
    case e: NotSerializableException =&amp;gt;
      abortStage(stage, &quot;Task not serializable: &quot; + e.toString, Some(e))
      runningStages -= stage

      // Abort execution
      return
    case NonFatal(e) =&amp;gt;
      abortStage(stage, s&quot;Task serialization failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  val tasks: Seq[Task[_]] = try {
    stage match {
      case stage: ShuffleMapStage =&amp;gt;
        partitionsToCompute.map { id =&amp;gt;
          val locs = taskIdToLocations(id)
          val part = stage.rdd.partitions(id)
          new ShuffleMapTask(stage.id, stage.latestInfo.attemptId,
            taskBinary, part, locs, stage.latestInfo.taskMetrics, properties)
        }

      case stage: ResultStage =&amp;gt;
        val job = stage.activeJob.get
        partitionsToCompute.map { id =&amp;gt;
          val p: Int = stage.partitions(id)
          val part = stage.rdd.partitions(p)
          val locs = taskIdToLocations(id)
          new ResultTask(stage.id, stage.latestInfo.attemptId,
            taskBinary, part, locs, id, properties, stage.latestInfo.taskMetrics)
        }
    }
  } catch {
    case NonFatal(e) =&amp;gt;
      abortStage(stage, s&quot;Task creation failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  if (tasks.size &amp;gt; 0) {
    logInfo(&quot;Submitting &quot; + tasks.size + &quot; missing tasks from &quot; + stage + &quot; (&quot; + stage.rdd + &quot;)&quot;)
    stage.pendingPartitions ++= tasks.map(_.partitionId)
    logDebug(&quot;New pending partitions: &quot; + stage.pendingPartitions)
    taskScheduler.submitTasks(new TaskSet(
      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))
    stage.latestInfo.submissionTime = Some(clock.getTimeMillis())
  } else {
    // Because we posted SparkListenerStageSubmitted earlier, we should mark
    // the stage as completed here in case there are no tasks to run
    markStageAsFinished(stage, None)

    val debugString = stage match {
      case stage: ShuffleMapStage =&amp;gt;
        s&quot;Stage ${stage} is actually done; &quot; +
          s&quot;(available: ${stage.isAvailable},&quot; +
          s&quot;available outputs: ${stage.numAvailableOutputs},&quot; +
          s&quot;partitions: ${stage.numPartitions})&quot;
      case stage : ResultStage =&amp;gt;
        s&quot;Stage ${stage} is actually done; (partitions: ${stage.numPartitions})&quot;
    }
    logDebug(debugString)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面的代码出现了多次&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，先介绍一下这个stage。&lt;/p&gt;

&lt;p&gt;前面我们说过，WordCount只有一个job，然后reduceByKey是shuffle操作，以这个为stage的边界。那么前面的stage就是&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，后面的stage就是&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;.因为前面会有shuffle操作，而后面是整个job的计算结果，所以叫ResultStage.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;是有一个函数，应用于rdd的一些partition来计算出这个action的结果。但有些action并不是在每个partition都执行的，比如&lt;code class=&quot;highlighter-rouge&quot;&gt;first()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;接下来介绍下这个函数的执行流程。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先是计算出 &lt;code class=&quot;highlighter-rouge&quot;&gt;paritionsToCompute&lt;/code&gt;，即用于计算的partition，数据。&lt;/li&gt;
  &lt;li&gt;然后就是&lt;code class=&quot;highlighter-rouge&quot;&gt;outputCommitCoordinator.stageStart&lt;/code&gt;,这个类是用来输出到hdfs上的，然后stageStart的两个参数，就是用于发出信息，两个参数分别是stageId和他要用于计算的partition数目。&lt;/li&gt;
  &lt;li&gt;然后就是计算这个stage用于计算的TaskId对应的task所在的location。因为TaskId和partitionId是对应的，所以也就是计算partitionId对应的taskLocation。然后taskLocation是一个host或者是一个（host,executorId）二元组。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)&lt;/code&gt;这里创建新的attempt 就是代表这个stage执行了几次。因为stage可能会失败的。如果失败就要接着执行，这个attempt从0开始。&lt;/li&gt;
  &lt;li&gt;然后就是创建广播变量，然后braocast。广播是用于executor来解析tasks。首先要序列化，给每个task都一个完整的rdd，这样可以让task独立性更强，这对于非线程安全是有必要的。对于ShuffleMapTask我们序列化的数据是&lt;code class=&quot;highlighter-rouge&quot;&gt;(rdd,shuffleDep)&lt;/code&gt;，对于resultTask,序列化数据为&lt;code class=&quot;highlighter-rouge&quot;&gt;(rdd,func)&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;然后是创建tasks，当然Tasks分为shuffleMapTask和resultTask，这都是跟stage类型对应的。这里创建tasks，需要用到一个参数&lt;code class=&quot;highlighter-rouge&quot;&gt;stage.latestInfo.attemptId&lt;/code&gt;,这里是前面提到的。&lt;/li&gt;
  &lt;li&gt;创建完tasks就是后面的&lt;code class=&quot;highlighter-rouge&quot;&gt;taskScheduler.submitTasks()&lt;/code&gt;，这样任务就交由taskScheduler调度了。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def submitTasks(taskSet: TaskSet) {
  val tasks = taskSet.tasks
  logInfo(&quot;Adding task set &quot; + taskSet.id + &quot; with &quot; + tasks.length + &quot; tasks&quot;)
  this.synchronized {
    val manager = createTaskSetManager(taskSet, maxTaskFailures)
    val stage = taskSet.stageId
    val stageTaskSets =
      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, new HashMap[Int, TaskSetManager])
    stageTaskSets(taskSet.stageAttemptId) = manager
    val conflictingTaskSet = stageTaskSets.exists { case (_, ts) =&amp;gt;
      ts.taskSet != taskSet &amp;amp;&amp;amp; !ts.isZombie
    }
    if (conflictingTaskSet) {
      throw new IllegalStateException(s&quot;more than one active taskSet for stage $stage:&quot; +
        s&quot; ${stageTaskSets.toSeq.map{_._2.taskSet.id}.mkString(&quot;,&quot;)}&quot;)
    }
    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)

    if (!isLocal &amp;amp;&amp;amp; !hasReceivedTask) {
      starvationTimer.scheduleAtFixedRate(new TimerTask() {
        override def run() {
          if (!hasLaunchedTask) {
            logWarning(&quot;Initial job has not accepted any resources; &quot; +
              &quot;check your cluster UI to ensure that workers are registered &quot; +
              &quot;and have sufficient resources&quot;)
          } else {
            this.cancel()
          }
        }
      }, STARVATION_TIMEOUT_MS, STARVATION_TIMEOUT_MS)
    }
    hasReceivedTask = true
  }
  backend.reviveOffers()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这段代码前面部分就是先创建taskManager，然后判断是否有超过一个数目的tasks存在，如果冲突就报异常。&lt;/p&gt;

&lt;p&gt;然后把这个TaskSetManager加入&lt;code class=&quot;highlighter-rouge&quot;&gt;schedulableBuilder&lt;/code&gt;，这个变量在初始化时候会选择调度策略，比如fifo啥的，加入之后就会按照相应的策略进行调度。&lt;/p&gt;

&lt;p&gt;然后之后的判断是否为本地，和是否已经接收过任务，&lt;code class=&quot;highlighter-rouge&quot;&gt;isLocal&lt;/code&gt;代表本地模式。如果非本地模式，而且还没接收到过任务，就会建立一个TimerTask，然后一直查看有没有接收到任务，因为如果没任务就是空转吗。&lt;/p&gt;

&lt;p&gt;最后backend就会让这个tasks唤醒。&lt;code class=&quot;highlighter-rouge&quot;&gt;backend.reviveOffers()&lt;/code&gt;,这里我们的backend通常是&lt;code class=&quot;highlighter-rouge&quot;&gt;CoarseGrainedSchedulerBackend&lt;/code&gt;，在执行reviveOffers之后，&lt;code class=&quot;highlighter-rouge&quot;&gt;driverEndpoint&lt;/code&gt;会send消息，然后backend的receive函数会接收到消息，然后执行操作。看CoarseGrainedSchedulerBackend 的receive函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive: PartialFunction[Any, Unit] = {
...
case ReviveOffers =&amp;gt;
  makeOffers()
...
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def makeOffers() {
  // Filter out executors under killing
  val activeExecutors = executorDataMap.filterKeys(executorIsAlive)
  val workOffers = activeExecutors.map { case (id, executorData) =&amp;gt;
    new WorkerOffer(id, executorData.executorHost, executorData.freeCores)
  }.toSeq
  launchTasks(scheduler.resourceOffers(workOffers))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面代码显示筛选出存活的&lt;code class=&quot;highlighter-rouge&quot;&gt;Executors&lt;/code&gt;，然后就创建出&lt;code class=&quot;highlighter-rouge&quot;&gt;workerOffers&lt;/code&gt;,参数是executorId,host,frescoers.&lt;/p&gt;

&lt;h3 id=&quot;执行task&quot;&gt;执行task&lt;/h3&gt;

&lt;p&gt;然后就launchTasks。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def launchTasks(tasks: Seq[Seq[TaskDescription]]) {
  for (task &amp;lt;- tasks.flatten) {
    val serializedTask = ser.serialize(task)
    if (serializedTask.limit &amp;gt;= maxRpcMessageSize) {
      scheduler.taskIdToTaskSetManager.get(task.taskId).foreach { taskSetMgr =&amp;gt;
        try {
          var msg = &quot;Serialized task %s:%d was %d bytes, which exceeds max allowed: &quot; +
            &quot;spark.rpc.message.maxSize (%d bytes). Consider increasing &quot; +
            &quot;spark.rpc.message.maxSize or using broadcast variables for large values.&quot;
          msg = msg.format(task.taskId, task.index, serializedTask.limit, maxRpcMessageSize)
          taskSetMgr.abort(msg)
        } catch {
          case e: Exception =&amp;gt; logError(&quot;Exception in error callback&quot;, e)
        }
      }
    }
    else {
      val executorData = executorDataMap(task.executorId)
      executorData.freeCores -= scheduler.CPUS_PER_TASK

      logInfo(s&quot;Launching task ${task.taskId} on executor id: ${task.executorId} hostname: &quot; +
        s&quot;${executorData.executorHost}.&quot;)

      executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask)))
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面的代码显示将task序列化，然后根据task.executorId 给他分配executor，然后就&lt;code class=&quot;highlighter-rouge&quot;&gt;executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask)))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这里有一个&lt;code class=&quot;highlighter-rouge&quot;&gt;executorEndPoint&lt;/code&gt;,之前前面有driverEndPoint(出现在backend.reviveOffer那里)，这两个端口的基类都是&lt;code class=&quot;highlighter-rouge&quot;&gt;RpcEndpointRef&lt;/code&gt;。RpcEndpointRef是RpcEndPoint的远程引用，是线程安全的。&lt;/p&gt;

&lt;p&gt;RpcEndpoint是 RPC[Remote Procedure Call ：远程过程调用]中定义了收到的消息将触发哪个方法。&lt;/p&gt;

&lt;p&gt;同时清楚的阐述了生命周期，构造-&amp;gt; onStart -&amp;gt; receive* -&amp;gt; onStop&lt;/p&gt;

&lt;p&gt;这里receive* 是指receive 和 receiveAndReply。&lt;/p&gt;

&lt;p&gt;他们的区别是：&lt;/p&gt;

&lt;p&gt;receive是无需等待答复，而receiveAndReply是会阻塞线程，直至有答复的。(参考：http://www.07net01.com/2016/04/1434116.html)&lt;/p&gt;

&lt;p&gt;然后这里的driverEndPoint就是代表这个信息会发给&lt;code class=&quot;highlighter-rouge&quot;&gt;CoarseGrainedSchedulerBackEnd&lt;/code&gt;，executorEndPoint就是发给&lt;code class=&quot;highlighter-rouge&quot;&gt;coarseGrainedExecutorBackEnd&lt;/code&gt;当然就是发给&lt;code class=&quot;highlighter-rouge&quot;&gt;coarseGrainedExecutorBackEnd&lt;/code&gt;。接下来去看相应的recieve代码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive: PartialFunction[Any, Unit] = {
...

    case LaunchTask(data) =&amp;gt;
      if (executor == null) {
        exitExecutor(1, &quot;Received LaunchTask command but executor was null&quot;)
      } else {
        val taskDesc = ser.deserialize[TaskDescription](data.value)
        logInfo(&quot;Got assigned task &quot; + taskDesc.taskId)
        executor.launchTask(this, taskId = taskDesc.taskId, attemptNumber = taskDesc.attemptNumber,
          taskDesc.name, taskDesc.serializedTask)
      }
...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里先将传过来的数据反序列化，然后&lt;code class=&quot;highlighter-rouge&quot;&gt;executor.launchTask&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def launchTask(
    context: ExecutorBackend,
    taskId: Long,
    attemptNumber: Int,
    taskName: String,
    serializedTask: ByteBuffer): Unit = {
  val tr = new TaskRunner(context, taskId = taskId, attemptNumber = attemptNumber, taskName,
    serializedTask)
  runningTasks.put(taskId, tr)
  threadPool.execute(tr)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里新建了taskRunner，然后之后交由线程池来运行，线程池既然要运行taskRunner，必定是运行taskRunner的run方法。看taskRunner的run方法，代码太长，懒得贴，大概描述下。&lt;/p&gt;

&lt;p&gt;主要就是设置参数，属性，反序列化出task等等，之后就要调用task.runTask方法。这里的task可能是&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;也可能是&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;，所以我们分别看这两种task的run方法。&lt;/p&gt;

&lt;h4 id=&quot;shufflemaptask&quot;&gt;ShuffleMapTask&lt;/h4&gt;

&lt;p&gt;先看&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def runTask(context: TaskContext): MapStatus = {
  // Deserialize the RDD using the broadcast variable.
  val deserializeStartTime = System.currentTimeMillis()
  val ser = SparkEnv.get.closureSerializer.newInstance()
  val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])](
    ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
  _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime

  var writer: ShuffleWriter[Any, Any] = null
  try {
    val manager = SparkEnv.get.shuffleManager
    writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context)
    writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &amp;lt;: Product2[Any, Any]]])
    writer.stop(success = true).get
  } catch {
    case e: Exception =&amp;gt;
      try {
        if (writer != null) {
          writer.stop(success = false)
        }
      } catch {
        case e: Exception =&amp;gt;
          log.debug(&quot;Could not stop writer&quot;, e)
      }
      throw e
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;前面部分代码就是反序列化那些，主要看中间的代码。获得shuffleManager,然后getWriter。因为shuffleMapTask有Shuffle操作，所以要shuffleWrite。&lt;/p&gt;

&lt;h4 id=&quot;resulttask&quot;&gt;ResultTask&lt;/h4&gt;

&lt;p&gt;看下ResultTask的runTask。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  override def runTask(context: TaskContext): U = {
    // Deserialize the RDD and the func using the broadcast variables.
    val deserializeStartTime = System.currentTimeMillis()
    val ser = SparkEnv.get.closureSerializer.newInstance()
    val (rdd, func) = ser.deserialize[(RDD[T], (TaskContext, Iterator[T]) =&amp;gt; U)](
      ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
    _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime

    func(context, rdd.iterator(partition, context))
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;跟那个差不多，只不过不是shuffleWrite，是func.&lt;/p&gt;

&lt;h4 id=&quot;rdd-迭代链&quot;&gt;rdd 迭代链&lt;/h4&gt;

&lt;p&gt;看这行代码&lt;code class=&quot;highlighter-rouge&quot;&gt;writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &amp;lt;: Product2[Any, Any]]])&lt;/code&gt;，看write方法里面的参数，rdd.iterator方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    getOrCompute(split, context)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个方法，是从后面的rdd开始迭代，首先判断这个rdd是否是已经被cache。&lt;/p&gt;

&lt;p&gt;如果已经被cache，getOrCompute，直接get，或者如果没找到就重算一遍，这个代码比较简单，我就不贴了。&lt;/p&gt;

&lt;p&gt;如果没有被cache，则调用&lt;code class=&quot;highlighter-rouge&quot;&gt;computeOrReadCheckpoint&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] =
{
  if (isCheckpointedAndMaterialized) {
    firstParent[T].iterator(split, context)
  } else {
    compute(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果是检查点，先介绍下检查点。&lt;/p&gt;

&lt;h4 id=&quot;检查点&quot;&gt;检查点&lt;/h4&gt;

&lt;p&gt;检查点机制的实现和持久化的实现有着较大的区别。检查点并非第一次计算就将结果进行存储，而是等到一个作业结束后启动专门的一个作业完成存储的操作。&lt;/p&gt;

&lt;p&gt;checkPoint操作的实现在RDD类中，&lt;em&gt;checkPoint&lt;/em&gt;方法会实例化ReliableRDDCheckpointData用于标记当前的RDD&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint
 * directory set with `SparkContext#setCheckpointDir` and all references to its parent
 * RDDs will be removed. This function must be called before any job has been
 * executed on this RDD. It is strongly recommended that this RDD is persisted in
 * memory, otherwise saving it on a file will require recomputation.
 */
def checkpoint(): Unit = RDDCheckpointData.synchronized {
  // NOTE: we use a global lock here due to complexities downstream with ensuring
  // children RDD partitions point to the correct parent partitions. In the future
  // we should revisit this consideration.
  if (context.checkpointDir.isEmpty) {
    throw new SparkException(&quot;Checkpoint directory has not been set in the SparkContext&quot;)
  } else if (checkpointData.isEmpty) {
    checkpointData = Some(new ReliableRDDCheckpointData(this))
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;RDDCheckpointData类内部有一个枚举类型 &lt;code class=&quot;highlighter-rouge&quot;&gt;CheckpointState &lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** 
 * Enumeration to manage state transitions of an RDD through checkpointing 
 * [ Initialized --&amp;gt; checkpointing in progress --&amp;gt; checkpointed ]. 
 */  
private[spark] object CheckpointState extends Enumeration {  
  type CheckpointState = Value  
  val Initialized, CheckpointingInProgress, Checkpointed = Value  
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;用于表示RDD检查点的当前状态，其值有Initialized 、CheckpointingInProgress、 checkpointed。其转换过程如下
(1)Initialized状态&lt;/p&gt;

&lt;p&gt;该状态是实例化ReliableRDDCheckpointData后的默认状态，用于标记当前的RDD已经建立了检查点(较v1.4.x少一个MarkForCheckPiont状态)&lt;/p&gt;

&lt;p&gt;(2)CheckpointingInProgress状态&lt;/p&gt;

&lt;p&gt;每个作业结束后都会对作业的末RDD调用其doCheckPoint方法，该方法会顺着RDD的关系依赖链往前遍历，直到遇见内部RDDCheckpointData对象被标记为Initialized的为止，此时将RDD的RDDCheckpointData对象标记为CheckpointingInProgress，并启动一个作业完成数据的写入操作。&lt;/p&gt;

&lt;p&gt;(3)Checkpointed状态&lt;/p&gt;

&lt;p&gt;新启动作业完成数据写入操作之后，将建立检查点的RDD的所有依赖全部清除，将RDD内部的RDDCheckpointData对象标记为Checkpointed，&lt;code class=&quot;highlighter-rouge&quot;&gt;将父RDD重新设置为一个CheckPointRDD对象，父RDD的compute方法会直接从系统中读取数据&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;如上只简单地介绍了相关概念，详细介绍请参看：&lt;a href=&quot;https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md&quot;&gt;https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;compute-链&quot;&gt;compute 链&lt;/h3&gt;
&lt;p&gt;上面有检查点的就直接去父Rdd的compute读取数据了。而非检查点，就compute，compute是一个链。
拿&lt;code class=&quot;highlighter-rouge&quot;&gt;MapPartitionsRDD&lt;/code&gt;举个例子，看看它的compute方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def compute(split: Partition, context: TaskContext): Iterator[U] =
f(context, split.index, firstParent[T].iterator(split, context))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看这里 compute还是调用了iterator，所以还是接着往前找了，直到找到checkpoint或者就是到rdd头。&lt;/p&gt;

&lt;p&gt;再看看其他的rdd的compute方法吧。&lt;/p&gt;

&lt;p&gt;看看&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleRdd&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def compute(split: Partition, context: TaskContext): Iterator[(K, C)] = {
  val dep = dependencies.head.asInstanceOf[ShuffleDependency[K, V, C]]
  SparkEnv.get.shuffleManager.getReader(dep.shuffleHandle, split.index, split.index + 1, context)
    .read()
    .asInstanceOf[Iterator[(K, C)]]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后这里shuffleRdd的compute方法就是从shuffle 那里read 数据，这算是一个stage的开始了。&lt;/p&gt;

&lt;p&gt;当然一个stage的开始未必是shuffleRead开始啦，比如textFile，它最终是返回一个HadoopRdd，然后他的compute方法，就是返回一个迭代器。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/jiangpeng59/article/details/53213694&quot;&gt;Spark核心RDD：计算函数compute&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/jiangpeng59/article/details/53212416&quot;&gt;Spark基础随笔：持久化&amp;amp;检查点&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>spark统一内存管理</title>
   <link href="http://turbofei.github.io/spark/2016/12/19/spark%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"/>
   <updated>2016-12-19T00:00:00+08:00</updated>
   <id>http://turbofei.github.io/spark/2016/12/19/spark统一内存管理</id>
   <content type="html">
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark统一内存管理是spark1.6.0的新特性，是对shuffle memory 和 storage memory 进行统一的管理，打破了以往的参数限制。&lt;/p&gt;

&lt;h2 id=&quot;非统一内存管理&quot;&gt;非统一内存管理&lt;/h2&gt;

&lt;p&gt;spark在1.6 之前都是非统一内存管理，通过设置&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.memoryFraction&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.storage.memoryFraction&lt;/code&gt;来设置shuffle 和storage的memory 大小。看下&lt;code class=&quot;highlighter-rouge&quot;&gt;StaticMemoryManager&lt;/code&gt;的获得最大shuffle和storage memory的函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def getMaxStorageMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
  val memoryFraction = conf.getDouble(&quot;spark.storage.memoryFraction&quot;, 0.6)
  val safetyFraction = conf.getDouble(&quot;spark.storage.safetyFraction&quot;, 0.9)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}

/**
 * Return the total amount of memory available for the execution region, in bytes.
 */
private def getMaxExecutionMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
...
  val memoryFraction = conf.getDouble(&quot;spark.shuffle.memoryFraction&quot;, 0.2)
  val safetyFraction = conf.getDouble(&quot;spark.shuffle.safetyFraction&quot;, 0.8)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;可以看出，&lt;code class=&quot;highlighter-rouge&quot;&gt;systemMaxMemory&lt;/code&gt;是通过参数&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.testing.memory&lt;/code&gt;来获得，如果这个参数没有设置，就取虚拟机内存，然后shuffle 和 storage都有安全系数，最后可用的最大内存都是：系统最大内存*比例系数*安全系数。&lt;/p&gt;

&lt;h2 id=&quot;统一内存管理&quot;&gt;统一内存管理&lt;/h2&gt;

&lt;p&gt;spark 1.6.0 出现了统一内存管理，是打破了shuffle 内存和storage内存的静态限制。通俗的描述，就是如果storage内存不够，而shuffle内存剩余就能借内存，如果shuffle内存不足，此时如果storage已经超出了&lt;code class=&quot;highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，那么就驱逐当前使用storage内存-&lt;code class=&quot;highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，如果storage 使用没有超过&lt;code class=&quot;highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，那么则把它剩余的都可以借给shuffle使用。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  private def getMaxMemory(conf: SparkConf): Long = {
    val systemMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
    val reservedMemory = conf.getLong(&quot;spark.testing.reservedMemory&quot;,
      if (conf.contains(&quot;spark.testing&quot;)) 0 else RESERVED_SYSTEM_MEMORY_BYTES)
    val minSystemMemory = (reservedMemory * 1.5).ceil.toLong
    if (systemMemory &amp;lt; minSystemMemory) {
      throw new IllegalArgumentException(s&quot;System memory $systemMemory must &quot; +
        s&quot;be at least $minSystemMemory. Please increase heap size using the --driver-memory &quot; +
        s&quot;option or spark.driver.memory in Spark configuration.&quot;)
    }
    // SPARK-12759 Check executor memory to fail fast if memory is insufficient
    if (conf.contains(&quot;spark.executor.memory&quot;)) {
      val executorMemory = conf.getSizeAsBytes(&quot;spark.executor.memory&quot;)
      if (executorMemory &amp;lt; minSystemMemory) {
        throw new IllegalArgumentException(s&quot;Executor memory $executorMemory must be at least &quot; +
          s&quot;$minSystemMemory. Please increase executor memory using the &quot; +
          s&quot;--executor-memory option or spark.executor.memory in Spark configuration.&quot;)
      }
    }
    val usableMemory = systemMemory - reservedMemory
    val memoryFraction = conf.getDouble(&quot;spark.memory.fraction&quot;, 0.6)
    (usableMemory * memoryFraction).toLong
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这个是统一内存管理的获得最大内存的函数，因为shuffle和storage是统一管理的，所以只有一个获得统一最大内存的函数。&lt;code class=&quot;highlighter-rouge&quot;&gt;usableMemory = systemMemory - reservedMemory&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;最大内存=&lt;code class=&quot;highlighter-rouge&quot;&gt;usableMemory * memoryFraction&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;统一内存管理的使用&quot;&gt;统一内存管理的使用&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UnifiedMemoryManager&lt;/code&gt;是在一个静态类里面的&lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt;方法调用的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def apply(conf: SparkConf, numCores: Int): UnifiedMemoryManager = {
  val maxMemory = getMaxMemory(conf)
  new UnifiedMemoryManager(
    conf,
    maxHeapMemory = maxMemory,
    onHeapStorageRegionSize =
      (maxMemory * conf.getDouble(&quot;spark.memory.storageFraction&quot;, 0.5)).toLong,
    numCores = numCores)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后通过 find Uages 找到是在 &lt;code class=&quot;highlighter-rouge&quot;&gt;sparkEnv&lt;/code&gt;里面调用。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val memoryManager: MemoryManager =
  if (useLegacyMemoryManager) {
    new StaticMemoryManager(conf, numUsableCores)
  } else {
    UnifiedMemoryManager(conf, numUsableCores)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;是通过判断参数，判断是使用统一内存管理还是非内存管理。&lt;/p&gt;

&lt;p&gt;然后通过查看usages 发现是在 &lt;code class=&quot;highlighter-rouge&quot;&gt;CoarseGrainedExecutorBackEnd&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;MesosExecutorBackEnd&lt;/code&gt;里面调用的，所以是每个executor都有一个统一内存管理的实例(…很显然，逻辑也是这样)。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>java unsafe类的使用</title>
   <link href="http://turbofei.github.io/coding/2016/11/13/java-unsafe%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8"/>
   <updated>2016-11-13T08:24:19+08:00</updated>
   <id>http://turbofei.github.io/coding/2016/11/13/java-unsafe类的使用</id>
   <content type="html">
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最近在写堆外操作的代码，需要用到unsafe 类，记录下。&lt;/p&gt;

&lt;h1 id=&quot;unsafe-简介&quot;&gt;unsafe 简介&lt;/h1&gt;

&lt;p&gt;unsafe类位于 sun.misc包,之所以叫unsafe是因为他操作堆外内存，即不受JVM控制的内存。由于最近要做点把数据存储在堆外的工作，所以了解了下unsafe。&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;下面是关于unsafe做测试的代码。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-JAVA&quot;&gt;import sun.misc.Unsafe;

import java.lang.reflect.Field;

/**
 * Created by bbw on 2016/11/11.
 */
class cat{
    public Integer name;
    public Integer age;
    public cat(Integer name,Integer age){
        this.name=name;
        this.age=age;
    }

}
public class testUnSafe {
    private static int apple = 10;
    private int orange = 10;
    private int banana=10;
    public   cat ki=new cat(233,3);

 //这是获得对象里面对象field的方法，根据这个对象在类里面的偏移量来获得
    public Object getObject(long offset) throws SecurityException, NoSuchFieldException, IllegalArgumentException,
            IllegalAccessException{
        return getUnsafeInstance().getObject(this,offset);
    }


    public static void main(String[] args) throws Exception {
        Unsafe unsafe = getUnsafeInstance();
        testUnSafe tus=new testUnSafe();

        Field appleField = testUnSafe.class.getDeclaredField(&quot;apple&quot;);
        // 获得field的偏移量
        System.out.println(&quot;Location of Apple: &quot; + unsafe.staticFieldOffset(appleField));

        Field orangeField = testUnSafe.class.getDeclaredField(&quot;orange&quot;);
        System.out.println(&quot;Location of Orange: &quot; + unsafe.objectFieldOffset(orangeField));



//这是field 是一个cat类的实例化对象，根据他的便宜地址获得对象，然后强制类型转化
        Field catField = testUnSafe.class.getDeclaredField(&quot;ki&quot;);
        System.out.println(&quot;Location of cat: &quot; + unsafe.objectFieldOffset(catField));
        long offset=unsafe.objectFieldOffset(catField);
        Object rki=tus.getObject(offset);
        cat rrki=(cat)rki;
        System.out.println(rrki.name);

        // follow is addressTest
        cat ncat=new cat(333,444);
        cat ncat2=new cat(555,666);
        cat[] ca={ncat,ncat2};
        long catArrayOffset=unsafe.arrayBaseOffset(cat[].class);
        System.out.println(catArrayOffset+&quot; &quot;+unsafe.arrayIndexScale(cat[].class));
        //cat rncat=((cat[])(tus.getObject(catArrayOffset)))[0];
       // System.out.println(rncat.name+rncat.age);
        Field bananaField = testUnSafe.class.getDeclaredField(&quot;banana&quot;);
        System.out.println(&quot;Location of banana: &quot; + unsafe.objectFieldOffset(bananaField));
    }
    
    //获得unsafe 的方法，是单例模式
    private static Unsafe getUnsafeInstance() throws SecurityException, NoSuchFieldException, IllegalArgumentException,
            IllegalAccessException {
        Field theUnsafeInstance = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
        theUnsafeInstance.setAccessible(true);
        return (Unsafe) theUnsafeInstance.get(Unsafe.class);
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;unsafe 是单例模式，所以全局就只有一个unsafe，必须用它提供的方法来获取。
然后里面有获得里面字段 和静态字段偏移地址的方法，偏移地址是相对于在这个对象里面的偏移地址，可以根据偏移地址获得这个field。
例如，我在这个类里面声明的 cat 类 field ，就可以根据它在对象里面偏移地址来取得这个类。&lt;/p&gt;

&lt;p&gt;至于如何获得方法里面变量的内存地址以及如何通过这个获得的内存地址来取得这个变量对象，我还不是很明白，只知道unsafe.arrayBaseOffset 来获得对象数据的偏移地址。&lt;/p&gt;

&lt;p&gt;下面是我写的一个静态类，可以用来实现unsafe的放置变量，并且可以把这块堆外内存里面存的数据转化为迭代器。
我是这样存数据的，首先是申请一块堆外内存，然后前四个字节存储这块内存的大小，然后紧接着四个字节存储已经使用的大小。然后存储数据的类型是从外部传进去的，0代表int,1代表long，2代表double。
然后每次在写入数据的时候，都会判断这块内存的大小够不够写入数据，如果不够就申请一个更大的内存，然后把原来的数据拷贝到新的内存里面，重新对这块内存的前八个字节赋值，即内存的大小和使用情况。
然后这个类的静态参数在每次传入内存的起始地址后会首先读取这块内存的前八个字节，获得内存大小以及使用情况。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-JAVA&quot;&gt;
package org.apache.spark.unsafe;
import java.util.Iterator;
/**
 * Created by bbw on 2016/11/14.
 */
public  final class UnsafeBuffer&amp;lt;T&amp;gt; {



    public  static int  MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    public static   int  hugeCapacity(int minCapacity) {
        if (minCapacity &amp;lt; 0) throw new OutOfMemoryError();
        if ((minCapacity &amp;gt; MAX_ARRAY_SIZE))
            return Integer.MAX_VALUE;
        else
            return MAX_ARRAY_SIZE;
        }


    public static long  copyBuf2New ( long baseAddress,int vType,int  minCapacity) {
        // read the size and count of this buf(the format size,count)
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);



        long address = PlatformDependent.UNSAFE.allocateMemory(minCapacity);
        // write the size and count

        PlatformDependent.UNSAFE.putInt(null,address,minCapacity);
        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount);


        int   i= 8;
        switch (vType) {
            case 0 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putInt(null, address + i, PlatformDependent.UNSAFE.getInt(null, baseAddress + i));
        i = i + 4;
        }
            case 1 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putLong(null, address + i, PlatformDependent.UNSAFE.getLong(null, baseAddress + i));
        i = i + 8;
        }
            case 2 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putDouble(null, address + i, PlatformDependent.UNSAFE.getDouble(null, baseAddress + i));
        i = i + 8;
        }
        default:
            assert (1==0);
        }
        return address;

        }


        public static long putInt(long baseAddress, int vType,int value){
            int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
            int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

           long address= ensureCapacity(baseAddress,vType,sizeCount+4);

            PlatformDependent.UNSAFE.putInt(null,address+sizeCount,value);

            PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+4);

            return address;


        }
    public static long putLong(long baseAddress, int vType,long value){
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

        long address= ensureCapacity(baseAddress,vType,sizeCount+8);

        PlatformDependent.UNSAFE.putLong(null,address+sizeCount,value);

        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+8);

        return address;


    }
    public static long putDouble(long baseAddress, int vType,double value){
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

        long address= ensureCapacity(baseAddress,vType,sizeCount+8);

        PlatformDependent.UNSAFE.putDouble(null,address+sizeCount,value);

        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+8);

        return address;


    }


public  static long grow (long  baseAddress,int vType,int minCapacity) {

    int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
    int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);
        int  oldCapacity=size;
        int  newCapacity = oldCapacity &amp;lt;&amp;lt; 1;
        if (newCapacity - minCapacity &amp;lt; 0) newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0) newCapacity = hugeCapacity(minCapacity);
        //buf = Arrays.copyOf(buf, newCapacity)
        //重新分配空间
        // baseAddress=PlatformDependent.UNSAFE.allocateMemory(newCapacity)
        long  temp=copyBuf2New(baseAddress,vType,minCapacity);
        PlatformDependent.UNSAFE.freeMemory(baseAddress);

    return temp;
}

    public static  long   ensureCapacity (long baseAddress,int vType,int minCapacity) {

    int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
    int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);


        if (minCapacity - size &amp;gt; 0)
           return grow(baseAddress,vType,minCapacity);
    else return baseAddress;
}




    public static   Iterator&amp;lt;Integer&amp;gt; intIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Integer&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Integer next() {
                offset += 4;
                return PlatformDependent.UNSAFE.getInt(null, address + offset - 4);
            }
        };
    }

    public static   Iterator&amp;lt;Long&amp;gt; longIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Long&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Long next() {
                offset += 8;
                return PlatformDependent.UNSAFE.getLong(null, address + offset - 8);
            }
        };
    }

    public static   Iterator&amp;lt;Double&amp;gt; doubleIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Double&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Double next() {
                offset += 8;
                return PlatformDependent.UNSAFE.getDouble(null, address + offset - 8);
            }
        };
    }


    public static  long createBuff(int size){
        long address=PlatformDependent.UNSAFE.allocateMemory(size);
        PlatformDependent.UNSAFE.putInt(null,address,size);
        PlatformDependent.UNSAFE.putInt(null,address+4,8);
        return address;
    }
}

&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>ganglia 安装</title>
   <link href="http://turbofei.github.io/bigdata/2016/08/17/ganglia-%E5%AE%89%E8%A3%85"/>
   <updated>2016-08-17T05:15:03+08:00</updated>
   <id>http://turbofei.github.io/bigdata/2016/08/17/ganglia-安装</id>
   <content type="html">
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最近帮大菠萝安装ganglia，记录下，方便以后安装。&lt;/p&gt;

&lt;h1 id=&quot;cluster-server-and-clients&quot;&gt;Cluster Server and Clients&lt;/h1&gt;

&lt;p&gt;I configured our nodes with the following hostnames using these steps. Our server is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3.buhpc.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The clients are:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.buhpc.com
2.buhpc.com
4.buhpc.com
5.buhpc.com
6.buhpc.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;!--more--&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation&lt;/h1&gt;

&lt;p&gt;On the server, inside the shared folder of our cluster, we will first download the latest version of ganglia. For our cluster, /nfs is the folder with our network file system.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /nfs
wget http://downloads.sourceforge.net/project/ganglia/ganglia%20monitoring%20core/3.7.2/ganglia-3.7.2.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;On the server, we will install dependencies and libconfuse.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install freetype-devel rpm-build php httpd libpng-devel libart_lgpl-devel python-devel pcre-devel autoconf automake libtool expat-devel rrdtool-devel apr-devel gcc-c++ make pkgconfig -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-2.7-7.el7.x86_64.rpm -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-devel-2.7-7.el7.x86_64.rpm -y

#建立rrd数据库
mkdir -p /var/lib/ganglia/rrds/
chown nobody:nobody -R /var/lib/ganglia/rrds/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now, we will build the rpms from ganglia-3.7.2 on the server.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rpmbuild -tb ganglia-3.7.2.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;After running rpmbuild, /root/rpmbuild/RPMS/x86_64 contains the generated rpms:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /root/rpmbuild/RPMS/x86_64/
yum install *ganglia*.rpm -y
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;We will remove gmetad because we do not need it on the clients. Send the rest of the rpms to all the clients’ /tmp folder:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /root/rpmbuild/RPMS/x86_64/
rm -rf ganglia-gmetad*.rpm
scp *.rpm root@1.buhpc.com:/tmp
scp *.rpm root@2.buhpc.com:/tmp
scp *.rpm root@4.buhpc.com:/tmp
scp *.rpm root@5.buhpc.com:/tmp
scp *.rpm root@6.buhpc.com:/tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;SSH onto every client and install the rpms that we will need:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh root@#.buhpc.com
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-2.7-7.el7.x86_64.rpm -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-devel-2.7-7.el7.x86_64.rpm -y
yum install /tmp/*ganglia*.rpm - y
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Back on the server, we will adjust the gmetad configuration file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /etc/ganglia
vim gmetad.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;buhpc will be the name of  our cluster. Find the following line and add the name of your cluster and ip address. I am using the subdomain instead of the ip address.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data_source &quot;buhpc&quot; 1 3.buhpc.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Now, we edit the server’s gmond configuration file.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/ganglia/gmond.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Make sure that these sections have the following and comment any extra lines you see that are within each section.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster {
  name = &quot;buhpc&quot;
  owner = &quot;unspecified&quot;
  latlong = &quot;unspecified&quot;
  url = &quot;unspecified&quot;
}

udp_send_channel {
  host = 1.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 2.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 3.buhpc.com
  port = 8649
  ttl = 1
}
udp_send_channel {
  host = 4.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 5.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 6.buhpc.com
  port = 8649
  ttl = 1
}

udp_recv_channel {
  port = 8649
  retry_bind = true
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Now, SSH into each of the clients and do the following individually. On every client:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/ganglia/gmond.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;We will change the clients’ gmond.conf in the same way as the server’s.  Make sure that these sections have the following lines and comment any extra lines you see that are within each section.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster {
  name = &quot;buhpc&quot;
  owner = &quot;unspecified&quot;
  latlong = &quot;unspecified&quot;
  url = &quot;unspecified&quot;
}

udp_send_channel {
  host = 1.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 2.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 3.buhpc.com
  port = 8649
  ttl = 1
}
udp_send_channel {
  host = 4.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 5.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 6.buhpc.com
  port = 8649
  ttl = 1
}

udp_recv_channel {
  port = 8649
  retry_bind = true
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;We will start gmond on the clients for monitoring.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chkconfig gmond on
systemctl start gmond
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后，安装ganglia-web 3.7.1&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget http://superb-sea2.dl.sourceforge.net/project/ganglia/ganglia-web/3.7.1/ganglia-web-3.7.1.tar.gz
tar zxvf  ganglia-web-3.7.1.tar.gz
cd  ganglia-web-3.7.1
vim Makefile
      # Location where gweb should be installed to (excluding conf, dwoo dirs).
      GDESTDIR = /var/www/html/ganglia

      # Gweb statedir (where conf dir and Dwoo templates dir are stored)
      GWEB_STATEDIR = /var/lib/ganglia-web

      # Gmetad rootdir (parent location of rrd folder)
      GMETAD_ROOTDIR = /var/lib/ganglia

      # User by which your webserver is running
      APACHE_USER =  apache

 make install
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Next, we will want to disable SELinux. Change SELINUX inside /etc/sysconfig/selinux from enforcing to disabled. Then, restart the server node.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/sysconfig/selinux
SELINUX=disabled
#如果 SELINUX本就是disable，不必reboot
reboot
Now, on the server, we’ll open the correct ports on the firewall.

#如果 firewall 没有打开，systemctl service firewalld
firewall-cmd --permanent --zone=public --add-service=http
firewall-cmd --permanent --zone=public --add-port=8649/udp
firewall-cmd --permanent --zone=public --add-port=8649/tcp
firewall-cmd --permanent --zone=public --add-port=8651/tcp
firewall-cmd --permanent --zone=public --add-port=8652/tcp
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;On the server, we will now start httpd, gmetad, and gmond.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chkconfig httpd
chkconfig gmetad on
chkconfig gmond on
systemctl start httpd
systemctl start gmetad
systemctl start gmond
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Visit http://3.buhpc.com/ganglia to see Ganglia’s monitoring. You should see something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.slothparadise.com/wp-content/uploads/2016/03/ganglia-home-page.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 
</feed>
