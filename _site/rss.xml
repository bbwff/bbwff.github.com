<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
        <title>turboFei's blog</title>
        <description>turboFei's blog - feiwang</description>
        <link>http://turbofei.github.io</link>
        <link>http://turbofei.github.io</link>
        <lastBuildDate>2019-05-19T14:32:55+08:00</lastBuildDate>
        <pubDate>2019-05-19T14:32:55+08:00</pubDate>
        <ttl>1800</ttl>


        <item>
                <title>Scala Concurrent Programming: Future And Thread</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#java-future&quot; id=&quot;markdown-toc-java-future&quot;&gt;Java Future&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#scala-future&quot; id=&quot;markdown-toc-scala-future&quot;&gt;Scala Future&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thread&quot; id=&quot;markdown-toc-thread&quot;&gt;Thread&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#thread状态&quot; id=&quot;markdown-toc-thread状态&quot;&gt;Thread状态&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#thread-方法解析&quot; id=&quot;markdown-toc-thread-方法解析&quot;&gt;Thread 方法解析&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;简单写下scala中的Future以及对Thread的认识&lt;/p&gt;

&lt;p&gt;java和scala中都有Future，那么这两个Future有什么不同呢？Thread是怎么样的，它的状态是如何变化的呢？一些操作比如sleep会涉及到锁么？&lt;/p&gt;

&lt;h3 id=&quot;java-future&quot;&gt;Java Future&lt;/h3&gt;

&lt;p&gt;java中Future类中方法很简单，也很少.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cancel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mayInterruptIfRunning&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isCancelled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InterruptedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExecutionException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timeout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimeUnit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;InterruptedException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ExecutionException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TimeoutException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;比较常用的就是get，可以设置超时时间。下面是使用java Future的一个场景，通常是使用线程池submit Callable。记得线程池要放在finally模块关闭。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testJavaFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Executors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newFixedThreadPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TimeUnit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SECONDS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;scala-future&quot;&gt;Scala Future&lt;/h3&gt;

&lt;p&gt;相较于java的Future，scala的Future中方法很丰富。而且scala中伴生对象的apply方法使得创建一个Future非常方便.例如:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;s&quot;&gt;&quot; future!&quot;&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;介绍其中几个方法，用法写在注释中，println结果也在注释中。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.collection.generic.CanBuildFrom&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.duration.Duration&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.Success&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.control.NonFatal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestScalaFuture&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executionContext&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFutureWithFailure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * recover方法是在Future发生异常时的处理。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testRecover&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFutureWithFailure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recover&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// -1
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 将两个Future zip到一起，这样就只需要使用一个Await就可以等结果。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testZip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// (1,2)
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 功能类似于zip，是处理更多个，需要指定CanBuildFrom。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testSequence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cbf&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implicitly&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;CanBuildFrom&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;\t&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 1 2 3
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cm&quot;&gt;/**
   * 这里的map， flatMap等操作是对返回值进行的操作，也是lazy的。
   * 这里的andThen不会改变返回值。
   * Transform是对返回值进行的操作，以及对异常的转换。
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testMisc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 8
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;andThen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;the value is 2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 这里只是执行一些操作，但是不会改变Future的返回值
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 2
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;createIntFuture&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;str:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NonFatal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throwable&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;})&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;10s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// str:3
&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;thread&quot;&gt;Thread&lt;/h3&gt;

&lt;p&gt;Thread类实现了Runnable，是一个特殊的Runnable类。&lt;/p&gt;

&lt;p&gt;一个线程代表一个程序的执行。jvm允许一个应用并发执行多个线程。每个线程都有一个优先级，优先级高的线程相对于优先级低的线程，更容易被执行。每个线程都可能被标记为一个守护(daemon)线程。当一个线程创建了一个新的线程，这个新的线程的优先级初始化为和创建它的线程一样。&lt;/p&gt;

&lt;p&gt;当一个JVM 启动时，通常是只有一个非守护线程。JVM会一直运行直到:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;exit方法被调用，并且允许exit。&lt;/li&gt;
  &lt;li&gt;所有非守护线程都已经结束，可以是正常返回结束也可以是异常结束。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有两种方法生成一个新的执行线程。&lt;/p&gt;

&lt;p&gt;一种是继承Thread类，overwrite run方法，然后start。&lt;/p&gt;

&lt;p&gt;另一种是继承&lt;code class=&quot;highlighter-rouge&quot;&gt;Runnable&lt;/code&gt;类，实现run方法，然后 &lt;code class=&quot;highlighter-rouge&quot;&gt;new Thread(runnable).start.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;线程的优先级分为1，5，10。1是所允许的最低优先级，5是默认分配，10是能够拥有的最高优先级。&lt;/p&gt;

&lt;p&gt;Thread类里面提供了一些静态工具方法. &lt;strong&gt;Deprecated&lt;/strong&gt;的方法不再列出.&lt;/p&gt;

&lt;h4 id=&quot;thread状态&quot;&gt;Thread状态&lt;/h4&gt;

&lt;p&gt;首先，thread的五种状态.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;NEW 线程被创建，还没start&lt;/li&gt;
  &lt;li&gt;RUNNABLE  在JVM上运行，可能在等操作系统的资源，比如时间片&lt;/li&gt;
  &lt;li&gt;BLOCKED 阻塞状态，等待lock来进入同步代码块&lt;/li&gt;
  &lt;li&gt;WAITING
    &lt;ul&gt;
      &lt;li&gt;Object.wait 没有指定timeout&lt;/li&gt;
      &lt;li&gt;因为Thread.join 无timeout等待&lt;/li&gt;
      &lt;li&gt;LockSupport.park()无限期等待&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TIMED_WAITING  有timeout的WAITING
    &lt;ul&gt;
      &lt;li&gt;Object.wait(long)&lt;/li&gt;
      &lt;li&gt;Thread.join(long)&lt;/li&gt;
      &lt;li&gt;LockSupport.parkNanos LockSupport.parkUntil&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TREMINATED  线程退出&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;thread-方法解析&quot;&gt;Thread 方法解析&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;yield&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;yield方法是给调度器一个hint表明自己自愿放弃当前的处理器，调度器可以忽略这个hint。这个方法不推荐，很少使用，可以用于避免cpu过度利用，但是使用之前要做好详细的分析与benchmark。spark项目中没有用到过yield.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;sleep&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;sleep方法比较常用，这是将当前线程放弃执行，休眠一段时间，但是sleep不会放弃自己得到的monitor.&lt;/p&gt;

&lt;p&gt;sleep(0)的意思代表是，大家所有线程重新抢占一下处理器。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;threadGroup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在创建thread时候可以传入threadGroup参数。如果没有传入group，如果该线程指定了securityManager，则去问securityManager拿group，最终是拿currentThread的group，如果没指定securityManager，则和父线程一组。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;start&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;开始运行线程，jvm调用run()方法。一个线程只能启动一次，否则会报IllegalThreadStateException。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;run&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实现的Runnable的run方法，用于让jvm调用&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;interrupt&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如果是线程自己interrupt自己，是允许的，否则，需要securityManager进行checkAccess，可能会抛出SecurityException。&lt;/p&gt;

&lt;p&gt;interrupt之后会加一个标志位interrupted.&lt;/p&gt;

&lt;p&gt;如果此时该线程被 wait, join, sleep, 那么这个interrupted标志位会被清除然后抛出InterruptedException.&lt;/p&gt;

&lt;p&gt;如果线程被&lt;code class=&quot;highlighter-rouge&quot;&gt;java.nio.channels.InterruptibleChannel&lt;/code&gt;的I/O操作阻塞，那么这个channel将被关闭，然后set interrupted标志位，这个线程会收到一个&lt;code class=&quot;highlighter-rouge&quot;&gt;ClosedByInterruptException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;如果线程被&lt;code class=&quot;highlighter-rouge&quot;&gt;java.nio.channels.Selector&lt;/code&gt;阻塞，那么将会设置interrupted标志位，并马上从selection操作返回。&lt;/p&gt;

&lt;p&gt;如果上述情况都没发生，那么这个线程设置interrup状态标志位.&lt;/p&gt;

&lt;p&gt;如果线程已经dead，interrupt操作没丝毫作用，也不会出错。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isInterrupted&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;查看是否被设为interrupted.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setPriority&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;改变线程的优先级。首先会由securityManager进行校验，校验失败抛SecurityException. 校验成功，则取设置的值和当前threadGroup的最大权限中的较小值，作为线程的优先级。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getPriority&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程优先级.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setName, getName&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设置线程名字，获取线程名字&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getThreadGroup&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程的threadGroup&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;activeCount&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得当前线程的threadGroup以及subGroup中的线程数.由于线程在动态变化，因此只是一个估计值，主要是用于debug以及monitoring.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;join(time)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;等待线程结束，如果join(0)代表一直等待。如果该线程被其他thread interrupt，那么这个线程的interrupted标志位被清除，然后抛出&lt;code class=&quot;highlighter-rouge&quot;&gt;InterruptedException&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;dumpStack&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;打印当前线程的栈，只用于&lt;strong&gt;debug&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;setDaemon(isDaemon)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;设为守护线程或者用户线程。JVM会在所有用户线程都挂掉之后退出。&lt;/p&gt;

&lt;p&gt;必须在线程启动之前设置，如果线程已经是alive，会抛&lt;code class=&quot;highlighter-rouge&quot;&gt;IllegalThreadStateException&lt;/code&gt;.同样也会检查SecurityManager当前线程是否有权限去设置。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;isDaemon&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是否是守护线程&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;checkAccess&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;检查当前线程有没有权限去修改这个线程。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getContextClassLoader, setContextClassLoader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;classLoader是用于加载classes和resources。默认的classLoader是父线程的classLoader。原始的线程classLoader通常是设置为应用的classLoader。如果classLoader不为空， 且securityManager不为空，将会进行权限校验。&lt;strong&gt;权限校验几乎伴随thread的每个操作&lt;/strong&gt;，后面就不再提了.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;holdsLock(Object obj)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线程是否持有某个monitor.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getStackTrace, getAllStackTraces&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个是打印当前线程的stack，一个是所有线程的stack，用户debug&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getId&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程Id&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;getState&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;获得线程状态&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UncaughtExceptionHandler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;是一个接口，用于当线程由于一些未捕获的异常而导致终止时的处理。&lt;/p&gt;

&lt;p&gt;里面只有一个方法.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;uncaughtException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;get(set)DefaultUncaughtExceptionHandler, get(set)UncaughtExceptionHandler&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;关于设置UncaughtExceptionHandler。ThreadGroup是UncaughtExceptionHandler的一个实现类，如果当前thread没有设置UncaughtExceptionHandler，那么返回threadGroup。&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/coding/2019/05/19/scala-concurrent-programming-Future-And-Thread</link>
                <guid>http://turbofei.github.io/coding/2019/05/19/scala-concurrent-programming:-Future-And-Thread</guid>
                <pubDate>2019-05-19T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>My Contribution To Apache Spark</title>
                <description>
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-27637&quot; id=&quot;markdown-toc-spark-27637&quot;&gt;SPARK-27637&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#description&quot; id=&quot;markdown-toc-description&quot;&gt;Description&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#solution&quot; id=&quot;markdown-toc-solution&quot;&gt;Solution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#link&quot; id=&quot;markdown-toc-link&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-27562in-progress&quot; id=&quot;markdown-toc-spark-27562in-progress&quot;&gt;SPARK-27562(In Progress)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#description-1&quot; id=&quot;markdown-toc-description-1&quot;&gt;Description&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#solution-1&quot; id=&quot;markdown-toc-solution-1&quot;&gt;Solution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#link-1&quot; id=&quot;markdown-toc-link-1&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-27716in-progress&quot; id=&quot;markdown-toc-spark-27716in-progress&quot;&gt;SPARK-27716(In Progress)&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#description-2&quot; id=&quot;markdown-toc-description-2&quot;&gt;Description&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#solution-2&quot; id=&quot;markdown-toc-solution-2&quot;&gt;Solution&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#link-2&quot; id=&quot;markdown-toc-link-2&quot;&gt;Link&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#to-be-continued&quot; id=&quot;markdown-toc-to-be-continued&quot;&gt;To Be Continued~&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;简单记录一下对spark的PR。Slowly, but always forward~&lt;/p&gt;

&lt;h3 id=&quot;spark-27637&quot;&gt;SPARK-27637&lt;/h3&gt;

&lt;h4 id=&quot;description&quot;&gt;Description&lt;/h4&gt;

&lt;p&gt;在spark中有两种shuffle client，自带的blockTransferService和externalShuffleClient。&lt;/p&gt;

&lt;p&gt;如果spark.shuffle.service.enabled=true,那么spark使用external shuffle client进行拉取shuffle block data，使用 nettyBlockTransferService进行拉取broadcast block data。&lt;/p&gt;

&lt;p&gt;如果spark.shuffle.service.enabled=false，那么shuffle block data 和broadcast block data 都由nettyBlockTransterService进行拉取。&lt;/p&gt;

&lt;p&gt;ExternalShuffleService(ESS)是一个shuffle服务，它可以忽视executor是否存活，保管executor的shuffle数据，就算executor是dead，也可以去ESS去取数据，因此在开启ESS情况下，是可以回收executor的，因此，如果要使用动态分配executor，必须开启ESS。&lt;/p&gt;

&lt;p&gt;而如果不使用ESS，那么就需要spark的executor自己去管理shuffle 数据，因此取shuffle数据就是通过直接连接BlockManager的ip:port进行。&lt;/p&gt;

&lt;p&gt;Broadcast数据是首先executor会访问其他executor去取，如果无法取到，则去向driver进行请求，由于这些broadcast数据必定是由executor管理，而不能委托给ESS，因此必须需要使用nettyBlockTransferService,无论ESS是否开启。&lt;/p&gt;

&lt;p&gt;在spark.shuffle.service.enabled=true且spark.executor.dynamicAllocation.enabled=true 时，由于executor可以被动态回收；如果在取broadcast数据的时候成功连接对应的executor，但是在开始取数据时候，executor被回收掉，那么必然造成取数据的失败。&lt;/p&gt;

&lt;p&gt;Spark中有一个RetryingBlockFetcher，如果在连接失败之后，会抛出java.io.IOException，之后会进行校验是否shouldRetry。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shouldRetry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isIOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCause&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getCause&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IOException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasRemainingRetries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;retryCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxRetries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;isIOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hasRemainingRetries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出这里只是判断是否是IOException并且还有剩余的重试此处，如果满足，就进行重试，之后也是必然的失败。如果这里设置的最大重试为10次，超时为30s，那么这里将会浪费掉五分钟的时间。因此，这里的校验是不合理的。&lt;/p&gt;

&lt;h4 id=&quot;solution&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;解决方案很简单，简单描述一下：&lt;/p&gt;

&lt;p&gt;在超时之后，如果是IOException，则向driverEndPoint发送rpc请求，判断这个executor是否存活。如果executor已经dead，则抛出ExecutorDeadException, 这就会造成 shouldRetry为false(因为isIOException == false). 核心代码如下: 具体参考PR.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;         &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OneForOneBlockFetcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;appId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blockIds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listener&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;transportConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tempFileManager&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;IOException&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
              &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;driverEndPointRef&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;askSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;IsExecutorAlive&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;execId&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutorDeadException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;The relative remote executor(Id: $execId), &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                  &lt;span class=&quot;s&quot;&gt;&quot;which maintains the block data to fetch is dead.&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Ps: 感谢社区大佬对我代码的review，非常佩服他们的代码功力，受益匪浅.&lt;/p&gt;

&lt;h4 id=&quot;link&quot;&gt;Link&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27637&quot;&gt;ISSUE SPARK-27637&lt;/a&gt;
&lt;a href=&quot;https://github.com/apache/spark/pull/24533&quot;&gt;PR SPARK-27637&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-27562in-progress&quot;&gt;SPARK-27562(In Progress)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;这个PR应该是改动太多了，不太好review，所以没有committer进行review，但是个人认为这个PR非常有意义。特别是针对之后的RemoteShuffleService(一个用于计算存储分离架构的ExternalShuffleService).&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&quot;description-1&quot;&gt;Description&lt;/h4&gt;

&lt;p&gt;参考&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-4105&quot;&gt;ISSUE SPARK-4105&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;shuffle是spark应用中一个重要的操作。 shuffle是map端的数据进行重新分区，然后reduce端去拉取每个map端对应的分区数据。因此在shuffle过程中，数据会进行网络传输。而网络传输面临着数据传输出错的风险，spark本身有一种校验shuffle传输数据的机制。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;SPARK-26089 对应PR&lt;/a&gt;合入之前的校验机制&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个机制是当shuffle数据有压缩编码，比如snappy，lz4时，判断shuffle数据的大小，如果数据大小小于一个阈值，比如16m，则对这个数据进行校验，校验方法为将数据输入流，拷贝到输出流再转为输入流，如果在流拷贝中没有出错，则表示数据没有损坏。&lt;/p&gt;

&lt;p&gt;但是这个校验机制存在一定的限制：&lt;/p&gt;

&lt;p&gt;1、 非压缩的数据无法校验（非压缩数据也存在传输出错风险）&lt;/p&gt;

&lt;p&gt;2、shuffle数据超过阈值则无法校验&lt;/p&gt;

&lt;p&gt;3、流拷贝消耗内存&lt;/p&gt;

&lt;p&gt;因此，目前的校验机制存在shuffle数据传输出错，导致shuffle read 端task由于数据出错造成任务出错的风险。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;在&lt;a href=&quot;https://github.com/apache/spark/pull/23453&quot;&gt;SPARK-26089 对应PR&lt;/a&gt;合入之后的校验机制&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这个PR对shuffle校验机制进行了一些优化：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;针对大的shuffle block会校验开头的部分数据，如果没出错，则通过校验，进入执行阶段&lt;/li&gt;
  &lt;li&gt;不再采用流拷贝操作，不会浪费内存。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是也存在一些问题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;如果大的shuffle block中间的数据出错，依然会造成task出错，而无法重新fetch&lt;/li&gt;
  &lt;li&gt;依然不会对未使用codec的数据进行校验。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;solution-1&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;首先，我们选取crc作为我们的校验方式，crc同时也是hadoop使用的通信校验方式，它简单且快速。这也是我们对比了其他校验方式，例如md5， sha系列算法之后的结果。&lt;/p&gt;

&lt;p&gt;在shuffle write阶段，我们在获得 mapTask对应的partitionedFile之后，根据索引，计算出每个分区的crc值，然后跟随各个分区的长度索引，一起写入到shuffle.index文件中。关于shuffle的机制可以参考&lt;a href=&quot;/spark/2016/12/26/spark源码分析Shuffle实现&quot;&gt;我之前的文章，shuffle源码分析&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;spark 的shuffle writer分为三种，bypassShuffleWriter， SortShuffleWriter以及UnsafeShuffleWriter。其中bypassShuffleWriter是在reducer的数量小于阈值(默认200)时候使用，他的特点是每个mapTask创建reducerNum个shuffle文件，所以需要在reducer个数小时使用，否则会造成很多小文件。&lt;/p&gt;

&lt;p&gt;而SortShuffleWriter和UnsafeShuffleWriter都是只创建一个PartitionedFile。所以在根据每个partition长度进行计算crc值时是很快的。&lt;/p&gt;

&lt;p&gt;之后我们将计算好的crc值与partition index一起写入shuffle 索引文件。&lt;/p&gt;

&lt;p&gt;在之后fetchBlock时，我们将每个partition的crc值随数据一起发送， 然后在shuffle read端，对拉取到的数据进行重新计算crc值，与原来的crc进行比对，如果相同，则数据不存在问题。&lt;/p&gt;

&lt;p&gt;在shuffle read端，数据一般都是在内存中，计算crc是很快的，在计算完之后，对这个内存中的inputStream进行reset操作，就可以重新进行后面的执行操作，如果数据是落在磁盘中，则代表数据较大，  crc的计算效率是经过实战考验的，我们也做了相应测试，由于文件创建的inputStream不支持reset操作，我们在计算完crc值之后，重新根据文件创建inputStream.&lt;/p&gt;

&lt;p&gt;这一套方案可以校验所有的数据，不论他是否进行压缩，是否太大， 都可以很好的计算，并且经过我们的是，性能没有下降。&lt;/p&gt;

&lt;p&gt;具体还有其他细节:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;原来的indexFile是写partitionNum+1 个long值，长度为8的倍数，crc值也是long值，我们加入一个1位的标志位，来区别是否进行了crc计算。&lt;/li&gt;
  &lt;li&gt;在写crc时的一致性保证。&lt;/li&gt;
  &lt;li&gt;在shuffle read端在发现crc值与原来的crc不同时的处理等等。&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;link-1&quot;&gt;Link&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27562&quot;&gt;ISSUE SPARK-27562&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/24447&quot;&gt;PR SPARK-27562&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-27716in-progress&quot;&gt;SPARK-27716(In Progress)&lt;/h3&gt;

&lt;h4 id=&quot;description-2&quot;&gt;Description&lt;/h4&gt;

&lt;p&gt;使用jdbc 的DataSource，我们可以将一个RDD保存到database中。比如mysql，greenplum。&lt;/p&gt;

&lt;p&gt;这些操作的主要逻辑由&lt;code class=&quot;highlighter-rouge&quot;&gt;JdbcUtils&lt;/code&gt;中的&lt;code class=&quot;highlighter-rouge&quot;&gt;saveTable&lt;/code&gt;函数完成,该函数的注释如下.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  /**
   * Saves the RDD to the database in a single transaction.
   */
  def saveTable(
      df: DataFrame,
      tableSchema: Option[StructType],
      isCaseSensitive: Boolean,
      options: JdbcOptionsInWrite)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;事实上这个注释的描述是错的，注释中说saveTable操作是在单个事务中完成。&lt;/p&gt;

&lt;p&gt;其实saveTable是调用savePartition操作来将每个分区的数据保存在数据库中，而savePartition的操作是在单个事务完成，而针对整体的saveTable却并不是单个事务。&lt;/p&gt;

&lt;p&gt;可能会存在某个分区出错，但是saveTable却处于一个中间状态的情况，这不符合事务的要求。&lt;/p&gt;

&lt;p&gt;在使用jdbc的数据传输操作可以分为以下几种。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;case1: append数据到一个已经存在的表中。&lt;/li&gt;
  &lt;li&gt;case2：overwrite一张表，但是这个表是级联表，如果将这个表drop会牵连到其他的表，因此只能将这个表清空，再append数据。&lt;/li&gt;
  &lt;li&gt;case3：overwrite一张表，该表存在且不是级联表，因此可以先drop表。&lt;/li&gt;
  &lt;li&gt;case4：要保存的表不存在。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在这个PR中，我对case3和case4进行了事务支持。&lt;/p&gt;

&lt;h4 id=&quot;solution-2&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;针对case3和case4，我们可以先将数据保存到一个临时表中。&lt;/p&gt;

&lt;p&gt;我们使用一个累加器来记录成功savePartition的分区数。累加器是spark中的一个分布式的计数器。&lt;/p&gt;

&lt;p&gt;来每个分区都执行savePartition之后，我们拿累加器的值和分区的数目做比较，如果所有分区都成功的savePartition，那么我们可以在driver上面drop destination table if exists,然后对临时表做rename操作，将其rename到最终的表。&lt;/p&gt;

&lt;p&gt;由于drop table 和rename table 都是原子操作，所以我们可以保证case3和case4是在单事务进行。&lt;/p&gt;

&lt;p&gt;如果有分区savePartition失败，那么我们将在driver端抛出一个分区失败的异常，提醒user。&lt;/p&gt;

&lt;p&gt;在finally模块，我们将会进行删除临时表的操作，最大重试次数为三次，确保不会产生一些垃圾数据。&lt;/p&gt;

&lt;h4 id=&quot;link-2&quot;&gt;Link&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/apache/spark/pull/24610&quot;&gt;PR SPARK-27716&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/SPARK-27716&quot;&gt;ISSUE SPARK-27716&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;to-be-continued&quot;&gt;To Be Continued~&lt;/h3&gt;
</description>
                <link>http://turbofei.github.io/spark/2019/05/18/my-contribution-to-apache-spark</link>
                <guid>http://turbofei.github.io/spark/2019/05/18/my-contribution-to-apache-spark</guid>
                <pubDate>2019-05-18T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Scala Concurrent Programing: Promise And Forkjoinpool</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#promise&quot; id=&quot;markdown-toc-promise&quot;&gt;Promise&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#nonfatal--controlthrowable&quot; id=&quot;markdown-toc-nonfatal--controlthrowable&quot;&gt;Nonfatal &amp;amp; ControlThrowable&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#try&quot; id=&quot;markdown-toc-try&quot;&gt;Try&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#forkjoinpool&quot; id=&quot;markdown-toc-forkjoinpool&quot;&gt;ForkJoinPool&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#work-steamling机制&quot; id=&quot;markdown-toc-work-steamling机制&quot;&gt;work-steamling机制&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;关于并发编程的一些总结与思考，包括promise, forkJoinPool, and etc.
在使用scala进行并发编程时，常用的一个就是Promise，Promise和Future是相关的。在生产中，Promise往往和Thread结合一起用，在一个线程中去执行Promise.trySuccess.提到线程就不得不提线程池，而ForkJoinPool是一个特殊的线程池，它比较适合计算密集型的场景。&lt;/p&gt;

&lt;h3 id=&quot;promise&quot;&gt;Promise&lt;/h3&gt;

&lt;p&gt;Promise是scala中独有的，java中没有。中文意思就是承诺，它可以在获得承诺的value时成功结束，也可以在遇到异常时失败。
一个Promise只能承诺一次，如果它已经完成承诺，或者失败，或者超时，再对它进行调用就会抛出IllegalStateException。在promize中有很多方法,如下&lt;/p&gt;
&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tryFailureWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryFailure&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;isCompleted&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;，&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这些方法有所不同，例如complete系列(包括tryComplete， tryCompleteWith)是可以返回值，也可以是异常的。&lt;/p&gt;

&lt;p&gt;而failure系列只能是异常，而success系列智能是返回value。因此，complete系列更像是一个对后两者的并集。&lt;/p&gt;

&lt;p&gt;在使用中，我们可以按照自己的需求去选择这些方法。&lt;/p&gt;

&lt;p&gt;比如我们可以直接使用complete系列将所有系列包容，也可以使用trySuccess 然后在捕获异常之后，将异常直接给failure方法。&lt;/p&gt;

&lt;p&gt;isComplete是用于判断Promise是否已经完成，而future是一个包含Promise结果的Future。&lt;/p&gt;

&lt;p&gt;我们通常将Promise和Await一起用。如果Promise在执行中出现了异常，Await是可以将其抛出，而如果Promise没有在规定时间内返回，那么将会抛出TimeoutException.&lt;/p&gt;

&lt;p&gt;例子如下:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.duration.Duration&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.Try&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scala.util.control.NonFatal&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestPromise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;cm&quot;&gt;/**
     * 此处是为了校验超时异常
     * 以及执行中异常.
     */&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Thread.sleep(13000)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// throw new Exception(&quot;this is an exception&quot;)
&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trySuccess&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;NonFatal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//            promisedLong.tryFailure(e)
&lt;/span&gt;        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;nc&quot;&gt;ExecutionContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test promise&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tryCompleteWith&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tryComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Await&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;promisedLong&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Duration&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;12s&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;nonfatal--controlthrowable&quot;&gt;Nonfatal &amp;amp; ControlThrowable&lt;/h4&gt;

&lt;p&gt;上面的例子中提到了Nonfatal，这在生产中是一个常用的类。&lt;/p&gt;

&lt;p&gt;顾名思义，Nonfatal代表非致命的，方法体也很短.&lt;/p&gt;

&lt;p&gt;可以看出致命的错误有，虚拟机Error，ThreadDeath，中断异常，链接Error，以及&lt;code class=&quot;highlighter-rouge&quot;&gt;ControlThrowable&lt;/code&gt;。除了这几种，其他都是非致命的。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NonFatal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
   &lt;span class=&quot;cm&quot;&gt;/**
    * Returns true if the provided `Throwable` is to be considered non-fatal, or false if it is to be considered fatal
    */&lt;/span&gt;
   &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;c1&quot;&gt;// VirtualMachineError includes OutOfMemoryError and other fatal errors
&lt;/span&gt;     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;VirtualMachineError&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ThreadDeath&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LinkageError&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ControlThrowable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;cm&quot;&gt;/**
   * Returns Some(t) if NonFatal(t) == true, otherwise None
   */&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unapply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Throwable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;一般在程序中，都是对Nonfatal进行catch处理， 而致命的就不catch了。&lt;/p&gt;

&lt;p&gt;那么什么是&lt;code class=&quot;highlighter-rouge&quot;&gt;ControlThrowable&lt;/code&gt;呢？&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ControlThrowable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Throwable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NoStackTrace&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到它继承了NoStackTrace类，也就是说这个异常栈是不能打印的。ControlThrowable代表这个Throwable是被放在控制流中。因为这个异常时作为控制流异常（比如BreadControl等等）， 因此发生这种异常，需要propagate，而不能catch，不过这一切都被封装在了Nonfatal，我们在编程中只要判断Nonfatal就可以。&lt;/p&gt;

&lt;h4 id=&quot;try&quot;&gt;Try&lt;/h4&gt;

&lt;p&gt;关于Try，它和try catch中的try不同，它代表执行一个程序块，通常和match，以及Success， Failure一起使用。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testTry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//      throw new Exception(&quot;this is an exception&quot;)
&lt;/span&gt;      &lt;span class=&quot;mi&quot;&gt;123L&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Success&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Failure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getMessage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;forkjoinpool&quot;&gt;ForkJoinPool&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;其实看源码中注释是理解源码最好的方式。&lt;/strong&gt;
ForkJoinPool是一个用于运行ForkJoinTask的线程池. ForkJoinPool和其他的ExecutorService不同，他有一套work-窃取机制，每个线程都可以尝试去find和执行pool中或者其他task提交的任务，这样就可以更加高效，因为每个线程的执行都不是限制死的，如果它空闲了就可以去窃取其他forkJointask的任务，这样也减少了线程的上下文切换，所以对于计算密集型的任务效率会很高，所以，如果你的任务是计算密集型，不妨试一下ForkJoinPool。相当于大家同心协力去把pool中的所有task运行完，这样避免了因为倾斜带来的低效。&lt;/p&gt;

&lt;p&gt;asyncMode默认是false，当设为true，这更适合于事件类型的任务，从来不会有join。&lt;/p&gt;

&lt;p&gt;下面是一个计算从1到n和的一个程序，采用了普通线程池和ForkJoinPool来实现，实验证明，forkjoinpool性能领先很大。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;java.util.concurrent.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TestForkJoinPool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sumWithExecutorService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Cost Time is:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ms!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executeWithForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentTimeMillis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;ForkJoinPoll Cost Time is:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ms!&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sumWithExecutorService&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ExecutorService&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Executors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;newFixedThreadPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;cm&quot;&gt;/**
             * 这里，如果前面不进行强制类型转换，那么除了之后就是一个int
             * 就没有必要取ceil 了，切记。
             */&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ceil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;double&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArrayList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threadNum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;submit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))));&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;futures&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ignore&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;call&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;throws&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executeWithForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;invoke&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;forkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RecursiveTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

        &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Integer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;compute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinSumTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thresHold&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leftTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rightTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;work-steamling机制&quot;&gt;work-steamling机制&lt;/h4&gt;

&lt;p&gt;ForkJoinPool中的fork和join是unix中创建线程的方法，在Unix中使用fork可以创建一个子进程，然后join是让父进程等待子进程执行完毕才进行。但是在ForkJoinPool中并不是每次fork都要创建一个子线程，我们可以设置poolSize，规定线程数目的上限。&lt;/p&gt;

&lt;p&gt;ForkJoinPool中的每个线程会维护一个工作队列.这个队列是双端队列，在每次执行自己队列的任务时会尝试随机窃取一个task，窃取对应队列的顺序是FIFO，而执行自己队列中的任务在同步模式下是LIFO。可以看到fork函数是将task放置在队列的尾部。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;n&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinTask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fork&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;externalPush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而join操作呢?&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;判断该任务是否已经完成，如果完成返回，否则2&lt;/li&gt;
  &lt;li&gt;这个任务是自己的工作队列中，如果在，则执行，等待其完成。&lt;/li&gt;
  &lt;li&gt;如果不在自己的工作队列中，则已经被小偷窃取。&lt;/li&gt;
  &lt;li&gt;找到小偷，窃取他队列中的任务，FIFO方式窃取，帮助他早日完成任务。&lt;/li&gt;
  &lt;li&gt;如果小偷已经做完自己的任务，自己在等待被其他小偷窃取走的任务时，帮助他。&lt;/li&gt;
  &lt;li&gt;递归5，直到返回结果。&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;WorkQueue&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Thread.currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wt&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ForkJoinWorkerThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;workQueue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;tryUnpush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;wt.pool.awaitJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;externalAwaitDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;cm&quot;&gt;/**
     * Blocks a non-worker-thread until completion.
     * @return status upon completion
     */&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;externalAwaitDone&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CountedCompleter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// try helping
&lt;/span&gt;                 &lt;span class=&quot;nc&quot;&gt;ForkJoinPool&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;common&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;externalHelpComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
                     &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CountedCompleter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;?&amp;gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;:&lt;/span&gt;
                 &lt;span class=&quot;kt&quot;&gt;ForkJoinPool.common.tryExternalUnpush&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;doExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;U&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compareAndSwapInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;STATUS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SIGNAL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                            &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;wait&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;InterruptedException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ie&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
                            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
                            &lt;span class=&quot;n&quot;&gt;notifyAll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
                    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
                &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interrupted&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;nc&quot;&gt;Thread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentThread&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;interrupt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
                <link>http://turbofei.github.io/coding/2019/05/18/scala-concurrent-programing-Promise-And-ForkJoinPool</link>
                <guid>http://turbofei.github.io/coding/2019/05/18/scala-concurrent-programing:-Promise-And-ForkJoinPool</guid>
                <pubDate>2019-05-18T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Transactions Suuport For Spark Greenlum</title>
                <description>
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;

&lt;p&gt;spark-greenplum是一个spark DataSource为greenplum的实现。通过使用postgresql copy命令的方式从dataframe分区向greenplum拷贝数据，相较于spark sql本身jbdc DataSource的速度提升了上百倍。本文讲解关于实现从spark sql向gp拷贝数据事务的实现。&lt;/p&gt;

&lt;p&gt;相关PR为:&lt;a href=&quot;https://github.com/yaooqinn/spark-greenplum/7&quot;&gt;SPARK-GREENPLUM-4&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;spark-greenplum&quot;&gt;Spark-greenplum&lt;/h3&gt;

&lt;p&gt;Spark-greenplum的项目地址为:https://github.com/yaooqinn/spark-greenplum.&lt;/p&gt;

&lt;p&gt;spark本身有jdbc的DataSource支持，可以进行spark sql 到greenplum的传输，但是速度慢。
查看JdbcUtils中的savePartition方法，其中的拷贝模块为:&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hasNext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numFields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isNullAt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setNull&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nullTypes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;setters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;row&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addBatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
          &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batchSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;stmt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;executeBatch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
          &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里看到，他是针对迭代器进行遍历，达到batchSize（默认为1000）之后进行一次insert操作，因此针对大批量的拷贝操作，速度较慢。&lt;/p&gt;

&lt;p&gt;在postgresql中，有一个copy命令，可以参考文档：https://www.postgresql.org/docs/9.2/sql-copy.html.&lt;/p&gt;

&lt;p&gt;下面的命令为将一个文件中的数据拷贝到一个表中.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;table_name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;column_name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'filename'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;STDIN&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;option&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这是一个原子操作，这个copy的速度相较于jdbc DataSource中的按批插入，性能提升极大。&lt;/p&gt;

&lt;p&gt;通过将每个dataFrame中partition的数据写入一个文件，然后使用copy from命令将这个文件中的数据拷贝到greenplum表中，针对每个分区中的copy操作分别是原子操作，但是如何针对所有分区实现事务呢？事务对于生产环境中是非常必要的。&lt;/p&gt;

&lt;p&gt;在讲解事务实现之前，先讲下在针对文件中一些特殊字符的处理.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Backslash characters (\) can be used in the COPY data to quote data characters that might otherwise be taken as row or column delimiters. In particular, the following characters must be preceded by a backslash if they appear as part of a column value: backslash itself, newline, carriage return, and the current delimiter character.
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;从sparksql 写数据到文件的过程是将每个Row写到文件中的一行，而且各个column之间使用指定的delimiter间隔。因此，在写文件时需要对于一些特殊字符进行处理，比如换行符合回车符，这些肯定是需要特殊处理的，因此不处理，就会导致一个row写了多行，之后copy命令就无法正确识别，其次就是 row中如果有column的值包含和delimiter相同的字符也要进行转义，不然copy命令就无法通过delimiter识别出列的值，除此之外还有’\‘需要特殊处理，因为对delimiter的处理是在demiter前加’\‘因此，也要针对’\‘进行处理避免与delimiter的处理方式混淆。&lt;/p&gt;

&lt;h3 id=&quot;事务实现&quot;&gt;事务实现&lt;/h3&gt;

&lt;p&gt;前面提到针对每个partition的copy命令都是原子操作，但是针对整体的partition如何实现原子操作呢？&lt;/p&gt;

&lt;p&gt;从spark sql向greenplum插入数据分为以下几种情况:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;gp表存在，是overwrite操作，但是这个表是一个级联删除表，因此我们不能使用drop再create的操作，只能truncate再进行append。&lt;/li&gt;
  &lt;li&gt;gp表存在，向表中append数据。&lt;/li&gt;
  &lt;li&gt;gp表存在，是overwrite操作，是非级联表，因此可以对该表进行drop再create的操作。&lt;/li&gt;
  &lt;li&gt;gp表不存在，可以直接进行create操作。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上面四种情况，可以分为两种:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;可以drop if exists，再导入数据&lt;/li&gt;
  &lt;li&gt;必须append数据。&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;case1&quot;&gt;case1&lt;/h4&gt;

&lt;p&gt;针对第一种情况，实现事务很简单，方案如下:&lt;/p&gt;

&lt;p&gt;首先创建一个临时表，然后针对每个分区，使用copy命令，将各个分区的数据拷贝到这个临时表中。最后，如果所有分区都成功拷贝。&lt;/p&gt;

&lt;p&gt;那么在driver中进行以下两步操作:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;drop $table if exists&lt;/li&gt;
  &lt;li&gt;alter table $tempTable rename to $table&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果这两步都成功，那么则完成了事务。&lt;/p&gt;

&lt;p&gt;如果有分区未成功拷贝，或者在以上两步中失败，则进行删除临时表的操作。并且抛出异常，提醒用户，事务未成功。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;如何判断分区成功数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;如何判断分区是否全部成功呢？我们使用 &lt;strong&gt;LongAccmulator&lt;/strong&gt;来实现，在driver中注册一个累加器，然后每个分区成功时则累加器加一，如果最终累加器的值，等于dataFrame的分区数，那么代表全部成功，否则是部分失败。&lt;/p&gt;

&lt;p&gt;关于LongAccmulator，想了解的可以去搜索了解，相当于一个分布式的atomicLong.&lt;/p&gt;

&lt;h4 id=&quot;case2&quot;&gt;case2&lt;/h4&gt;

&lt;p&gt;针对第二种情况，我们添加一个transactionOn 的option。如果为true，那么我们将dataFrame进行coalesce(1)的操作，这样dataFrame就只有一个分区，针对这个分区中copy操作就是原子性的，这样就保证了事务。&lt;/p&gt;

&lt;p&gt;关于coalesce操作，它与reparation操作不同。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def coalesce(numPartitions: Int, shuffle: Boolean = false,
               partitionCoalescer: Option[PartitionCoalescer] = Option.empty)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;对于coalesce操作，从m个分区编程n个分区，如果m&amp;lt;n是一定要进行shuffle的，如果m&amp;gt;n, 则如果非指定shuffle为true，则不需要进行shuffle。&lt;/p&gt;

&lt;p&gt;因此coalesce(1)操作，不会造成shuffle压力，而且rdd操作是迭代读取，之后进行落盘(参考&lt;a href=&quot;https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1&quot;&gt;rdd-basic&lt;/a&gt;）。只是每个partition分区的数据都发向一个节点，数据拷贝需要进行串行，然后就是可能造成磁盘压力，如果存储不够的话就很尴尬。&lt;/p&gt;

&lt;p&gt;如果transactionOn为false，则不保障事务。&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/spark/2019/05/12/transactions-suuport-for-spark-greenlum</link>
                <guid>http://turbofei.github.io/spark/2019/05/12/transactions-suuport-for-spark-greenlum</guid>
                <pubDate>2019-05-12T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Spark Cbo Code Analysis</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-cbo-源码分析&quot; id=&quot;markdown-toc-spark-cbo-源码分析&quot;&gt;Spark CBO 源码分析&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#统计信息类&quot; id=&quot;markdown-toc-统计信息类&quot;&gt;统计信息类&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#statistics的计算&quot; id=&quot;markdown-toc-statistics的计算&quot;&gt;Statistics的计算&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#拿到数据之后怎么用&quot; id=&quot;markdown-toc-拿到数据之后怎么用&quot;&gt;拿到数据之后怎么用&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#costbasedjoinreorder&quot; id=&quot;markdown-toc-costbasedjoinreorder&quot;&gt;CostBasedJoinReorder&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#joinselection&quot; id=&quot;markdown-toc-joinselection&quot;&gt;JoinSelection&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;对Spark的CBO(cost based optimization) 进行源码分析&lt;/p&gt;

&lt;h2 id=&quot;spark-cbo-源码分析&quot;&gt;Spark CBO 源码分析&lt;/h2&gt;

&lt;p&gt;CBO是基于Cost来优化plan。&lt;/p&gt;

&lt;p&gt;要计算cost就需要统计一些参与计算的表的相关信息，因此spark添加了&lt;code class=&quot;highlighter-rouge&quot;&gt;Statistics和ColumnStat&lt;/code&gt;类来统计相关信息。&lt;/p&gt;

&lt;p&gt;CBO主要是针对join来计算cost,目前spark-2.3 版本中与CBO相关的参数如下：&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;参数&lt;/th&gt;
      &lt;th&gt;默认值&lt;/th&gt;
      &lt;th&gt;说明&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enables CBO for estimation of plan statistics when set true.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.enabled&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Enables join reorder in CBO.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;Applies star-join filter heuristics to cost based join enumeration.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;The maximum number of joined nodes allowed in the dynamic programming algorithm.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;spark.sql.cbo.starSchemaDetection&lt;/td&gt;
      &lt;td&gt;false&lt;/td&gt;
      &lt;td&gt;When true, it enables join reordering based on star schema detection.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;下文按照逻辑顺序分析spark cbo 源码。&lt;/p&gt;

&lt;h2 id=&quot;统计信息类&quot;&gt;统计信息类&lt;/h2&gt;

&lt;p&gt;CBO相关的统计信息类有两个，一个是ColumnStat,代表的是表中列的详细，例如最大值，最小值，空值个数，平均长度，最大长度。另外一个类是Statistics，这个类是对应一个LogicalPlan的统计信息，例如join，aggregate，logicalRelation。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-Scala&quot;&gt;case class Statistics(
    sizeInBytes: BigInt,
    rowCount: Option[BigInt] = None,
    attributeStats: AttributeMap[ColumnStat] = AttributeMap(Nil),
    hints: HintInfo = HintInfo()) 

case class ColumnStat(
    distinctCount: BigInt,
    min: Option[Any],
    max: Option[Any],
    nullCount: BigInt,
    avgLen: Long,
    maxLen: Long,
    histogram: Option[Histogram] = None) 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如上所示，可以看到ColumnStat表示列的详细信息。&lt;/p&gt;

&lt;p&gt;而Statistics，中的sizeInBytes和rowCount就代表这个logicalPlan输出数据的大小和行数，而attributeStats 代表这个logicalPlan涉及到的列的统计信息（一个expressID到列信息的映射），和hints。&lt;/p&gt;

&lt;p&gt;对于join来说，它的Statistics里的信息就代表join操作输出的大小，行数以及attributeStats。&lt;/p&gt;

&lt;p&gt;对于logicalRelation，它的Statistics代表其对应表中schema相关数据的大小，行数，attributeStats。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CatalogStatistics&lt;/code&gt;这个类表示存储在外部catalog(例如hive metastore）中的表的信息.&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CatalogStatistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;colStats&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;String&lt;/span&gt;, &lt;span class=&quot;kt&quot;&gt;ColumnStat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这些表的信息需要使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;analyze table&lt;/code&gt;命令来计算，然后存储到catalog里。&lt;/p&gt;

&lt;p&gt;每种LogicalPlan计算Statistics的方法是不同的。&lt;/p&gt;

&lt;p&gt;对于LogicalRelation来说，它是读取对应表中schema，使用CatalogStatistics类的toPlanStats可以生成Statistics。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;toPlanStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Attribute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isDefined&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AttributeMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// Estimate size as number of rows * row size.
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EstimationUtils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOutputSize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planOutput&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attributeStats&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrStats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// When CBO is disabled or the table doesn't have other statistics, we apply the size-only
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;// estimation strategy and only propagate sizeInBytes in statistics.
&lt;/span&gt;    &lt;span class=&quot;nc&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sizeInBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;下面将介绍其他LogicalPlan的Statistics计算。&lt;/p&gt;

&lt;h2 id=&quot;statistics的计算&quot;&gt;Statistics的计算&lt;/h2&gt;

&lt;p&gt;看LogicalPlanStats类，可以看出，这里，判断cbo是否开启，如果cbo打开，则采用BasicStatsPlanVisitor类来计算相关的Statistics，如果没有cbo，则使用SizeInBytesOnlyStatsPlanVisitor来计算。&lt;/p&gt;

&lt;p&gt;从类的名字就可以看出来，只有cbo开启，才会计算rowCount以及attributeStats信息，如果没有cbo,SizeInBytesOnlyStatsPlanVisitor只会计算 size信息。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LogicalPlanStats&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;LogicalPlan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stats&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrElse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cboEnabled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BasicStatsPlanVisitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;visit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SizeInBytesOnlyStatsPlanVisitor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;visit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;statsCache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其实在BasicStatsPlanVisitor类中对于大部分类型的LogicalPlan都还是调用SizeInBytesOnlyStatsPlanVisitor的方法来计算。&lt;/p&gt;

&lt;p&gt;只有针对Aggregate，Join，Filter，Project有另外的计算方法。&lt;/p&gt;

&lt;p&gt;这里讲下join操作的Statistics计算过程。&lt;/p&gt;

&lt;p&gt;如果没有开启CBO，join操作首先判断是否是 leftAntiJoin或者是LeftSemiJoin，如果是，则把leftChild的sizeInBytes作为计算结果，因为对于leftAntiJoin和leftSemiJoin来说，join之后表的大小是小于leftChild的。而对于其他类型的join，把左右child的sizeInBytes相乘作为join之后的大小，并且关闭掉broadcastHint，因为这些join类型可能造成很大的output。而这种粗糙的代价估计造成的结果就是，对代价估计不准确，如果该join是可以进行broadcastjoin，也可能由于粗糙的代价估计变得不可进行。&lt;/p&gt;

&lt;p&gt;如果开启了CBO，对于join操作就不止计算sizeInBytes，还需要计算rowCount，AttributeStats。&lt;/p&gt;

&lt;p&gt;代码如下，首先是判断join类型，如果是 inner,cross,leftOuter,RightOuter,FullOuter中的一种，则使用estimateInnerOuterJoin方法。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;estimate&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Option&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Statistics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinType&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;match&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Inner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cross&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftOuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RightOuter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FullOuter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;estimateInnerOuterJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftSemi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LeftAnti&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;estimateLeftSemiAntiJoin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;logDebug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[CBO] Unsupported join type: ${join.joinType}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;None&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里只针对针对estimateInnerOuterJoin方法，用语言描述一下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果是equiJoin:&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;1、首先估算被equi条件选择的记录条数,即等于innerJoin选择的条数，命名为numInnerJoinedRows；以及这些equi涉及的key在join之后的stats。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;即在join中，存在类似 a.co1=b.co1, a.co2=b.co2 这些类似条件，现在是估计满足这些相等条件的记录条数。&lt;/p&gt;

      &lt;p&gt;使用的公式是： T(A J B) = T(A) * T(B) / max(V(A.ki), V(B.ki)).&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;2、 预估得到结果的行数。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;因为即使满足这些相等条件，也不会只输出这些满足条件的记录。&lt;/p&gt;

      &lt;p&gt;如果是leftOuterJoin，则会对左边表中所有记录都会输出，不管右边匹配是否为空。&lt;/p&gt;

      &lt;p&gt;因此，对于leftOuterJoin来说，输出的记录条数等于max(左边表条数，numInnerJoinedRows)。&lt;/p&gt;

      &lt;p&gt;同样还有rightOuterJoin,输出记录条数=max(右边表条数，numInnerJoinedRows)。&lt;/p&gt;

      &lt;p&gt;对于全连接，输出记录条数=max(左边表条数，numInnerJoinedRows)+max(右边表条数，numInnerJoinedRows)-numInnerJoinedRows。即类似于A与B的并集-A与B的交集。&lt;/p&gt;
    &lt;/blockquote&gt;

    &lt;p&gt;3、然后是根据前面的计算结果更新Statistics，包括attributeStats。&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;如果不是equiJoin：&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;则按照笛卡尔积来计算，输出行数为两个表行数的乘积&lt;/p&gt;

  &lt;/blockquote&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;拿到数据之后怎么用&quot;&gt;拿到数据之后怎么用&lt;/h2&gt;

&lt;p&gt;这些Statistics的结果，会怎么运用呢？&lt;/p&gt;

&lt;p&gt;spark sql中plan的处理过程可以参考&lt;a href=&quot;./spark-sql-catalyst.md&quot;&gt;Spark sql catalyst过程详解&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;在unresolvedLogicalPlan-&amp;gt;resolvedLogicalPlan过程中收集Statistics，然后在&lt;/p&gt;

&lt;p&gt;resolvedLogicalPlan-&amp;gt;optimizedLogicalPlan过程中，基于这些统计信息，进行costBasedJoinRecorder，即基于统计信息，对join顺序重排序，寻求最优join方案。&lt;/p&gt;

&lt;p&gt;在optimizedLogicalPlan-&amp;gt;phsicalPlan过程中，基于Statistics中的sizeInBytes信息以及hint选择合适的join策略(broadcastJoin,hashShuffledJoin,sortMergeJoin).&lt;/p&gt;

&lt;h4 id=&quot;costbasedjoinreorder&quot;&gt;CostBasedJoinReorder&lt;/h4&gt;

&lt;p&gt;这是一个使用plan的stats信息，来选择合适的join顺序的类。&lt;/p&gt;

&lt;p&gt;类&lt;code class=&quot;highlighter-rouge&quot;&gt;Optimizer&lt;/code&gt;中有两个跟join 顺序有关的rule，一个是reoderJoin，另外一个是CostBasedJoinRecorder。reorderjoin是没有cbo也会触发的rule，这个不会使用统计的信息，只是负责将filter下推，这样最底层的join至少会有一个filter。如果这些join已经每个都有一条condition，那么这些plan就不会变化，因此reorder join不涉及基于代价的优化。&lt;/p&gt;

&lt;p&gt;首先看下对cost的定义。cost是有一个基数，是rowCount，然后一个sizeInBytes。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/**
 * This class defines the cost model for a plan.
 * @param card Cardinality (number of rows).
 * @param size Size in bytes.
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;BigInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而判断cost的方法是：&lt;/p&gt;

&lt;p&gt;A: Cost(ac,as)  B: Cost(bc,bs)&lt;/p&gt;

&lt;p&gt;如果&lt;/p&gt;

&lt;p&gt;(ac/bc)*joinReorderCardWeight +(as/bs)*(1-joinReorderCardWeight)&amp;lt;1，&lt;/p&gt;

&lt;p&gt;则认为A比B好。&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.cbo.joinReorder.card.weight&lt;/code&gt;默认为0.7。代码如下：&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betterThan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;JoinPlan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Boolean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relativeRows&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;card&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;relativeSize&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BigDecimal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;other&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;planCost&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;relativeRows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinReorderCardWeight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;relativeSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;joinReorderCardWeight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;costBasedJoinReorder是使用一个动态规划来进行选择合适的join顺序。&lt;/p&gt;

&lt;p&gt;下面讲一个这个动态规划算法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;假设有  a j b j c j d   a.k1=b.k1 and b.k2 = c.k2 and c.k3=d.k3&lt;/p&gt;

  &lt;p&gt;将会分为4层来进行：&lt;/p&gt;

  &lt;blockquote&gt;
    &lt;p&gt;level 0: p({A}), p({B}), p({C}), p({D})
level 1: p({A, B}), p({B, C}), p({C, D})
level 2: p({A, B, C}), p({B, C, D})
level 3: p({A, B, C, D})&lt;/p&gt;
  &lt;/blockquote&gt;

  &lt;p&gt;首先就是生成第0层，第0层的founfPlans={p{a},p{b},p{c},p{d}}.&lt;/p&gt;

  &lt;p&gt;如果设层级为level，那么每层的任务就是找到（level+1)个plan进行join最优的版本。&lt;/p&gt;

  &lt;p&gt;因此 k层和level-k层的所包含的表的个数之和，就是(k+1+level-k+1)=level+2，也就是说是level+1层所需要的foundPlan。&lt;/p&gt;

  &lt;p&gt;而我们在每次生成新的join之后，就判断他的itemSet是否已经存在，如果不存在就存储；如果存在，就取出其对应的plan，对比看是不是优于之前的plan（betterThan)，保存最优的。&lt;/p&gt;

  &lt;p&gt;这样。每个level里面保存的都是相应个数个多join最优的plan，最终也得到了最优的plan。&lt;/p&gt;

  &lt;p&gt;当然，在形成plan时有很多判断，比如在level1 里面，就不能形成p({A,C})。&lt;/p&gt;

  &lt;p&gt;因为不存在condition 使得A,C可以进行join。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，在动态规划进行search的时候，有一个filter。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;spark.sql.cbo.joinReorder.dp.star.filter&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;这是一个星型join过滤器，用来确保star schema 中的tables是被plan在一起。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;spark.sql.cbo.joinReorder.dp.threshold&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;代表在dp进行costbasedReorder时，最多支持的表的数量。&lt;/p&gt;

&lt;p&gt;**spark.sql.cbo.starSchemaDetection  **&lt;/p&gt;

&lt;p&gt;这个参数是在reorderJoin中触发，而且只在&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.cbo.starSchemaDetection=true spark.sql.cbo.enabled=false&lt;/code&gt;时才触发，很奇怪，这个参数以cbo命名，但是却在cbo.enable=false才触发。&lt;/p&gt;

&lt;p&gt;这个是用来观察是否存在starJoin。&lt;/p&gt;

&lt;h4 id=&quot;joinselection&quot;&gt;JoinSelection&lt;/h4&gt;

&lt;p&gt;在SparkPlanner类中，有几个优化策略会对LogicalPlan进行优化。&lt;/p&gt;

&lt;div class=&quot;language-scala highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkPlanner&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SparkContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SQLConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;experimentalMethods&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ExperimentalMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SparkStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;override&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strategies&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Strategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;experimentalMethods&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extraStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;extraPlanningStrategies&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;DataSourceV2Strategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;FileSourceStrategy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;DataSourceStrategy&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;SpecialLimits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;Aggregation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;JoinSelection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;InMemoryScans&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;
      &lt;span class=&quot;nc&quot;&gt;BasicOperators&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nil&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;里面有一个JoinSelection方法，这个方法是主要是用来判断是否可以使用broadcastjoin，然后决定是使用broadcastJoin，还是shuffledHashJoin还是sortMergeJoin。&lt;/p&gt;

&lt;p&gt;broadcastjoin可以避免shuffle，如果使用得当，可以提升程序的性能。&lt;code class=&quot;highlighter-rouge&quot;&gt;这是针对一个大表和一个极小表&lt;/code&gt;在spark中有一个参数是，&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，这个参数是一个数字，单位字节，代表如果一个表的szie小于这个数值，就可以进行broadcastjoin。但是这里只使用size作为估计是不准确的，还应该使用rowCount作为参考，因为在join中，join的结果是与两个表的条数强相关，只使用size做判断是不准确的。&lt;/p&gt;

&lt;p&gt;在spark中，有BroadCastHint，前面也提到过，如果没有开启cbo，那么如果判断join类型是非leftAntiJoin和leftSemiJoin，则会觉得join之后的大小无法估测，可能会爆炸式增长，因此会关掉BroadcastHint。&lt;/p&gt;

&lt;p&gt;对于shuffledHashJoin，&lt;code class=&quot;highlighter-rouge&quot;&gt;这是针对一个大表和一个小表（判断标准为a.stats.sizeInBytes * 3 &amp;lt;= b.stats.sizeInBytes)&lt;/code&gt;，简单描述一下过程就是两个表A和B，首先，选择一个表进行shuffle write操作，即针对每个分区，按照key的hash值进行排序，将相同hash值的key放在一起，形成一个partitionFile，然后在read端拉取write端所有相应key的数据，作为localhashMap和另外一个标的分区进行join。&lt;/p&gt;

&lt;p&gt;这里也使用stats进行判断，如果&lt;code class=&quot;highlighter-rouge&quot;&gt;plan.stats.sizeInBytes &amp;lt; conf.autoBroadcastJoinThreshold * conf.numShufflePartitions&lt;/code&gt;，则判断该表的size可以满足每个分区构建localhashMap的可能，可以看到这里也是以&lt;code class=&quot;highlighter-rouge&quot;&gt;autoBroadcastJoinThreshold&lt;/code&gt;作为衡量标准。&lt;/p&gt;

&lt;p&gt;如果是两张大表，则需要使用sortmergeJoin，类似于先排序，即按照keypair排序，然后进行归并。&lt;/p&gt;

&lt;p&gt;这些join selection的操作，不管是否开启CBO都会进行。但是和CBO相关的是，这些数据的统计是和CBO有关，前面提过，如果开启CBO则使用BasicStatsPlanVisitor来进行统计。&lt;/p&gt;

&lt;p&gt;上述的这些估测，都是基于size信息。但是即使是基于size信息，如果没有开启cbo，这些信息也是粗糙的，没有CBO那种更细致的估计，因此可能会造成Join种类选择不合适。&lt;/p&gt;

&lt;p&gt;上述的判断，很多是基于&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.sql.autoBroadcastJoinThreshold&lt;/code&gt;，因此在运行环境中，一定要结合集群环境设置合适的值。&lt;/p&gt;

&lt;p&gt;而且，在joinSelection中，也应该基于rowCount来判断join的种类。&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/spark/2018/12/04/spark-cbo-code-analysis</link>
                <guid>http://turbofei.github.io/spark/2018/12/04/spark-cbo-code-analysis</guid>
                <pubDate>2018-12-04T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Spark Sql Analysis</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#spark-sql概述&quot; id=&quot;markdown-toc-spark-sql概述&quot;&gt;Spark Sql概述&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#源码跟踪&quot; id=&quot;markdown-toc-源码跟踪&quot;&gt;源码跟踪&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#sql-语句--unresolved-logicalplan&quot; id=&quot;markdown-toc-sql-语句--unresolved-logicalplan&quot;&gt;sql 语句-&amp;gt; Unresolved LogicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#resolved-logicalplan&quot; id=&quot;markdown-toc-resolved-logicalplan&quot;&gt;Resolved LogicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#optimizedlogicalplan&quot; id=&quot;markdown-toc-optimizedlogicalplan&quot;&gt;OptimizedLogicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#physicalplan&quot; id=&quot;markdown-toc-physicalplan&quot;&gt;PhysicalPlan&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#可执行的物理计划&quot; id=&quot;markdown-toc-可执行的物理计划&quot;&gt;可执行的物理计划&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#执行&quot; id=&quot;markdown-toc-执行&quot;&gt;执行&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;从源码层面解释一个sparkSql语句是如何执行的，从sql到与底层RDD如何对接&lt;/p&gt;

&lt;h2 id=&quot;spark-sql概述&quot;&gt;Spark Sql概述&lt;/h2&gt;

&lt;p&gt;spark sql是 apache spark的其中一个模块，主要用于进行结构化数据的处理。spark sql的底层执行还是调用rdd，在之前的文章中提过rdd的执行流程，因此本文主要讲解一下从sql到底层rdd的对接。通过观察spark sql 模块的源码，源码分为四个部分，如下图。&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;/public/img/spark-sql/sql-model.png&quot; title=&quot;sql-model&quot; width=&quot;60%&quot; /&gt;
&lt;/div&gt;

&lt;p&gt;在官方github的sql模块readme文件有如下描述。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Catalyst (sql/catalyst) - An implementation-agnostic framework for manipulating trees of relational operators and expressions.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Execution (sql/core) - A query planner / execution engine for translating Catalyst’s logical query plans into Spark RDDs. This component also includes a new public interface, SQLContext, that allows users to execute SQL or LINQ statements against existing RDDs and Parquet files.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Hive Support (sql/hive) - Includes an extension of SQLContext called HiveContext that allows users to write queries using a subset of HiveQL and access data from a Hive Metastore using Hive SerDes. There are also wrappers that allow users to run queries that include Hive UDFs, UDAFs, and UDTFs.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;HiveServer and CLI support (sql/hive-thriftserver) - Includes support for the SQL CLI (bin/spark-sql) and a HiveServer2 (for JDBC/ODBC) compatible server.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;本文主要讲解core和catalyst模块。首先给一个spark sql语句执行流程，来方便对后续内容进行整体把握。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;SQL 语句经过 SqlParser 解析成 Unresolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 analyzer 结合数据数据字典 (catalog) 进行绑定, 生成 resolved LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 optimizer 对 resolved LogicalPlan 进行优化, 生成 optimized LogicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 SparkPlan 将 LogicalPlan 转换成 PhysicalPlan;&lt;/li&gt;
  &lt;li&gt;使用 prepareForExecution() 将 PhysicalPlan 转换成可执行物理计划;&lt;/li&gt;
  &lt;li&gt;使用 execute() 执行可执行物理计划;&lt;/li&gt;
  &lt;li&gt;生成 RDD。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;源码跟踪&quot;&gt;源码跟踪&lt;/h2&gt;

&lt;p&gt;首先是要创建sparkSession然后导入数据，此处不赘述。我们从执行sql语句开始跟踪。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val teenagersDF = spark.sql(&quot;SELECT SUM(v) FROM (SELECT score.id, 100+80+ score.math_score +score.english_score AS v FROM people JOIN score WHERE  people.id=score.id AND people.age &amp;gt;100) tmp&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;sql-语句--unresolved-logicalplan&quot;&gt;sql 语句-&amp;gt; Unresolved LogicalPlan&lt;/h3&gt;

&lt;p&gt;此部分主要是对sql语句进行解析。判断一条sql语句是否符合要求，并且进行各部分的划分，比如哪些是操作，哪些是得到的结果等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/parser.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样一句sql 调用，跟进去。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def sql(sqlText: String): DataFrame = {
  Dataset.ofRows(self, sessionState.sqlParser.parsePlan(sqlText))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;我们可以看到sql语句会返回一个&lt;code class=&quot;highlighter-rouge&quot;&gt;dataFrame&lt;/code&gt;。而在spark中DataFrame的定义就是&lt;code class=&quot;highlighter-rouge&quot;&gt;Dataset[Row]&lt;/code&gt; .值得一提的是，在spark源码中用到了许多&lt;code class=&quot;highlighter-rouge&quot;&gt;lazy&lt;/code&gt;变量，这些变量虽然是声明在类中，但是并不是在创建对象的时候就初始化这些变量，而是在第一次调用是才进行初始化，因此在跟踪源码时一定要注意这些lazy变量的调用，因为很多lazy变量的初始化都涉及到一系列函数的调用。如果不注意，会失去对很多函数的跟踪。具体lazy变量的介绍，&lt;a href=&quot;https://stackoverflow.com/questions/7484928/what-does-a-lazy-val-do&quot;&gt;可以参考&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sqlParser: ParserInterface = new SparkSqlParser(conf)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看到sqlParser就是一个lazy变量，它会创建一个解析器。上述的sql函数在创建解析器之后调用parsePlan函数，如下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Creates LogicalPlan for a given SQL string. */
override def parsePlan(sqlText: String): LogicalPlan = parse(sqlText) { parser =&amp;gt;
  astBuilder.visitSingleStatement(parser.singleStatement()) match {
    case plan: LogicalPlan =&amp;gt; plan
    case _ =&amp;gt;
      val position = Origin(None, None)
      throw new ParseException(Option(sqlText), &quot;Unsupported SQL statement&quot;, position, position)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个函数是使用了Scala柯里化特性。其实是调用的parse函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  protected def parse[T](command: String)(toResult: SqlBaseParser =&amp;gt; T): T = {
    logInfo(s&quot;Parsing command: $command&quot;)
    val lexer = new SqlBaseLexer(new ANTLRNoCaseStringStream(command))
    lexer.removeErrorListeners()
    lexer.addErrorListener(ParseErrorListener)
    val tokenStream = new CommonTokenStream(lexer)
    val parser = new SqlBaseParser(tokenStream)
    parser.addParseListener(PostProcessor)
    parser.removeErrorListeners()
    parser.addErrorListener(ParseErrorListener)

    try {
      try {
        // first, try parsing with potentially faster SLL mode
        parser.getInterpreter.setPredictionMode(PredictionMode.SLL)
        toResult(parser)
      }
      catch {
     ...
      }
    }
    catch {
      ...
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;而此处的parse函数是使用的Antlr(一个开源语法分析器)来对sql语句进行解析，lexer是其词法分析器，然后spark使用自身的sqlBaseParser对sql语句进行语法分析，结合parse和parsePlan函数，得到了sql语句的&lt;code class=&quot;highlighter-rouge&quot;&gt;UnresolvedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;resolved-logicalplan&quot;&gt;Resolved LogicalPlan&lt;/h3&gt;

&lt;p&gt;此部分是对之前得到的逻辑计划进行分析，比如这个字段到底应该是什么类型，等等，不是很熟悉编译。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/analysis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;进入到Dataset类的ofRows函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def ofRows(sparkSession: SparkSession, logicalPlan: LogicalPlan): DataFrame = {
  val qe = sparkSession.sessionState.executePlan(logicalPlan)
  qe.assertAnalyzed()
  new Dataset[Row](sparkSession, qe, RowEncoder(qe.analyzed.schema))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个函数很短，跟踪executePlan函数，可以看到它是创建了一个queryExecution对象。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def executePlan(plan: LogicalPlan): QueryExecution = new QueryExecution(sparkSession, plan)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个对象是很重要的一个对象,涉及到前面的&lt;code class=&quot;highlighter-rouge&quot;&gt;UnresolvedLogicalPlan&lt;/code&gt;的分析、优化、转物理计划以及ToRDD所有操作。&lt;/p&gt;

&lt;p&gt;ofRows函数第二行是对逻辑计划进行确认分析，里面涉及到分析操作，分析是对之前逻辑计划里面的属性进行分析。分析的源码我就不贴了，分析是使用一套既定的规则，然后进行多次迭代，知道分析结果达到一个固定点或者到达最高迭代次数停止。得到&lt;code class=&quot;highlighter-rouge&quot;&gt;resolvedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;optimizedlogicalplan&quot;&gt;OptimizedLogicalPlan&lt;/h3&gt;

&lt;p&gt;此部分主要是对逻辑计划进行优化， 例如谓词下推等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/public/img/spark-sql/optimizer.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后第三行，就是生成一个Dataset[Row]，前面提到过，其实这就是dataFrame。&lt;/p&gt;

&lt;p&gt;跟踪进入Dataset的this函数。里面有一个变量会在创建对象时执行&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@transient private[sql] val logicalPlan: LogicalPlan = {
  def hasSideEffects(plan: LogicalPlan): Boolean = plan match {
    case _: Command |
         _: InsertIntoTable =&amp;gt; true
    case _ =&amp;gt; false
  }

  queryExecution.analyzed match {
    // For various commands (like DDL) and queries with side effects, we force query execution
    // to happen right away to let these side effects take place eagerly.
    case p if hasSideEffects(p) =&amp;gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case Union(children) if children.forall(hasSideEffects) =&amp;gt;
      LogicalRDD(queryExecution.analyzed.output, queryExecution.toRdd)(sparkSession)
    case _ =&amp;gt;
      queryExecution.analyzed
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看到里面有一行调用了LogicalRDD函数，第一个参数是输出位置，第一个参数，queryExecution.toRdd. 一系列的lazy变量。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val optimizedPlan: LogicalPlan = sparkSession.sessionState.optimizer.execute(withCachedData)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里调用了一些列，调用到optimizedPlan，其实也是进行规则优化，基于一系列规则，到不动点或者最大迭代次数退出优化。这就得到了&lt;code class=&quot;highlighter-rouge&quot;&gt;optimizedLogicalPlan&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;physicalplan&quot;&gt;PhysicalPlan&lt;/h3&gt;

&lt;p&gt;回到前面的sparkPlan懒变量，最后一句，planner.plan对之前的 &lt;code class=&quot;highlighter-rouge&quot;&gt;optimizedLogicalPlan&lt;/code&gt;进行转化生成phsicalPlan。此处的next是操作是获得返回的physicalPlan迭代器中的第一个physicalPlan。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val sparkPlan: SparkPlan = {
  SparkSession.setActiveSession(sparkSession)
  // TODO: We use next(), i.e. take the first plan returned by the planner, here for now,
  //       but we will implement to choose the best plan.
  planner.plan(ReturnAnswer(optimizedPlan)).next()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里的planner为SparkPlanner，类中有一系列的策略，还可以从外部加策略。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def strategies: Seq[Strategy] =
    extraStrategies ++ (
    FileSourceStrategy ::
    DataSourceStrategy ::
    DDLStrategy ::
    SpecialLimits ::
    Aggregation ::
    JoinSelection ::
    InMemoryScans ::
    BasicOperators :: Nil)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后进行转化的函数如下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def plan(plan: LogicalPlan): Iterator[PhysicalPlan] = {
  // Obviously a lot to do here still...

  // Collect physical plan candidates.
  val candidates = strategies.iterator.flatMap(_(plan))

  // The candidates may contain placeholders marked as [[planLater]],
  // so try to replace them by their child plans.
  val plans = candidates.flatMap { candidate =&amp;gt;
    val placeholders = collectPlaceholders(candidate)

    if (placeholders.isEmpty) {
      // Take the candidate as is because it does not contain placeholders.
      Iterator(candidate)
    } else {
      // Plan the logical plan marked as [[planLater]] and replace the placeholders.
      placeholders.iterator.foldLeft(Iterator(candidate)) {
        case (candidatesWithPlaceholders, (placeholder, logicalPlan)) =&amp;gt;
          // Plan the logical plan for the placeholder.
          val childPlans = this.plan(logicalPlan)

          candidatesWithPlaceholders.flatMap { candidateWithPlaceholders =&amp;gt;
            childPlans.map { childPlan =&amp;gt;
              // Replace the placeholder by the child plan
              candidateWithPlaceholders.transformUp {
                case p if p == placeholder =&amp;gt; childPlan
              }
            }
          }
      }
    }
  }

  val pruned = prunePlans(plans)
  assert(pruned.hasNext, s&quot;No plan for $plan&quot;)
  pruned
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;没看明白，知识欠缺。大概就是得到一系列physicalPlan，然后进行剪枝，筛除掉性能不好的，这就得到了&lt;code class=&quot;highlighter-rouge&quot;&gt;physicalPlan&lt;/code&gt;迭代器，然后通过前面说的next函数，得到迭代器头部的&lt;code class=&quot;highlighter-rouge&quot;&gt;physicalPlan&lt;/code&gt;，应该是最好的那个。&lt;/p&gt;

&lt;h3 id=&quot;可执行的物理计划&quot;&gt;可执行的物理计划&lt;/h3&gt;

&lt;p&gt;在得到物理计划sparkPlan之后会执行下面的函数，prepareForExecution(sparkPlan)，得到可执行的物理计划。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val executedPlan: SparkPlan = prepareForExecution(sparkPlan)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Prepares a planned [[SparkPlan]] for execution by inserting shuffle operations and internal
 * row format conversions as needed.
 */
protected def prepareForExecution(plan: SparkPlan): SparkPlan = {
  preparations.foldLeft(plan) { case (sp, rule) =&amp;gt; rule.apply(sp) }
}

/** A sequence of rules that will be applied in order to the physical plan before execution. */
protected def preparations: Seq[Rule[SparkPlan]] = Seq(
  python.ExtractPythonUDFs,
  PlanSubqueries(sparkSession),
  EnsureRequirements(sparkSession.sessionState.conf),
  CollapseCodegenStages(sparkSession.sessionState.conf),
  ReuseExchange(sparkSession.sessionState.conf),
  ReuseSubquery(sparkSession.sessionState.conf))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看注释以及源码，理解，就是又是一些规则，然后对逻辑计划不断使用这些规则进行完善，就是把规则按顺序运用一遍，&lt;a href=&quot;https://blog.csdn.net/oopsoom/article/details/23447317&quot;&gt;scala的 foldleft用法参考这里&lt;/a&gt;,不得不说scala语法真多。&lt;/p&gt;

&lt;h3 id=&quot;执行&quot;&gt;执行&lt;/h3&gt;

&lt;p&gt;可以看到在获得获得可执行计划之后就是执行，&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;lazy val toRdd: RDD[InternalRow] = executedPlan.execute()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def execute(): RDD[InternalRow] = executeQuery {
  doExecute()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;//class sparkPlan
protected def doExecute(): RDD[InternalRow]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个函数对应很多子类，每个子类的第一句基本都是&lt;code class=&quot;highlighter-rouge&quot;&gt;child.execute()&lt;/code&gt;,可见这是在构建lineage。也就是一条链，把所有可执行计划串联起来。&lt;/p&gt;

&lt;p&gt;这里的doExecute返回的是一个中间类型的RDD。&lt;/p&gt;

</description>
                <link>http://turbofei.github.io/spark/2018/07/27/Spark-Sql-Analysis</link>
                <guid>http://turbofei.github.io/spark/2018/07/27/Spark-Sql-Analysis</guid>
                <pubDate>2018-07-27T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Rdd Basics</title>
                <description>
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;从RDD入手, 对Spark进行深入理解&lt;/p&gt;

&lt;h3 id=&quot;正文&quot;&gt;正文&lt;/h3&gt;
&lt;p&gt;是之前做的html格式的PPT，&lt;a href=&quot;https://netease-bigdata.github.io/ne-spark-courseware/slides/spark_core/rdd_basics.html#1&quot;&gt;链接&lt;/a&gt;&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/spark/2018/07/12/rdd-basics</link>
                <guid>http://turbofei.github.io/spark/2018/07/12/rdd-basics</guid>
                <pubDate>2018-07-12T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Deca项目总结</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;Deca项目是研究生期间参加的重要科研项目，项目主要是采用去对象化的思想，减少大数据平台在运行过程中，数据的占有空间与对象的数量，从而减小内存的压力，也减小GC的压力。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;实现的功能&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;deca主要实现的功能就是减小了大数据平台在运行任务过程中的数据在内存中的占用量以及在运行过程中对象的数量。&lt;/p&gt;

&lt;p&gt;当前的主流分布式内存计算系统均采用&lt;code class=&quot;highlighter-rouge&quot;&gt;高级托管语言&lt;/code&gt;开发，这样开发进度快，方便部署和维护。&lt;/p&gt;

&lt;p&gt;GC是托管语言（JAVA,SCALA等）的运行时系统自主管理对象的基础，GC操作会检索当前堆中存活的对象，并释放已经死亡对象的空间。&lt;/p&gt;

&lt;p&gt;大量数据均以对象形式存放在内存中，这对导致两个问题&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;内存膨胀问题&lt;/p&gt;

    &lt;p&gt;对象形式的内存布局会存储大量引用结构和元数据（对象头），而不是直接存储数据，空间利用率较低。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Full GC 问题&lt;/p&gt;

    &lt;p&gt;内存膨胀会导致JVM更加频繁的触发full gc（检索整个JVM堆内存），而GC开销与&lt;code class=&quot;highlighter-rouge&quot;&gt;存活对象数量&lt;/code&gt;成正比，导致GC时间过长。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这里引申一下gc的分类，gc分为minor gc, major gc 和 full gc。其中minor是清理年轻代，major是清理老年代，而full是清理整个堆空间。&lt;/p&gt;

&lt;p&gt;因此在面临使用内存空间有限的情况下，必须在软件层面对内存管理进行优化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;技术和架构&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;问题分析&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;spark是开源系统中主导的数据并行计算框架，提供函数式编程模型RDD，并增加了基于shuffle的GroupBy系列运算符扩展，支持中间数据的内存缓存和基于哈希的shuffle聚合操作。&lt;/p&gt;

&lt;p&gt;spark将数据封装在RDD中，然后通过action划分job，再通过shuffle操作划分stage，然后在jvm中运行数据。&lt;/p&gt;

&lt;p&gt;因此spark中的内存主要分为三部分。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Cache RDD到内存&lt;/p&gt;

    &lt;p&gt;这部分内存需要一直维护，只要用户进行unpersist操作，所以这部分内存生命周期较长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;shuffle操作(生命周期是一个stage)&lt;/p&gt;

    &lt;p&gt;shuffle操作需要落磁盘，进行磁盘I/O,因此需要维护所有磁盘I/O的数据，生命周期也长。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;stage内部的操作&lt;/p&gt;

    &lt;p&gt;产生大量的临时对象，属于内存中的临时对象，很快会被gc回收。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;长时间存活对象&lt;/code&gt;会一直活在内存中，每次Full GC 要扫描的对象数量很多，计算开销很大。而且对象一直存活，会大量占用内存，频繁导致full gc。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;方法设计&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;核心思想是减少数据&lt;code class=&quot;highlighter-rouge&quot;&gt;对象的数量&lt;/code&gt;，而非数据的大小。&lt;/p&gt;

&lt;p&gt;使用对象拆解，暴露出数据对象中的&lt;code class=&quot;highlighter-rouge&quot;&gt;裸数据&lt;/code&gt;：原生字段类型；去除对象头和引用结构。&lt;/p&gt;

&lt;p&gt;基于生命周期的内存管理：将相同/相近生命周期的一组数据对象中的裸数据存放在连续的内存块（数组）中。&lt;/p&gt;

&lt;p&gt;数据无需访问时即可一次回收整个内存块空间。&lt;/p&gt;

&lt;p&gt;这样GC的索引由大量的对象变为少量的容器，gc开销大大减小。&lt;/p&gt;

&lt;p&gt;将UDT(用户定义类型）分为三类：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;静态定长：原生类型及其组合，如int, long, (int, long)&lt;/li&gt;
  &lt;li&gt;动态定长：原生类型的数组及组合，如int[], (int[], long)&lt;/li&gt;
  &lt;li&gt;变长对象和递归类型对象：实例化对象长度不确定，如TreeNode（TreeNode里面有一个TreeNode引用的left,right)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;前两种可以安全拆解，第三种不行。&lt;/p&gt;

&lt;p&gt;针对以上的三种内存，其中cache RDD，当cache的数据对象可以拆解时候，可以拆解为Bytes数组依次存放在page中，同时根据page对象中对象offset可以获得对象成员变量。&lt;/p&gt;

&lt;p&gt;而针对shuffle内存，也是放在page里面，针对shuffle阶段的排序，使用指针，避免大量数据的移动。&lt;/p&gt;

&lt;p&gt;在shuffle 阶段存在很多变长的成员，在shuffle阶段，reduceByKey尚能拆解，因为reduce之后的value依然是定长的。但是针对groupByKey这个算子，他的操作对象是（K,combinerBuffer)，combiner是变长的，group之后也是变长，是不确定的。&lt;/p&gt;

&lt;p&gt;Spark-1.4里groupByKey在shuffle write端可以利用到堆外的内存，也就是tungsten-sort，所有的数据都会写在堆外并在堆外排序，但是shuffle-read端Spark默认还是用的HashShuffleReader,所有的聚合操作都在堆内完成，这个我们已经实现了read端的堆外版本，聚合操作运行在堆外。大致介绍下原理，这里就用到了VST拆解的原理，我们知道shuffle read端读出来的(K,C)对的基本类型，于是先实现了一个简易的map(UnsafeUnfixedWidthAggregationFlintMap),嗯名字略长。。这是一个针对系统的定制的map，也是用到了Hash原理，不过所有操作都是在堆外进行。这个map用于存储key和&lt;strong&gt;valueAddress&lt;/strong&gt;，这个&lt;strong&gt;valueAddress&lt;/strong&gt;是一个long型值，我们会将K对应的一组Value在堆外开辟一片疆土用于存储他们，当然每次新来value时我们会检查是否扩容，若扩容会改变这块疆土(堆外空间)的起始地址，因为涉及到内存的拷贝，所以map中的&lt;strong&gt;valueAddress&lt;/strong&gt;就是这块存储区域的初始偏移地址。&lt;strong&gt;valueAddress&lt;/strong&gt;指向的存储区域结构为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://kzx1025.github.io/img/map.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果每个partition相同的key不多，而且每个key存在大量value时，采用mapsideCombine的groupBykey是一个不错的选择。如果不存在hot key，那收益就很小。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;担当的责任&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;主要是担任shuffle groupByKey read 阶段的内存优化，我实现了read端的堆外版本，聚合操作运行在堆外。大致介绍下原理，这里就用到了VST拆解的原理，我们知道shuffle read端读出来的(K,C)对的基本类型，于是先实现了一个简易的map(UnsafeUnfixedWidthAggregationFlintMap),嗯名字略长。。这是一个针对系统的定制的map，也是用到了Hash原理，不过所有操作都是在堆外进行。这个map用于存储key和&lt;strong&gt;valueAddress&lt;/strong&gt;，这个&lt;strong&gt;valueAddress&lt;/strong&gt;是一个long型值，我们会将K对应的一组Value在堆外开辟一片疆土用于存储他们，当然每次新来value时我们会检查是否扩容，若扩容会改变这块疆土(堆外空间)的起始地址，因为涉及到内存的拷贝，所以map中的&lt;strong&gt;valueAddress&lt;/strong&gt;就是这块存储区域的初始偏移地址。&lt;/p&gt;

&lt;p&gt;这样就处理了变长类型的处理，之前是只实现了reduceBykey的。&lt;/p&gt;

&lt;p&gt;后面我们也尝试了&lt;code class=&quot;highlighter-rouge&quot;&gt;列式存储&lt;/code&gt;，把之前page中的数组形式，转换为列式存储。&lt;/p&gt;

&lt;p&gt;同时负责实验的设计，实验过程中遇到bug的解决以及gc统计分析的工作。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;难点&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;spark是惰性执行，代码中充满着各种各样的迭代器，追踪代码时都不知道哪个迭代器被调用了。修改代码需要连环的修改多个文件。&lt;/p&gt;

&lt;p&gt;然后就是有时候单机测试可以通过，但是分布式时候就。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;收获&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mark&lt;/code&gt;&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/essay/2017/07/01/deca%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93</link>
                <guid>http://turbofei.github.io/essay/2017/07/01/deca项目总结</guid>
                <pubDate>2017-07-01T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Spark源码分析shuffle实现</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#shuffle&quot; id=&quot;markdown-toc-shuffle&quot;&gt;Shuffle&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#bypassmergesortshufflewriter&quot; id=&quot;markdown-toc-bypassmergesortshufflewriter&quot;&gt;BypassMergeSortShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sortshufflewriter&quot; id=&quot;markdown-toc-sortshufflewriter&quot;&gt;SortShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#unsafeshufflewriter&quot; id=&quot;markdown-toc-unsafeshufflewriter&quot;&gt;unsafeShuffleWriter&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#blockstoreshufflereader&quot; id=&quot;markdown-toc-blockstoreshufflereader&quot;&gt;BlockStoreShuffleReader&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#总结&quot; id=&quot;markdown-toc-总结&quot;&gt;总结&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark shuff部分是spark源码的重要组成部分，shuffle发生在stage的交界处，对于spark的性能有重要影响，源码更新后，spark的shuffle机制也不一样，本文分析spark2.0的shuffle实现。&lt;/p&gt;

&lt;p&gt;本文基于spark2.0。&lt;/p&gt;

&lt;h2 id=&quot;shuffle&quot;&gt;Shuffle&lt;/h2&gt;

&lt;p&gt;shuffle是Mapreduce框架中一个特定的phase，介于Map和Reduce之间。shuffle的英文意思是混洗，包含两个部分，shuffle write 和shuffle read。这里有一篇文章:&lt;a href=&quot;http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/&quot;&gt;详细探究Spark的shuffle实现&lt;/a&gt;，这篇文章写于2014年，讲的是早期版本的shuffle实现。随着源码的更新，shuffle机制也做出了相应的优化，下面分析spark-2.0的shuffle机制。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;shuffleWriter&lt;/code&gt;是一个抽象类，具体实现有三种，&lt;code class=&quot;highlighter-rouge&quot;&gt;BypassMergeSortShuffleWriter&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;sortShuffleWriter&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;UnsafeShuffleWriter&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;bypassmergesortshufflewriter&quot;&gt;BypassMergeSortShuffleWriter&lt;/h3&gt;

&lt;p&gt;-_-,我先翻译下这个类开头给的注释，注释是很好的全局理解代码的工具，要好好理解。如下：&lt;/p&gt;

&lt;p&gt;这个类实现了基于sort-shuffle的hash风格的shuffle fallback path（回退路径？怎么翻）。这个write路径把数据写到不同的文件里，每个文件对应一个reduce分区，然后把这些文件整合到一个单独的文件，这个文件的不同区域服务不同的reducer。数据不是缓存在内存中。这个类本质上和之前的&lt;code class=&quot;highlighter-rouge&quot;&gt;HashShuffleReader&lt;/code&gt;，除了这个类的输出格式可以通过&lt;code class=&quot;highlighter-rouge&quot;&gt;org.apache.spark.shuffle.IndexShuffleBlockResolver&lt;/code&gt;来调用。这个写路径对于有许多reduce分区的shuffle来说是不高效的，因为他同时打开很多serializers和文件流。因此只有在以下情况下才会选择这个路径：&lt;/p&gt;

&lt;p&gt;1、没有排序  2、没有聚合操作  3、partition的数量小于bypassMergeThreshold&lt;/p&gt;

&lt;p&gt;这个代码曾经是ExternalSorter的一部分，但是为了减少代码复杂度就独立了出来。好，翻译结束。-_-&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void write(Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  assert (partitionWriters == null);
  if (!records.hasNext()) {
    partitionLengths = new long[numPartitions];
    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, null);
    mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);
    return;
  }
  final SerializerInstance serInstance = serializer.newInstance();
  final long openStartTime = System.nanoTime();
  partitionWriters = new DiskBlockObjectWriter[numPartitions];
  for (int i = 0; i &amp;lt; numPartitions; i++) {
    final Tuple2&amp;lt;TempShuffleBlockId, File&amp;gt; tempShuffleBlockIdPlusFile =
      blockManager.diskBlockManager().createTempShuffleBlock();
    final File file = tempShuffleBlockIdPlusFile._2();
    final BlockId blockId = tempShuffleBlockIdPlusFile._1();
    partitionWriters[i] =
      blockManager.getDiskWriter(blockId, file, serInstance, fileBufferSize, writeMetrics);
  }
  // Creating the file to write to and creating a disk writer both involve interacting with
  // the disk, and can take a long time in aggregate when we open many files, so should be
  // included in the shuffle write time.
  writeMetrics.incWriteTime(System.nanoTime() - openStartTime);

  while (records.hasNext()) {
    final Product2&amp;lt;K, V&amp;gt; record = records.next();
    final K key = record._1();
    partitionWriters[partitioner.getPartition(key)].write(key, record._2());
  }

  for (DiskBlockObjectWriter writer : partitionWriters) {
    writer.commitAndClose();
  }

  File output = shuffleBlockResolver.getDataFile(shuffleId, mapId);
  File tmp = Utils.tempFileWith(output);
  try {
    partitionLengths = writePartitionedFile(tmp);
    shuffleBlockResolver.writeIndexFileAndCommit(shuffleId, mapId, partitionLengths, tmp);
  } finally {
    if (tmp.exists() &amp;amp;&amp;amp; !tmp.delete()) {
      logger.error(&quot;Error while deleting temp file {}&quot;, tmp.getAbsolutePath());
    }
  }
  mapStatus = MapStatus$.MODULE$.apply(blockManager.shuffleServerId(), partitionLengths);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;前面都很好理解，就是根据key的哈希值写到不同的文件里面，然后就是&lt;code class=&quot;highlighter-rouge&quot;&gt;writePartitionedFile&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;writeIndexFileAndCommit&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Concatenate all of the per-partition files into a single combined file.
 *
 * @return array of lengths, in bytes, of each partition of the file (used by map output tracker).
 */
private long[] writePartitionedFile(File outputFile) throws IOException {
  // Track location of the partition starts in the output file
  final long[] lengths = new long[numPartitions];
  if (partitionWriters == null) {
    // We were passed an empty iterator
    return lengths;
  }

  final FileOutputStream out = new FileOutputStream(outputFile, true);
  final long writeStartTime = System.nanoTime();
  boolean threwException = true;
  try {
    for (int i = 0; i &amp;lt; numPartitions; i++) {
      final File file = partitionWriters[i].fileSegment().file();
      if (file.exists()) {
        final FileInputStream in = new FileInputStream(file);
        boolean copyThrewException = true;
        try {
          lengths[i] = Utils.copyStream(in, out, false, transferToEnabled);
          copyThrewException = false;
        } finally {
          Closeables.close(in, copyThrewException);
        }
        if (!file.delete()) {
          logger.error(&quot;Unable to delete file for partition {}&quot;, i);
        }
      }
    }
    threwException = false;
  } finally {
    Closeables.close(out, threwException);
    writeMetrics.incWriteTime(System.nanoTime() - writeStartTime);
  }
  partitionWriters = null;
  return lengths;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个就是按顺序把之前写的分区文件里的数据合并到一个大文件里面，然后返回每个分区文件的长度。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Write an index file with the offsets of each block, plus a final offset at the end for the
 * end of the output file. This will be used by getBlockData to figure out where each block
 * begins and ends.
 *
 * It will commit the data and index file as an atomic operation, use the existing ones, or
 * replace them with new ones.
 *
 * Note: the `lengths` will be updated to match the existing index file if use the existing ones.
 * */
def writeIndexFileAndCommit(
    shuffleId: Int,
    mapId: Int,
    lengths: Array[Long],
    dataTmp: File): Unit = {
  val indexFile = getIndexFile(shuffleId, mapId)
  val indexTmp = Utils.tempFileWith(indexFile)
  try {
    val out = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(indexTmp)))
    Utils.tryWithSafeFinally {
      // We take in lengths of each block, need to convert it to offsets.
      var offset = 0L
      out.writeLong(offset)
      for (length &amp;lt;- lengths) {
        offset += length
        out.writeLong(offset)
      }
    } {
      out.close()
    }

    val dataFile = getDataFile(shuffleId, mapId)
    // There is only one IndexShuffleBlockResolver per executor, this synchronization make sure
    // the following check and rename are atomic.
    synchronized {
      val existingLengths = checkIndexAndDataFile(indexFile, dataFile, lengths.length)
      if (existingLengths != null) {
        // Another attempt for the same task has already written our map outputs successfully,
        // so just use the existing partition lengths and delete our temporary map outputs.
        System.arraycopy(existingLengths, 0, lengths, 0, lengths.length)
        if (dataTmp != null &amp;amp;&amp;amp; dataTmp.exists()) {
          dataTmp.delete()
        }
        indexTmp.delete()
      } else {
        // This is the first successful attempt in writing the map outputs for this task,
        // so override any existing index and data files with the ones we wrote.
        if (indexFile.exists()) {
          indexFile.delete()
        }
        if (dataFile.exists()) {
          dataFile.delete()
        }
        if (!indexTmp.renameTo(indexFile)) {
          throw new IOException(&quot;fail to rename file &quot; + indexTmp + &quot; to &quot; + indexFile)
        }
        if (dataTmp != null &amp;amp;&amp;amp; dataTmp.exists() &amp;amp;&amp;amp; !dataTmp.renameTo(dataFile)) {
          throw new IOException(&quot;fail to rename file &quot; + dataTmp + &quot; to &quot; + dataFile)
        }
      }
    }
  } finally {
    if (indexTmp.exists() &amp;amp;&amp;amp; !indexTmp.delete()) {
      logError(s&quot;Failed to delete temporary index file at ${indexTmp.getAbsolutePath}&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解释下这段代码，上来先写indexTmp，是把分区文件长度写进去，便于索引需要的那部分数据。然后就判断这个任务是不是第一次执行到这里，如果之前执行成功过，那就不用写了，直接用以前的结果就行。&lt;/p&gt;

&lt;p&gt;如果是第一次执行到这里，那么就把之前的indexTmp重命名为indexFile，dataTmp重命名为dataFile然后返回。&lt;/p&gt;

&lt;p&gt;这里要注意下，每个executor上面只有一个&lt;code class=&quot;highlighter-rouge&quot;&gt;IndexShuffleBlockResolver&lt;/code&gt;，这个管理这个executor上所有的indexFile.&lt;/p&gt;

&lt;p&gt;等这个indexFile也写好之后，就返回&lt;code class=&quot;highlighter-rouge&quot;&gt;mapStatus&lt;/code&gt;。shuffleWrite就结束了。&lt;/p&gt;

&lt;h3 id=&quot;sortshufflewriter&quot;&gt;SortShuffleWriter&lt;/h3&gt;

&lt;p&gt;首先描述下大概。因为是sort，所以要排序，这里就用到了ExternalSoter这个数据结构。然后把要处理的数据全部插入到ExternalSorter里面，在插入的过程中是不排序的，就是插入，插入数据是(partitionId,key,value)。然后是调用&lt;code class=&quot;highlighter-rouge&quot;&gt; sorter.writePartitionedFile&lt;/code&gt;,在这里会排序，会按照partitionId和key（或者key的hashcode）进行排序，其他的就和上面bypassShuffleWriter的差不多了，最后也是写到一个indexFile里面。返回mapStatus。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Write a bunch of records to this task's output */
override def write(records: Iterator[Product2[K, V]]): Unit = {
  sorter = if (dep.mapSideCombine) {
    require(dep.aggregator.isDefined, &quot;Map-side combine without Aggregator specified!&quot;)
    new ExternalSorter[K, V, C](
      context, dep.aggregator, Some(dep.partitioner), dep.keyOrdering, dep.serializer)
  } else {
    // In this case we pass neither an aggregator nor an ordering to the sorter, because we don't
    // care whether the keys get sorted in each partition; that will be done on the reduce side
    // if the operation being run is sortByKey.
    new ExternalSorter[K, V, V](
      context, aggregator = None, Some(dep.partitioner), ordering = None, dep.serializer)
  }
  sorter.insertAll(records)

  // Don't bother including the time to open the merged output file in the shuffle write time,
  // because it just opens a single file, so is typically too fast to measure accurately
  // (see SPARK-3570).
  val output = shuffleBlockResolver.getDataFile(dep.shuffleId, mapId)
  val tmp = Utils.tempFileWith(output)
  try {
    val blockId = ShuffleBlockId(dep.shuffleId, mapId, IndexShuffleBlockResolver.NOOP_REDUCE_ID)
    val partitionLengths = sorter.writePartitionedFile(blockId, tmp)
    shuffleBlockResolver.writeIndexFileAndCommit(dep.shuffleId, mapId, partitionLengths, tmp)
    mapStatus = MapStatus(blockManager.shuffleServerId, partitionLengths)
  } finally {
    if (tmp.exists() &amp;amp;&amp;amp; !tmp.delete()) {
      logError(s&quot;Error while deleting temp file ${tmp.getAbsolutePath}&quot;)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里面ExternalSorter是核心。看它的源码，它存数据是使用的两种数据结构。&lt;code class=&quot;highlighter-rouge&quot;&gt;PartitionedAppendOnlyMap&lt;/code&gt;、&lt;code class=&quot;highlighter-rouge&quot;&gt;PartitionedPairBuffer&lt;/code&gt;，其中有聚合操作使用map，没有聚合操作使用buffer。PartitionedAppendOnlyMap 继承了SizeTrackingAppendOnlyMap 和WritablePartitionedPairCollection 。 其中SizeTrackingAppendOnlyMap是用于预测空间（SizeTracker），然后加存储数据（AppendOnlyMap）,然后WritablePartitionedPairCollection是用于插入数据时候插入partitionId（insert(partition: Int, key: K, value: V)）加上里面实现了对数据按照partitionId和Key排序的方法。&lt;/p&gt;

&lt;p&gt;我主要是对AppendOnlyMap怎么存储数据比较感兴趣。看下AppendOnlyMap。&lt;/p&gt;

&lt;p&gt;看源码，它存储数据是&lt;code class=&quot;highlighter-rouge&quot;&gt;private var data = new Array[AnyRef](2 * capacity)&lt;/code&gt;,是使用数组存储的，key和value挨着，这样做是为了节省空间。&lt;/p&gt;

&lt;p&gt;然后map的Update和changeValue函数是差不多的，只不过后者的changeValue是由计算函数计算的value，所以我们就看update方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Set the value for a key */
def update(key: K, value: V): Unit = {
  assert(!destroyed, destructionMessage)
  val k = key.asInstanceOf[AnyRef]
  if (k.eq(null)) {
    if (!haveNullValue) {
      incrementSize()
    }
    nullValue = value
    haveNullValue = true
    return
  }
  var pos = rehash(key.hashCode) &amp;amp; mask
  var i = 1
  while (true) {
    val curKey = data(2 * pos)
    if (curKey.eq(null)) {
      data(2 * pos) = k
      data(2 * pos + 1) = value.asInstanceOf[AnyRef]
      incrementSize()  // Since we added a new key
      return
    } else if (k.eq(curKey) || k.equals(curKey)) {
      data(2 * pos + 1) = value.asInstanceOf[AnyRef]
      return
    } else {
      val delta = i
      pos = (pos + delta) &amp;amp; mask
      i += 1
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看源码可以看出，这里插入数据，采用的二次探测法。java.util.collection的HashMap在hash冲突时候采用的是链接法，而这里的二次探测法缺点就是删除元素时候比较复杂，不能简单的把数组中的相应位置设为null，这样就没办法查找元素，通常是把被删除的元素标记为已删除，但是又需要占据额外的空间。但是此处是appendOnlyMap，也就是只会追加（插入或者更新），不会删除，所以这个自定义的map更省内存。&lt;/p&gt;

&lt;p&gt;然后这个AppendOnlyMap会在growMap的时候重新hash。在sorter.insertall时候是不排序的。&lt;/p&gt;

&lt;p&gt;然后writePartitionedFile 里面调用&lt;code class=&quot;highlighter-rouge&quot;&gt;collection.destructiveSortedWritablePartitionedIterator(comparator)	&lt;/code&gt;会对数据排序，之后就跟上一小节里面的writePartitionedFile差不多了，无非就是把内存里面的数据和spill的数据合并之后写入大文件里面，之后的writeIndexFile是一样的，就不细说。&lt;/p&gt;

&lt;h3 id=&quot;unsafeshufflewriter&quot;&gt;unsafeShuffleWriter&lt;/h3&gt;

&lt;p&gt;这里之所以叫作unsafe，是因为要操纵堆外内存，把数据写到堆外，堆外内存是不受jvm控制的，需要手动进行申请内存与释放内存空间，所以是unsafe的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@Override
public void write(scala.collection.Iterator&amp;lt;Product2&amp;lt;K, V&amp;gt;&amp;gt; records) throws IOException {
  // Keep track of success so we know if we encountered an exception
  // We do this rather than a standard try/catch/re-throw to handle
  // generic throwables.
  boolean success = false;
  try {
    while (records.hasNext()) {
      insertRecordIntoSorter(records.next());
    }
    closeAndWriteOutput();
    success = true;
  } finally {
    if (sorter != null) {
      try {
        sorter.cleanupResources();
      } catch (Exception e) {
        // Only throw this error if we won't be masking another
        // error.
        if (success) {
          throw e;
        } else {
          logger.error(&quot;In addition to a failure during writing, we failed during &quot; +
                       &quot;cleanup.&quot;, e);
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;除了是写到堆外，其他应该跟sortShuffleWriter 差不多吧，懒得写了，以后发现有什么特别之处再补充。&lt;/p&gt;

&lt;h3 id=&quot;blockstoreshufflereader&quot;&gt;BlockStoreShuffleReader&lt;/h3&gt;

&lt;p&gt;前面三个shuffleWriter，shuffle分为shuffleWriter和shuffleReader。shuffleReadr只有一个具体实现类就是BlockStoreShuffleReader。看开头注释为：读取（startPartition和endPartition）之间的partition的数据，从其他节点。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Read the combined key-values for this reduce task */
override def read(): Iterator[Product2[K, C]] = {
  val blockFetcherItr = new ShuffleBlockFetcherIterator(
    context,
    blockManager.shuffleClient,
    blockManager,
    mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition),
    // Note: we use getSizeAsMb when no suffix is provided for backwards compatibility
    SparkEnv.get.conf.getSizeAsMb(&quot;spark.reducer.maxSizeInFlight&quot;, &quot;48m&quot;) * 1024 * 1024,
    SparkEnv.get.conf.getInt(&quot;spark.reducer.maxReqsInFlight&quot;, Int.MaxValue))

  // Wrap the streams for compression based on configuration
  val wrappedStreams = blockFetcherItr.map { case (blockId, inputStream) =&amp;gt;
    serializerManager.wrapForCompression(blockId, inputStream)
  }

  val serializerInstance = dep.serializer.newInstance()

  // Create a key/value iterator for each stream
  val recordIter = wrappedStreams.flatMap { wrappedStream =&amp;gt;
    // Note: the asKeyValueIterator below wraps a key/value iterator inside of a
    // NextIterator. The NextIterator makes sure that close() is called on the
    // underlying InputStream when all records have been read.
    serializerInstance.deserializeStream(wrappedStream).asKeyValueIterator
  }

  // Update the context task metrics for each record read.
  val readMetrics = context.taskMetrics.createTempShuffleReadMetrics()
  val metricIter = CompletionIterator[(Any, Any), Iterator[(Any, Any)]](
    recordIter.map { record =&amp;gt;
      readMetrics.incRecordsRead(1)
      record
    },
    context.taskMetrics().mergeShuffleReadMetrics())

  // An interruptible iterator must be used here in order to support task cancellation
  val interruptibleIter = new InterruptibleIterator[(Any, Any)](context, metricIter)

  val aggregatedIter: Iterator[Product2[K, C]] = if (dep.aggregator.isDefined) {
    if (dep.mapSideCombine) {
      // We are reading values that are already combined
      val combinedKeyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, C)]]
      dep.aggregator.get.combineCombinersByKey(combinedKeyValuesIterator, context)
    } else {
      // We don't know the value type, but also don't care -- the dependency *should*
      // have made sure its compatible w/ this aggregator, which will convert the value
      // type to the combined type C
      val keyValuesIterator = interruptibleIter.asInstanceOf[Iterator[(K, Nothing)]]
      dep.aggregator.get.combineValuesByKey(keyValuesIterator, context)
    }
  } else {
    require(!dep.mapSideCombine, &quot;Map-side combine without Aggregator specified!&quot;)
    interruptibleIter.asInstanceOf[Iterator[Product2[K, C]]]
  }

  // Sort the output if there is a sort ordering defined.
  dep.keyOrdering match {
    case Some(keyOrd: Ordering[K]) =&amp;gt;
      // Create an ExternalSorter to sort the data. Note that if spark.shuffle.spill is disabled,
      // the ExternalSorter won't spill to disk.
      val sorter =
        new ExternalSorter[K, C, C](context, ordering = Some(keyOrd), serializer = dep.serializer)
      sorter.insertAll(aggregatedIter)
      context.taskMetrics().incMemoryBytesSpilled(sorter.memoryBytesSpilled)
      context.taskMetrics().incDiskBytesSpilled(sorter.diskBytesSpilled)
      context.taskMetrics().incPeakExecutionMemory(sorter.peakMemoryUsedBytes)
      CompletionIterator[Product2[K, C], Iterator[Product2[K, C]]](sorter.iterator, sorter.stop())
    case None =&amp;gt;
      aggregatedIter
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;首先是建立一个&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleBlockFetcherIterator&lt;/code&gt;，传入的参数有&lt;code class=&quot;highlighter-rouge&quot;&gt;mapOutputTracker.getMapSizesByExecutorId(handle.shuffleId, startPartition, endPartition)&lt;/code&gt;,这个是必须的，只取需要的partition的数据。&lt;/p&gt;

&lt;p&gt;点进去ShuffleBlockFetcherIterator这个类，发现这个类会自动调用initialize()方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[this] def initialize(): Unit = {
  // Add a task completion callback (called in both success case and failure case) to cleanup.
  context.addTaskCompletionListener(_ =&amp;gt; cleanup())

  // Split local and remote blocks.
  val remoteRequests = splitLocalRemoteBlocks()
  // Add the remote requests into our queue in a random order
  fetchRequests ++= Utils.randomize(remoteRequests)
  assert ((0 == reqsInFlight) == (0 == bytesInFlight),
    &quot;expected reqsInFlight = 0 but found reqsInFlight = &quot; + reqsInFlight +
    &quot;, expected bytesInFlight = 0 but found bytesInFlight = &quot; + bytesInFlight)

  // Send out initial requests for blocks, up to our maxBytesInFlight
  fetchUpToMaxBytes()

  val numFetches = remoteRequests.size - fetchRequests.size
  logInfo(&quot;Started &quot; + numFetches + &quot; remote fetches in&quot; + Utils.getUsedTimeMs(startTime))

  // Get Local Blocks
  fetchLocalBlocks()
  logDebug(&quot;Got local blocks in &quot; + Utils.getUsedTimeMs(startTime))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个方法里面会&lt;code class=&quot;highlighter-rouge&quot;&gt;fetchUpToMaxBytes()&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;fetchLocalBlocks()&lt;/code&gt;,一个是取远程数据一个是取本地数据。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def fetchUpToMaxBytes(): Unit = {
  // Send fetch requests up to maxBytesInFlight
  while (fetchRequests.nonEmpty &amp;amp;&amp;amp;
    (bytesInFlight == 0 ||
      (reqsInFlight + 1 &amp;lt;= maxReqsInFlight &amp;amp;&amp;amp;
        bytesInFlight + fetchRequests.front.size &amp;lt;= maxBytesInFlight))) {
    sendRequest(fetchRequests.dequeue())
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里会设置一个阈值，避免过度负载的。&lt;code class=&quot;highlighter-rouge&quot;&gt;sendRequest&lt;/code&gt;来请求数据。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[this] def sendRequest(req: FetchRequest) {
  logDebug(&quot;Sending request for %d blocks (%s) from %s&quot;.format(
    req.blocks.size, Utils.bytesToString(req.size), req.address.hostPort))
  bytesInFlight += req.size
  reqsInFlight += 1

  // so we can look up the size of each blockID
  val sizeMap = req.blocks.map { case (blockId, size) =&amp;gt; (blockId.toString, size) }.toMap
  val remainingBlocks = new HashSet[String]() ++= sizeMap.keys
  val blockIds = req.blocks.map(_._1.toString)

  val address = req.address
  shuffleClient.fetchBlocks(address.host, address.port, address.executorId, blockIds.toArray,
    new BlockFetchingListener {
      override def onBlockFetchSuccess(blockId: String, buf: ManagedBuffer): Unit = {
        // Only add the buffer to results queue if the iterator is not zombie,
        // i.e. cleanup() has not been called yet.
        ShuffleBlockFetcherIterator.this.synchronized {
          if (!isZombie) {
            // Increment the ref count because we need to pass this to a different thread.
            // This needs to be released after use.
            buf.retain()
            remainingBlocks -= blockId
            results.put(new SuccessFetchResult(BlockId(blockId), address, sizeMap(blockId), buf,
              remainingBlocks.isEmpty))
            logDebug(&quot;remainingBlocks: &quot; + remainingBlocks)
          }
        }
        logTrace(&quot;Got remote block &quot; + blockId + &quot; after &quot; + Utils.getUsedTimeMs(startTime))
      }

      override def onBlockFetchFailure(blockId: String, e: Throwable): Unit = {
        logError(s&quot;Failed to get block(s) from ${req.address.host}:${req.address.port}&quot;, e)
        results.put(new FailureFetchResult(BlockId(blockId), address, e))
      }
    }
  )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;后面一大堆代码，反正就是取数据吗，就不细看了。&lt;/p&gt;

&lt;p&gt;取完数据之后，就通过dep.mapSideCombine判断是否在map端做了聚合操作，如果做了聚合操作，这里的(k,v)的v就是CompactBuffer类型，就调用combineCombinersByKey，如果在map端没有聚合，就还是value类型，就combineValuesByKey。&lt;/p&gt;

&lt;p&gt;之后就判断是否定义了排序，如果需要排序就用ExternalSorter排序。&lt;/p&gt;

&lt;p&gt;到这里shuffle过程就结束啦。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;前两种shuffleWriter（UnsafeShuffleWriter没细看）里的shuffleWrite端最后得到的文件都只是一个IndexFile，这跟&lt;a href=&quot;http://jerryshao.me/architecture/2014/01/04/spark-shuffle-detail-investigation/&quot;&gt;早期的shuffle机制&lt;/a&gt;还是不一样的。&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/spark/2016/12/26/spark%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90Shuffle%E5%AE%9E%E7%8E%B0</link>
                <guid>http://turbofei.github.io/spark/2016/12/26/spark源码分析Shuffle实现</guid>
                <pubDate>2016-12-26T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Spark内存预测</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sizetracker&quot; id=&quot;markdown-toc-sizetracker&quot;&gt;sizeTracker&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#sizeestimator&quot; id=&quot;markdown-toc-sizeestimator&quot;&gt;SizeEstimator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark是一个内存计算框架，因此内存是重要的资源，合理的使用的内存在spark应用在执行过程中非常重要。在使用内存的过程，spark会采用抽样的方法预测出所需要的内存，并预先分配内存。本文会就内存预测机制进行源码的解读。&lt;/p&gt;

&lt;h2 id=&quot;sizetracker&quot;&gt;sizeTracker&lt;/h2&gt;

&lt;p&gt;spark里面内存预测有一个trait，叫做&lt;code class=&quot;highlighter-rouge&quot;&gt; SizeTracker&lt;/code&gt;，然后有一些类实现了它，比如PartitionedAppendOnlyMap、SizeTrackingAppendOnlyMap。&lt;/p&gt;

&lt;p&gt;SizeTracker的estimateSize方法就是预测当前集合的size。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Estimate the current size of the collection in bytes. O(1) time.
 */
def estimateSize(): Long = {
  assert(samples.nonEmpty)
  val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates)
  (samples.last.size + extrapolatedDelta).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;其实这个sizeTracker类有四个方法，其他三个方法分别是&lt;code class=&quot;highlighter-rouge&quot;&gt;resetSamples&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;afterUpdate&lt;/code&gt;,&lt;code class=&quot;highlighter-rouge&quot;&gt;takeSample&lt;/code&gt;.看了下SizeTrackingAppendOnlyMap的流程，afterUpdata方法是在update或者changeValue之后会调用，其实updata和changeValue没有什么区别，只不过一个是直接更新k-v，另一个是使用一个函数计算后更新k-v。然后resetSamples是在growTable之后调用（SizeTrackingAppendOnlyMap的growTable就是空间翻一倍）。&lt;/p&gt;

&lt;p&gt;看下sizeTracker里面的参数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Controls the base of the exponential which governs the rate of sampling.
 * E.g., a value of 2 would mean we sample at 1, 2, 4, 8, ... elements.
 */
private val SAMPLE_GROWTH_RATE = 1.1

/** Samples taken since last resetSamples(). Only the last two are kept for extrapolation. */
private val samples = new mutable.Queue[Sample]

/** The average number of bytes per update between our last two samples. */
private var bytesPerUpdate: Double = _

/** Total number of insertions and updates into the map since the last resetSamples(). */
private var numUpdates: Long = _

/** The value of 'numUpdates' at which we will take our next sample. */
private var nextSampleNum: Long = _
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;SAMPLE_GROWTH_RATE&lt;/code&gt;是一个斜率，代表下次抽样时候更新的次数应该是这次抽样更新次数的1.1倍，比如上次是更新10000次时候抽样，下次抽样就得是更新11000次时候再抽样，可以避免每次更新都抽样，减少抽样花销。&lt;code class=&quot;highlighter-rouge&quot;&gt;samples&lt;/code&gt;是一个队列， 里面的类型是样例类&lt;code class=&quot;highlighter-rouge&quot;&gt;sample&lt;/code&gt;。然后&lt;code class=&quot;highlighter-rouge&quot;&gt;bytesPerUpdate&lt;/code&gt;是抽样之后得到区间增长量/个数增长量，就是一个斜率。然后&lt;code class=&quot;highlighter-rouge&quot;&gt;numUpdates&lt;/code&gt;就是代表抽样集合里面元素个数，&lt;code class=&quot;highlighter-rouge&quot;&gt;nextSampleNum&lt;/code&gt;代表下次要抽样的时候集合的个数，前面说过，就是此次抽样时候的个数*1.1.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Reset samples collected so far.
 * This should be called after the collection undergoes a dramatic change in size.
 */
protected def resetSamples(): Unit = {
  numUpdates = 1
  nextSampleNum = 1
  samples.clear()
  takeSample()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;resetSamples会在每次翻倍增长后，重置抽样参数，没啥好说的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Callback to be invoked after every update.
 */
protected def afterUpdate(): Unit = {
  numUpdates += 1
  if (nextSampleNum == numUpdates) {
    takeSample()
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个是每次更新后，都更新次数+1，然后当他等于下次抽样次数时候就进行抽样。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Take a new sample of the current collection's size.
 */
private def takeSample(): Unit = {
  samples.enqueue(Sample(SizeEstimator.estimate(this), numUpdates))
  // Only use the last two samples to extrapolate
  if (samples.size &amp;gt; 2) {
    samples.dequeue()
  }
  val bytesDelta = samples.toList.reverse match {
    case latest :: previous :: tail =&amp;gt;
      (latest.size - previous.size).toDouble / (latest.numUpdates - previous.numUpdates)
    // If fewer than 2 samples, assume no change
    case _ =&amp;gt; 0
  }
  bytesPerUpdate = math.max(0, bytesDelta)
  nextSampleNum = math.ceil(numUpdates * SAMPLE_GROWTH_RATE).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;抽样就是找出最近的两个sample，然后计算增长斜率，size增长量/num增长量，然后把下次抽样的次数*1.1更新下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Estimate the current size of the collection in bytes. O(1) time.
 */
def estimateSize(): Long = {
  assert(samples.nonEmpty)
  val extrapolatedDelta = bytesPerUpdate * (numUpdates - samples.last.numUpdates)
  (samples.last.size + extrapolatedDelta).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后这个estimateSize 就是上次的size+增长率*增长量。增长率和size就是上次抽样得到的。&lt;/p&gt;

&lt;p&gt;可以看到在takeSample方法里面加入队列时候size的预测用到了&lt;code class=&quot;highlighter-rouge&quot;&gt;SizeEstimator.estimate&lt;/code&gt;.看下这个SizeEstimator类。&lt;/p&gt;

&lt;h2 id=&quot;sizeestimator&quot;&gt;SizeEstimator&lt;/h2&gt;

&lt;p&gt;看下这类的estimate方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def estimate(obj: AnyRef, visited: IdentityHashMap[AnyRef, AnyRef]): Long = {
  val state = new SearchState(visited)
  state.enqueue(obj)
  while (!state.isFinished) {
    visitSingleObject(state.dequeue(), state)
  }
  state.size
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里主要是调用visitSingleObject。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def visitSingleObject(obj: AnyRef, state: SearchState) {
  val cls = obj.getClass
  if (cls.isArray) {
    visitArray(obj, cls, state)
  } else if (cls.getName.startsWith(&quot;scala.reflect&quot;)) {
    // Many objects in the scala.reflect package reference global reflection objects which, in
    // turn, reference many other large global objects. Do nothing in this case.
  } else if (obj.isInstanceOf[ClassLoader] || obj.isInstanceOf[Class[_]]) {
    // Hadoop JobConfs created in the interpreter have a ClassLoader, which greatly confuses
    // the size estimator since it references the whole REPL. Do nothing in this case. In
    // general all ClassLoaders and Classes will be shared between objects anyway.
  } else {
    obj match {
      case s: KnownSizeEstimation =&amp;gt;
        state.size += s.estimatedSize
      case _ =&amp;gt;
        val classInfo = getClassInfo(cls)
        state.size += alignSize(classInfo.shellSize)
        for (field &amp;lt;- classInfo.pointerFields) {
          state.enqueue(field.get(obj))
        }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果是Array类型，就visitArray。如果是scala.reflect开头的类，因为这个包里面涉及全局反射对象，因此涉及很多其他的大对象，所以这种对象不做任何操作。然后如果是classLoader类型，hadoop 作业在解释器中创建了classLoader，因为涉及整个REPL（读取-求值-处理-循环），所以很难处理。一般，所有classLoader和classes都是共享的。然后有的就是已经预测过的，直接读取。然后其他类型，就是拆解，拆成实际对象和引用，实际对象算出size相加，然后指针类型就把它指向的对象加入state队列，然后再进入while循环。直到state isFinished。&lt;/p&gt;

&lt;p&gt;接下来看看visitArray.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Estimate the size of arrays larger than ARRAY_SIZE_FOR_SAMPLING by sampling.
private val ARRAY_SIZE_FOR_SAMPLING = 400
private val ARRAY_SAMPLE_SIZE = 100 // should be lower than ARRAY_SIZE_FOR_SAMPLING

private def visitArray(array: AnyRef, arrayClass: Class[_], state: SearchState) {
  val length = ScalaRunTime.array_length(array)
  val elementClass = arrayClass.getComponentType()

  // Arrays have object header and length field which is an integer
  var arrSize: Long = alignSize(objectSize + INT_SIZE)

  if (elementClass.isPrimitive) {
    arrSize += alignSize(length.toLong * primitiveSize(elementClass))
    state.size += arrSize
  } else {
    arrSize += alignSize(length.toLong * pointerSize)
    state.size += arrSize

    if (length &amp;lt;= ARRAY_SIZE_FOR_SAMPLING) {
      var arrayIndex = 0
      while (arrayIndex &amp;lt; length) {
        state.enqueue(ScalaRunTime.array_apply(array, arrayIndex).asInstanceOf[AnyRef])
        arrayIndex += 1
      }
    } else {
      // Estimate the size of a large array by sampling elements without replacement.
      // To exclude the shared objects that the array elements may link, sample twice
      // and use the min one to calculate array size.
      val rand = new Random(42)
      val drawn = new OpenHashSet[Int](2 * ARRAY_SAMPLE_SIZE)
      val s1 = sampleArray(array, state, rand, drawn, length)
      val s2 = sampleArray(array, state, rand, drawn, length)
      val size = math.min(s1, s2)
      state.size += math.max(s1, s2) +
        (size * ((length - ARRAY_SAMPLE_SIZE) / (ARRAY_SAMPLE_SIZE))).toLong
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这段代码，首先要把&lt;code class=&quot;highlighter-rouge&quot;&gt;Array 的object 头部,长度 filed&lt;/code&gt;算进去，然后如果array里面的元素是基本类型，那么长度就固定，就可以直接算出来。&lt;/p&gt;

&lt;p&gt;如果不是基本类型，&lt;code class=&quot;highlighter-rouge&quot;&gt;就有指向对象的引用？&lt;/code&gt;所以代码里面先把length个指针占用的空间加上。&lt;/p&gt;

&lt;p&gt;如果这时候数组长度，小于采样时候数组长度那个界限，就把数组里面引用指向的对象加入state队列，也就是小于界限就全部计算size。&lt;/p&gt;

&lt;p&gt;如果数组长度大于采样时候数组长度的界限，就准备采样。然后采样两组，两组采样数据都是不重复的。计算公式如下:&lt;code class=&quot;highlighter-rouge&quot;&gt;math.max(s1, s2) + (math.min(s1, s2) * ((length - ARRAY_SAMPLE_SIZE) / (ARRAY_SAMPLE_SIZE)))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这个计算公式不知道有什么合理的地方，反正spark用这个公式，应该是有一定道理。&lt;/p&gt;

&lt;p&gt;就是  &lt;code class=&quot;highlighter-rouge&quot;&gt;math.min(s1,s2)*(length-ARRAY_SAMPLE_SIZE)+abs(s1-s2)&lt;/code&gt;，这应该是为了不让内存预估过大，以免占用太多，同时用一个小的增量对这个偏小的预估进行补偿。&lt;/p&gt;

</description>
                <link>http://turbofei.github.io/spark/2016/12/26/spark%E5%86%85%E5%AD%98%E9%A2%84%E6%B5%8B</link>
                <guid>http://turbofei.github.io/spark/2016/12/26/spark内存预测</guid>
                <pubDate>2016-12-26T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>Spark应用执行流程</title>
                <description>
&lt;p&gt;目录&lt;/p&gt;

&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#background&quot; id=&quot;markdown-toc-background&quot;&gt;Background&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#word-count&quot; id=&quot;markdown-toc-word-count&quot;&gt;Word Count&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#理论剖析&quot; id=&quot;markdown-toc-理论剖析&quot;&gt;理论剖析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#源码剖析&quot; id=&quot;markdown-toc-源码剖析&quot;&gt;源码剖析&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提交job&quot; id=&quot;markdown-toc-提交job&quot;&gt;提交job&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#划分stage&quot; id=&quot;markdown-toc-划分stage&quot;&gt;划分stage&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#提交tasks&quot; id=&quot;markdown-toc-提交tasks&quot;&gt;提交tasks&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#执行task&quot; id=&quot;markdown-toc-执行task&quot;&gt;执行task&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#shufflemaptask&quot; id=&quot;markdown-toc-shufflemaptask&quot;&gt;ShuffleMapTask&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#resulttask&quot; id=&quot;markdown-toc-resulttask&quot;&gt;ResultTask&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#rdd-迭代链&quot; id=&quot;markdown-toc-rdd-迭代链&quot;&gt;rdd 迭代链&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#检查点&quot; id=&quot;markdown-toc-检查点&quot;&gt;检查点&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#compute-链&quot; id=&quot;markdown-toc-compute-链&quot;&gt;compute 链&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#参考&quot; id=&quot;markdown-toc-参考&quot;&gt;参考&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;从最简单的spark应用WordCount入手，分析rdd链，分析job如何提交，task如何提交，从全局了解spark应用的执行流程。&lt;/p&gt;

&lt;h2 id=&quot;word-count&quot;&gt;Word Count&lt;/h2&gt;

&lt;p&gt;word count是spark 最基本的小程序，主要功能就是统计一个文件里面各个单词出现的个数。代码很简洁，如下。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import org.apache.spark.{SparkConf, SparkContext}

object SparkWC {
  def main(args: Array[String]) {
    val sparkConf = new SparkConf()
    val sparkContext = new SparkContext(sparkConf)
    sparkContext.textFile(args(0))
          .flatMap(line =&amp;gt; line.split(&quot; &quot;))
          .map(word =&amp;gt; (word, 1))
          .reduceByKey(_ + _)
          .saveAsTextFile(args(1))
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;理论剖析&quot;&gt;理论剖析&lt;/h3&gt;
&lt;p&gt;里面的RDD链，用他们的操作表示，就是textFile-&amp;gt;flatMap-&amp;gt;map-&amp;gt;reduceBykey-&amp;gt;saveAsTextFile.&lt;/p&gt;

&lt;p&gt;spark里面有两种操作，&lt;code class=&quot;highlighter-rouge&quot;&gt;action&lt;/code&gt; 和&lt;code class=&quot;highlighter-rouge&quot;&gt;transformation&lt;/code&gt;，其中action会触发提交job的操作，transformation不会触发job，只是进行rdd的转换。而不同transformation操作的rdd链两端的依赖关系也不同，spark中的rdd依赖有两种，分别是&lt;code class=&quot;highlighter-rouge&quot;&gt;narrow dependency&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;wide dependency&lt;/code&gt; ,这两种依赖如下图所示。
&lt;br /&gt;
&lt;img src=&quot;http://ogk82bfkr.bkt.clouddn.com/upload/narrow-depen.png&quot; height=&quot;200&quot; width=&quot;200&quot; /&gt;
      
&lt;img src=&quot;http://ogk82bfkr.bkt.clouddn.com/upload/wide-depen.png&quot; height=&quot;200&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边图是窄依赖，右边图是宽依赖，窄依赖里面的partition的对应顺序是不变的，款依赖会涉及shuffle操作，会造成partition混洗，因此往往以款依赖划分stage。在上面的操作中，saveAsTextFile是action，reduceByKey是宽依赖，因此这个应用总共有1个job，两个stage，然后在不同的stage中会执行tasks。&lt;/p&gt;

&lt;h3 id=&quot;源码剖析&quot;&gt;源码剖析&lt;/h3&gt;

&lt;p&gt;从rdd链开始分析。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def textFile(
      path: String,
      minPartitions: Int = defaultMinPartitions): RDD[String] = withScope {
    assertNotStopped()
    hadoopFile(path, classOf[TextInputFormat], classOf[LongWritable], classOf[Text],
      minPartitions).map(pair =&amp;gt; pair._2.toString).setName(path)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;textFile 这个算子的返回结果是一个RDD，然后RDD链就开始了，可以看出来他调用了一些新的函数，比如hadoopFile啥的，这些我们都不管，因为他们都没有触发 commitJob，所以这些中间过程我们就省略，直到saveAsTextFile这个action。&lt;/p&gt;

&lt;h3 id=&quot;提交job&quot;&gt;提交job&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def saveAsTextFile(path: String): Unit = withScope {
    // https://issues.apache.org/jira/browse/SPARK-2075
    //
    // NullWritable is a `Comparable` in Hadoop 1.+, so the compiler cannot find an implicit
    // Ordering for it and will use the default `null`. However, it's a `Comparable[NullWritable]`
    // in Hadoop 2.+, so the compiler will call the implicit `Ordering.ordered` method to create an
    // Ordering for `NullWritable`. That's why the compiler will generate different anonymous
    // classes for `saveAsTextFile` in Hadoop 1.+ and Hadoop 2.+.
    //
    // Therefore, here we provide an explicit Ordering `null` to make sure the compiler generate
    // same bytecodes for `saveAsTextFile`.
    val nullWritableClassTag = implicitly[ClassTag[NullWritable]]
    val textClassTag = implicitly[ClassTag[Text]]
    val r = this.mapPartitions { iter =&amp;gt;
      val text = new Text()
      iter.map { x =&amp;gt;
        text.set(x.toString)
        (NullWritable.get(), text)
      }
    }
    RDD.rddToPairRDDFunctions(r)(nullWritableClassTag, textClassTag, null)
      .saveAsHadoopFile[TextOutputFormat[NullWritable, Text]](path)
  }
  
  
  //接下来调用这个
  def saveAsHadoopFile[F &amp;lt;: OutputFormat[K, V]](
      path: String)(implicit fm: ClassTag[F]): Unit = self.withScope {
    saveAsHadoopFile(path, keyClass, valueClass, fm.runtimeClass.asInstanceOf[Class[F]])
  }
  
//省略一部分调用过程
...
...

//最后调用这个函数
  def saveAsHadoopDataset(conf: JobConf): Unit = self.withScope {
    // Rename this as hadoopConf internally to avoid shadowing (see SPARK-2038).
    val hadoopConf = conf
    val outputFormatInstance = hadoopConf.getOutputFormat
    val keyClass = hadoopConf.getOutputKeyClass
    val valueClass = hadoopConf.getOutputValueClass
    if (outputFormatInstance == null) {
      throw new SparkException(&quot;Output format class not set&quot;)
    }
    if (keyClass == null) {
      throw new SparkException(&quot;Output key class not set&quot;)
    }
    if (valueClass == null) {
      throw new SparkException(&quot;Output value class not set&quot;)
    }
    SparkHadoopUtil.get.addCredentials(hadoopConf)

    logDebug(&quot;Saving as hadoop file of type (&quot; + keyClass.getSimpleName + &quot;, &quot; +
      valueClass.getSimpleName + &quot;)&quot;)

    if (isOutputSpecValidationEnabled) {
      // FileOutputFormat ignores the filesystem parameter
      val ignoredFs = FileSystem.get(hadoopConf)
      hadoopConf.getOutputFormat.checkOutputSpecs(ignoredFs, hadoopConf)
    }

    val writer = new SparkHadoopWriter(hadoopConf)
    writer.preSetup()

    val writeToFile = (context: TaskContext, iter: Iterator[(K, V)]) =&amp;gt; {
      // Hadoop wants a 32-bit task attempt ID, so if ours is bigger than Int.MaxValue, roll it
      // around by taking a mod. We expect that no task will be attempted 2 billion times.
      val taskAttemptId = (context.taskAttemptId % Int.MaxValue).toInt

      val outputMetricsAndBytesWrittenCallback: Option[(OutputMetrics, () =&amp;gt; Long)] =
        initHadoopOutputMetrics(context)

      writer.setup(context.stageId, context.partitionId, taskAttemptId)
      writer.open()
      var recordsWritten = 0L

      Utils.tryWithSafeFinallyAndFailureCallbacks {
        while (iter.hasNext) {
          val record = iter.next()
          writer.write(record._1.asInstanceOf[AnyRef], record._2.asInstanceOf[AnyRef])

          // Update bytes written metric every few records
          maybeUpdateOutputMetrics(outputMetricsAndBytesWrittenCallback, recordsWritten)
          recordsWritten += 1
        }
      }(finallyBlock = writer.close())
      writer.commit()
      outputMetricsAndBytesWrittenCallback.foreach { case (om, callback) =&amp;gt;
        om.setBytesWritten(callback())
        om.setRecordsWritten(recordsWritten)
      }
    }

    self.context.runJob(self, writeToFile)
    writer.commitJob()
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;上面是saveAstextFile的调用过程，中间省略了一个函数，看代码的最后两行。可以看出调用了&lt;code class=&quot;highlighter-rouge&quot;&gt; self.context.runJob()&lt;/code&gt;可以知道这里触发了job的提交。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; def runJob[T, U: ClassTag](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      resultHandler: (Int, U) =&amp;gt; Unit): Unit = {
    if (stopped.get()) {
      throw new IllegalStateException(&quot;SparkContext has been shutdown&quot;)
    }
    val callSite = getCallSite
    val cleanedFunc = clean(func)
    logInfo(&quot;Starting job: &quot; + callSite.shortForm)
    if (conf.getBoolean(&quot;spark.logLineage&quot;, false)) {
      logInfo(&quot;RDD's recursive dependencies:\n&quot; + rdd.toDebugString)
    }
    dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)
    progressBar.foreach(_.finishAll())
    rdd.doCheckpoint() //是否cache rdd
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;可以看出上面代码有 &lt;code class=&quot;highlighter-rouge&quot;&gt;dagScheduler.runJob&lt;/code&gt;，开始进行调度。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def runJob[T, U](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      callSite: CallSite,
      resultHandler: (Int, U) =&amp;gt; Unit,
      properties: Properties): Unit = {
    val start = System.nanoTime
    val waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)
    // Note: Do not call Await.ready(future) because that calls `scala.concurrent.blocking`,
    // which causes concurrent SQL executions to fail if a fork-join pool is used. Note that
    // due to idiosyncrasies in Scala, `awaitPermission` is not actually used anywhere so it's
    // safe to pass in null here. For more detail, see SPARK-13747.
    val awaitPermission = null.asInstanceOf[scala.concurrent.CanAwait]
    waiter.completionFuture.ready(Duration.Inf)(awaitPermission)
    waiter.completionFuture.value.get match {
      case scala.util.Success(_) =&amp;gt;
        logInfo(&quot;Job %d finished: %s, took %f s&quot;.format
          (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9))
      case scala.util.Failure(exception) =&amp;gt;
        logInfo(&quot;Job %d failed: %s, took %f s&quot;.format
          (waiter.jobId, callSite.shortForm, (System.nanoTime - start) / 1e9))
        // SPARK-8644: Include user stack trace in exceptions coming from DAGScheduler.
        val callerStackTrace = Thread.currentThread().getStackTrace.tail
        exception.setStackTrace(exception.getStackTrace ++ callerStackTrace)
        throw exception
    }
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;在 dagScheduler.runJob()里面有 &lt;code class=&quot;highlighter-rouge&quot;&gt;submitJob&lt;/code&gt;的操作，提交job。
看下面&lt;code class=&quot;highlighter-rouge&quot;&gt;submitJob&lt;/code&gt;的代码。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  def submitJob[T, U](
      rdd: RDD[T],
      func: (TaskContext, Iterator[T]) =&amp;gt; U,
      partitions: Seq[Int],
      callSite: CallSite,
      resultHandler: (Int, U) =&amp;gt; Unit,
      properties: Properties): JobWaiter[U] = {
    // Check to make sure we are not launching a task on a partition that does not exist.
    val maxPartitions = rdd.partitions.length
    partitions.find(p =&amp;gt; p &amp;gt;= maxPartitions || p &amp;lt; 0).foreach { p =&amp;gt;
      throw new IllegalArgumentException(
        &quot;Attempting to access a non-existent partition: &quot; + p + &quot;. &quot; +
          &quot;Total number of partitions: &quot; + maxPartitions)
    }

    val jobId = nextJobId.getAndIncrement()
    if (partitions.size == 0) {
      // Return immediately if the job is running 0 tasks
      return new JobWaiter[U](this, jobId, 0, resultHandler)
    }

    assert(partitions.size &amp;gt; 0)
    val func2 = func.asInstanceOf[(TaskContext, Iterator[_]) =&amp;gt; _]
    val waiter = new JobWaiter(this, jobId, partitions.size, resultHandler)
    eventProcessLoop.post(JobSubmitted(
      jobId, rdd, func2, partitions.toArray, callSite, waiter,
      SerializationUtils.clone(properties)))
    waiter
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后eventProcessLoop.post(JobSubmitted … 然后就有循环程序处理 这个post。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def doOnReceive(event: DAGSchedulerEvent): Unit = event match {
  case JobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties) =&amp;gt;
    dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;划分stage&quot;&gt;划分stage&lt;/h3&gt;

&lt;p&gt;提交完job之后，会对stage进行划分。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;handleJobSubmitted&lt;/code&gt;,如下代码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[scheduler] def handleJobSubmitted(jobId: Int,
    finalRDD: RDD[_],
    func: (TaskContext, Iterator[_]) =&amp;gt; _,
    partitions: Array[Int],
    callSite: CallSite,
    listener: JobListener,
    properties: Properties) {
  var finalStage: ResultStage = null
  try {
    // New stage creation may throw an exception if, for example, jobs are run on a
    // HadoopRDD whose underlying HDFS files have been deleted.
    finalStage = newResultStage(finalRDD, func, partitions, jobId, callSite)
  } catch {
    case e: Exception =&amp;gt;
      logWarning(&quot;Creating new stage failed due to exception - job: &quot; + jobId, e)
      listener.jobFailed(e)
      return
  }

  val job = new ActiveJob(jobId, finalStage, callSite, listener, properties)
  clearCacheLocs()
  logInfo(&quot;Got job %s (%s) with %d output partitions&quot;.format(
    job.jobId, callSite.shortForm, partitions.length))
  logInfo(&quot;Final stage: &quot; + finalStage + &quot; (&quot; + finalStage.name + &quot;)&quot;)
  logInfo(&quot;Parents of final stage: &quot; + finalStage.parents)
  logInfo(&quot;Missing parents: &quot; + getMissingParentStages(finalStage))

  val jobSubmissionTime = clock.getTimeMillis()
  jobIdToActiveJob(jobId) = job
  activeJobs += job
  finalStage.setActiveJob(job)
  val stageIds = jobIdToStageIds(jobId).toArray
  val stageInfos = stageIds.flatMap(id =&amp;gt; stageIdToStage.get(id).map(_.latestInfo))
  listenerBus.post(
    SparkListenerJobStart(job.jobId, jobSubmissionTime, stageInfos, properties))
  submitStage(finalStage)

  submitWaitingStages()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解释下这段代码，先是找到最后一个stage， finalStage，然后就生成stageId还有stage的一些信息，然后post 出job开始的消息，然后提交最后一个stage，最后一行是提交等待的stages。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** Submits stage, but first recursively submits any missing parents. */
private def submitStage(stage: Stage) {
  val jobId = activeJobForStage(stage)
  if (jobId.isDefined) {
    logDebug(&quot;submitStage(&quot; + stage + &quot;)&quot;)
    if (!waitingStages(stage) &amp;amp;&amp;amp; !runningStages(stage) &amp;amp;&amp;amp; !failedStages(stage)) {
      val missing = getMissingParentStages(stage).sortBy(_.id)
      logDebug(&quot;missing: &quot; + missing)
      if (missing.isEmpty) {
        logInfo(&quot;Submitting &quot; + stage + &quot; (&quot; + stage.rdd + &quot;), which has no missing parents&quot;)
        submitMissingTasks(stage, jobId.get)
      } else {
        for (parent &amp;lt;- missing) {
          submitStage(parent)
        }
        waitingStages += stage
      }
    }
  } else {
    abortStage(stage, &quot;No active job for stage &quot; + stage.id, None)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;解释下这段代码，就是递归提交之前都没有提交的stage，因为之前是提交最后一个stage吗，但是前面stage也没操作，所以要不断地提交parentStage，直到job的头部。如果说这个stage没有未完成的parentStage，那就代表它前面都执行完毕。&lt;/p&gt;

&lt;h3 id=&quot;提交tasks&quot;&gt;提交tasks&lt;/h3&gt;

&lt;p&gt;找到最开始还没完成的stage，那么提交这个stage的Tasks。调用的函数是&lt;code class=&quot;highlighter-rouge&quot;&gt;submitMissingTasks(stage,jobId.get)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;下面是 这个函数的代码，有点长。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def submitMissingTasks(stage: Stage, jobId: Int) {
  logDebug(&quot;submitMissingTasks(&quot; + stage + &quot;)&quot;)
  // Get our pending tasks and remember them in our pendingTasks entry
  stage.pendingPartitions.clear()

  // First figure out the indexes of partition ids to compute.
  val partitionsToCompute: Seq[Int] = stage.findMissingPartitions()

  // Use the scheduling pool, job group, description, etc. from an ActiveJob associated
  // with this Stage
  val properties = jobIdToActiveJob(jobId).properties

  runningStages += stage
  // SparkListenerStageSubmitted should be posted before testing whether tasks are
  // serializable. If tasks are not serializable, a SparkListenerStageCompleted event
  // will be posted, which should always come after a corresponding SparkListenerStageSubmitted
  // event.
  stage match {
    case s: ShuffleMapStage =&amp;gt;
      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - 1)
    case s: ResultStage =&amp;gt;
      outputCommitCoordinator.stageStart(
        stage = s.id, maxPartitionId = s.rdd.partitions.length - 1)
  }
  val taskIdToLocations: Map[Int, Seq[TaskLocation]] = try {
    stage match {
      case s: ShuffleMapStage =&amp;gt;
        partitionsToCompute.map { id =&amp;gt; (id, getPreferredLocs(stage.rdd, id))}.toMap
      case s: ResultStage =&amp;gt;
        val job = s.activeJob.get
        partitionsToCompute.map { id =&amp;gt;
          val p = s.partitions(id)
          (id, getPreferredLocs(stage.rdd, p))
        }.toMap
    }
  } catch {
    case NonFatal(e) =&amp;gt;
      stage.makeNewStageAttempt(partitionsToCompute.size)
      listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties))
      abortStage(stage, s&quot;Task creation failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)
  listenerBus.post(SparkListenerStageSubmitted(stage.latestInfo, properties))

  // TODO: Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.
  // Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast
  // the serialized copy of the RDD and for each task we will deserialize it, which means each
  // task gets a different copy of the RDD. This provides stronger isolation between tasks that
  // might modify state of objects referenced in their closures. This is necessary in Hadoop
  // where the JobConf/Configuration object is not thread-safe.
  var taskBinary: Broadcast[Array[Byte]] = null
  try {
    // For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).
    // For ResultTask, serialize and broadcast (rdd, func).
    val taskBinaryBytes: Array[Byte] = stage match {
      case stage: ShuffleMapStage =&amp;gt;
        JavaUtils.bufferToArray(
          closureSerializer.serialize((stage.rdd, stage.shuffleDep): AnyRef))
      case stage: ResultStage =&amp;gt;
        JavaUtils.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): AnyRef))
    }

    taskBinary = sc.broadcast(taskBinaryBytes)
  } catch {
    // In the case of a failure during serialization, abort the stage.
    case e: NotSerializableException =&amp;gt;
      abortStage(stage, &quot;Task not serializable: &quot; + e.toString, Some(e))
      runningStages -= stage

      // Abort execution
      return
    case NonFatal(e) =&amp;gt;
      abortStage(stage, s&quot;Task serialization failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  val tasks: Seq[Task[_]] = try {
    stage match {
      case stage: ShuffleMapStage =&amp;gt;
        partitionsToCompute.map { id =&amp;gt;
          val locs = taskIdToLocations(id)
          val part = stage.rdd.partitions(id)
          new ShuffleMapTask(stage.id, stage.latestInfo.attemptId,
            taskBinary, part, locs, stage.latestInfo.taskMetrics, properties)
        }

      case stage: ResultStage =&amp;gt;
        val job = stage.activeJob.get
        partitionsToCompute.map { id =&amp;gt;
          val p: Int = stage.partitions(id)
          val part = stage.rdd.partitions(p)
          val locs = taskIdToLocations(id)
          new ResultTask(stage.id, stage.latestInfo.attemptId,
            taskBinary, part, locs, id, properties, stage.latestInfo.taskMetrics)
        }
    }
  } catch {
    case NonFatal(e) =&amp;gt;
      abortStage(stage, s&quot;Task creation failed: $e\n${Utils.exceptionString(e)}&quot;, Some(e))
      runningStages -= stage
      return
  }

  if (tasks.size &amp;gt; 0) {
    logInfo(&quot;Submitting &quot; + tasks.size + &quot; missing tasks from &quot; + stage + &quot; (&quot; + stage.rdd + &quot;)&quot;)
    stage.pendingPartitions ++= tasks.map(_.partitionId)
    logDebug(&quot;New pending partitions: &quot; + stage.pendingPartitions)
    taskScheduler.submitTasks(new TaskSet(
      tasks.toArray, stage.id, stage.latestInfo.attemptId, jobId, properties))
    stage.latestInfo.submissionTime = Some(clock.getTimeMillis())
  } else {
    // Because we posted SparkListenerStageSubmitted earlier, we should mark
    // the stage as completed here in case there are no tasks to run
    markStageAsFinished(stage, None)

    val debugString = stage match {
      case stage: ShuffleMapStage =&amp;gt;
        s&quot;Stage ${stage} is actually done; &quot; +
          s&quot;(available: ${stage.isAvailable},&quot; +
          s&quot;available outputs: ${stage.numAvailableOutputs},&quot; +
          s&quot;partitions: ${stage.numPartitions})&quot;
      case stage : ResultStage =&amp;gt;
        s&quot;Stage ${stage} is actually done; (partitions: ${stage.numPartitions})&quot;
    }
    logDebug(debugString)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面的代码出现了多次&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;和&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，先介绍一下这个stage。&lt;/p&gt;

&lt;p&gt;前面我们说过，WordCount只有一个job，然后reduceByKey是shuffle操作，以这个为stage的边界。那么前面的stage就是&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapStage&lt;/code&gt;，后面的stage就是&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;.因为前面会有shuffle操作，而后面是整个job的计算结果，所以叫ResultStage.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultStage&lt;/code&gt;是有一个函数，应用于rdd的一些partition来计算出这个action的结果。但有些action并不是在每个partition都执行的，比如&lt;code class=&quot;highlighter-rouge&quot;&gt;first()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;接下来介绍下这个函数的执行流程。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;首先是计算出 &lt;code class=&quot;highlighter-rouge&quot;&gt;paritionsToCompute&lt;/code&gt;，即用于计算的partition，数据。&lt;/li&gt;
  &lt;li&gt;然后就是&lt;code class=&quot;highlighter-rouge&quot;&gt;outputCommitCoordinator.stageStart&lt;/code&gt;,这个类是用来输出到hdfs上的，然后stageStart的两个参数，就是用于发出信息，两个参数分别是stageId和他要用于计算的partition数目。&lt;/li&gt;
  &lt;li&gt;然后就是计算这个stage用于计算的TaskId对应的task所在的location。因为TaskId和partitionId是对应的，所以也就是计算partitionId对应的taskLocation。然后taskLocation是一个host或者是一个（host,executorId）二元组。&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)&lt;/code&gt;这里创建新的attempt 就是代表这个stage执行了几次。因为stage可能会失败的。如果失败就要接着执行，这个attempt从0开始。&lt;/li&gt;
  &lt;li&gt;然后就是创建广播变量，然后braocast。广播是用于executor来解析tasks。首先要序列化，给每个task都一个完整的rdd，这样可以让task独立性更强，这对于非线程安全是有必要的。对于ShuffleMapTask我们序列化的数据是&lt;code class=&quot;highlighter-rouge&quot;&gt;(rdd,shuffleDep)&lt;/code&gt;，对于resultTask,序列化数据为&lt;code class=&quot;highlighter-rouge&quot;&gt;(rdd,func)&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;然后是创建tasks，当然Tasks分为shuffleMapTask和resultTask，这都是跟stage类型对应的。这里创建tasks，需要用到一个参数&lt;code class=&quot;highlighter-rouge&quot;&gt;stage.latestInfo.attemptId&lt;/code&gt;,这里是前面提到的。&lt;/li&gt;
  &lt;li&gt;创建完tasks就是后面的&lt;code class=&quot;highlighter-rouge&quot;&gt;taskScheduler.submitTasks()&lt;/code&gt;，这样任务就交由taskScheduler调度了。&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def submitTasks(taskSet: TaskSet) {
  val tasks = taskSet.tasks
  logInfo(&quot;Adding task set &quot; + taskSet.id + &quot; with &quot; + tasks.length + &quot; tasks&quot;)
  this.synchronized {
    val manager = createTaskSetManager(taskSet, maxTaskFailures)
    val stage = taskSet.stageId
    val stageTaskSets =
      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, new HashMap[Int, TaskSetManager])
    stageTaskSets(taskSet.stageAttemptId) = manager
    val conflictingTaskSet = stageTaskSets.exists { case (_, ts) =&amp;gt;
      ts.taskSet != taskSet &amp;amp;&amp;amp; !ts.isZombie
    }
    if (conflictingTaskSet) {
      throw new IllegalStateException(s&quot;more than one active taskSet for stage $stage:&quot; +
        s&quot; ${stageTaskSets.toSeq.map{_._2.taskSet.id}.mkString(&quot;,&quot;)}&quot;)
    }
    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)

    if (!isLocal &amp;amp;&amp;amp; !hasReceivedTask) {
      starvationTimer.scheduleAtFixedRate(new TimerTask() {
        override def run() {
          if (!hasLaunchedTask) {
            logWarning(&quot;Initial job has not accepted any resources; &quot; +
              &quot;check your cluster UI to ensure that workers are registered &quot; +
              &quot;and have sufficient resources&quot;)
          } else {
            this.cancel()
          }
        }
      }, STARVATION_TIMEOUT_MS, STARVATION_TIMEOUT_MS)
    }
    hasReceivedTask = true
  }
  backend.reviveOffers()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这段代码前面部分就是先创建taskManager，然后判断是否有超过一个数目的tasks存在，如果冲突就报异常。&lt;/p&gt;

&lt;p&gt;然后把这个TaskSetManager加入&lt;code class=&quot;highlighter-rouge&quot;&gt;schedulableBuilder&lt;/code&gt;，这个变量在初始化时候会选择调度策略，比如fifo啥的，加入之后就会按照相应的策略进行调度。&lt;/p&gt;

&lt;p&gt;然后之后的判断是否为本地，和是否已经接收过任务，&lt;code class=&quot;highlighter-rouge&quot;&gt;isLocal&lt;/code&gt;代表本地模式。如果非本地模式，而且还没接收到过任务，就会建立一个TimerTask，然后一直查看有没有接收到任务，因为如果没任务就是空转吗。&lt;/p&gt;

&lt;p&gt;最后backend就会让这个tasks唤醒。&lt;code class=&quot;highlighter-rouge&quot;&gt;backend.reviveOffers()&lt;/code&gt;,这里我们的backend通常是&lt;code class=&quot;highlighter-rouge&quot;&gt;CoarseGrainedSchedulerBackend&lt;/code&gt;，在执行reviveOffers之后，&lt;code class=&quot;highlighter-rouge&quot;&gt;driverEndpoint&lt;/code&gt;会send消息，然后backend的receive函数会接收到消息，然后执行操作。看CoarseGrainedSchedulerBackend 的receive函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive: PartialFunction[Any, Unit] = {
...
case ReviveOffers =&amp;gt;
  makeOffers()
...
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def makeOffers() {
  // Filter out executors under killing
  val activeExecutors = executorDataMap.filterKeys(executorIsAlive)
  val workOffers = activeExecutors.map { case (id, executorData) =&amp;gt;
    new WorkerOffer(id, executorData.executorHost, executorData.freeCores)
  }.toSeq
  launchTasks(scheduler.resourceOffers(workOffers))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面代码显示筛选出存活的&lt;code class=&quot;highlighter-rouge&quot;&gt;Executors&lt;/code&gt;，然后就创建出&lt;code class=&quot;highlighter-rouge&quot;&gt;workerOffers&lt;/code&gt;,参数是executorId,host,frescoers.&lt;/p&gt;

&lt;h3 id=&quot;执行task&quot;&gt;执行task&lt;/h3&gt;

&lt;p&gt;然后就launchTasks。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def launchTasks(tasks: Seq[Seq[TaskDescription]]) {
  for (task &amp;lt;- tasks.flatten) {
    val serializedTask = ser.serialize(task)
    if (serializedTask.limit &amp;gt;= maxRpcMessageSize) {
      scheduler.taskIdToTaskSetManager.get(task.taskId).foreach { taskSetMgr =&amp;gt;
        try {
          var msg = &quot;Serialized task %s:%d was %d bytes, which exceeds max allowed: &quot; +
            &quot;spark.rpc.message.maxSize (%d bytes). Consider increasing &quot; +
            &quot;spark.rpc.message.maxSize or using broadcast variables for large values.&quot;
          msg = msg.format(task.taskId, task.index, serializedTask.limit, maxRpcMessageSize)
          taskSetMgr.abort(msg)
        } catch {
          case e: Exception =&amp;gt; logError(&quot;Exception in error callback&quot;, e)
        }
      }
    }
    else {
      val executorData = executorDataMap(task.executorId)
      executorData.freeCores -= scheduler.CPUS_PER_TASK

      logInfo(s&quot;Launching task ${task.taskId} on executor id: ${task.executorId} hostname: &quot; +
        s&quot;${executorData.executorHost}.&quot;)

      executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask)))
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;上面的代码显示将task序列化，然后根据task.executorId 给他分配executor，然后就&lt;code class=&quot;highlighter-rouge&quot;&gt;executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask)))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;这里有一个&lt;code class=&quot;highlighter-rouge&quot;&gt;executorEndPoint&lt;/code&gt;,之前前面有driverEndPoint(出现在backend.reviveOffer那里)，这两个端口的基类都是&lt;code class=&quot;highlighter-rouge&quot;&gt;RpcEndpointRef&lt;/code&gt;。RpcEndpointRef是RpcEndPoint的远程引用，是线程安全的。&lt;/p&gt;

&lt;p&gt;RpcEndpoint是 RPC[Remote Procedure Call ：远程过程调用]中定义了收到的消息将触发哪个方法。&lt;/p&gt;

&lt;p&gt;同时清楚的阐述了生命周期，构造-&amp;gt; onStart -&amp;gt; receive* -&amp;gt; onStop&lt;/p&gt;

&lt;p&gt;这里receive* 是指receive 和 receiveAndReply。&lt;/p&gt;

&lt;p&gt;他们的区别是：&lt;/p&gt;

&lt;p&gt;receive是无需等待答复，而receiveAndReply是会阻塞线程，直至有答复的。(参考：http://www.07net01.com/2016/04/1434116.html)&lt;/p&gt;

&lt;p&gt;然后这里的driverEndPoint就是代表这个信息会发给&lt;code class=&quot;highlighter-rouge&quot;&gt;CoarseGrainedSchedulerBackEnd&lt;/code&gt;，executorEndPoint就是发给&lt;code class=&quot;highlighter-rouge&quot;&gt;coarseGrainedExecutorBackEnd&lt;/code&gt;当然就是发给&lt;code class=&quot;highlighter-rouge&quot;&gt;coarseGrainedExecutorBackEnd&lt;/code&gt;。接下来去看相应的recieve代码。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def receive: PartialFunction[Any, Unit] = {
...

    case LaunchTask(data) =&amp;gt;
      if (executor == null) {
        exitExecutor(1, &quot;Received LaunchTask command but executor was null&quot;)
      } else {
        val taskDesc = ser.deserialize[TaskDescription](data.value)
        logInfo(&quot;Got assigned task &quot; + taskDesc.taskId)
        executor.launchTask(this, taskId = taskDesc.taskId, attemptNumber = taskDesc.attemptNumber,
          taskDesc.name, taskDesc.serializedTask)
      }
...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里先将传过来的数据反序列化，然后&lt;code class=&quot;highlighter-rouge&quot;&gt;executor.launchTask&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def launchTask(
    context: ExecutorBackend,
    taskId: Long,
    attemptNumber: Int,
    taskName: String,
    serializedTask: ByteBuffer): Unit = {
  val tr = new TaskRunner(context, taskId = taskId, attemptNumber = attemptNumber, taskName,
    serializedTask)
  runningTasks.put(taskId, tr)
  threadPool.execute(tr)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这里新建了taskRunner，然后之后交由线程池来运行，线程池既然要运行taskRunner，必定是运行taskRunner的run方法。看taskRunner的run方法，代码太长，懒得贴，大概描述下。&lt;/p&gt;

&lt;p&gt;主要就是设置参数，属性，反序列化出task等等，之后就要调用task.runTask方法。这里的task可能是&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;也可能是&lt;code class=&quot;highlighter-rouge&quot;&gt;ResultTask&lt;/code&gt;，所以我们分别看这两种task的run方法。&lt;/p&gt;

&lt;h4 id=&quot;shufflemaptask&quot;&gt;ShuffleMapTask&lt;/h4&gt;

&lt;p&gt;先看&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleMapTask&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def runTask(context: TaskContext): MapStatus = {
  // Deserialize the RDD using the broadcast variable.
  val deserializeStartTime = System.currentTimeMillis()
  val ser = SparkEnv.get.closureSerializer.newInstance()
  val (rdd, dep) = ser.deserialize[(RDD[_], ShuffleDependency[_, _, _])](
    ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
  _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime

  var writer: ShuffleWriter[Any, Any] = null
  try {
    val manager = SparkEnv.get.shuffleManager
    writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context)
    writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &amp;lt;: Product2[Any, Any]]])
    writer.stop(success = true).get
  } catch {
    case e: Exception =&amp;gt;
      try {
        if (writer != null) {
          writer.stop(success = false)
        }
      } catch {
        case e: Exception =&amp;gt;
          log.debug(&quot;Could not stop writer&quot;, e)
      }
      throw e
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;前面部分代码就是反序列化那些，主要看中间的代码。获得shuffleManager,然后getWriter。因为shuffleMapTask有Shuffle操作，所以要shuffleWrite。&lt;/p&gt;

&lt;h4 id=&quot;resulttask&quot;&gt;ResultTask&lt;/h4&gt;

&lt;p&gt;看下ResultTask的runTask。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  override def runTask(context: TaskContext): U = {
    // Deserialize the RDD and the func using the broadcast variables.
    val deserializeStartTime = System.currentTimeMillis()
    val ser = SparkEnv.get.closureSerializer.newInstance()
    val (rdd, func) = ser.deserialize[(RDD[T], (TaskContext, Iterator[T]) =&amp;gt; U)](
      ByteBuffer.wrap(taskBinary.value), Thread.currentThread.getContextClassLoader)
    _executorDeserializeTime = System.currentTimeMillis() - deserializeStartTime

    func(context, rdd.iterator(partition, context))
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;跟那个差不多，只不过不是shuffleWrite，是func.&lt;/p&gt;

&lt;h4 id=&quot;rdd-迭代链&quot;&gt;rdd 迭代链&lt;/h4&gt;

&lt;p&gt;看这行代码&lt;code class=&quot;highlighter-rouge&quot;&gt;writer.write(rdd.iterator(partition, context).asInstanceOf[Iterator[_ &amp;lt;: Product2[Any, Any]]])&lt;/code&gt;，看write方法里面的参数，rdd.iterator方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;final def iterator(split: Partition, context: TaskContext): Iterator[T] = {
  if (storageLevel != StorageLevel.NONE) {
    getOrCompute(split, context)
  } else {
    computeOrReadCheckpoint(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;这个方法，是从后面的rdd开始迭代，首先判断这个rdd是否是已经被cache。&lt;/p&gt;

&lt;p&gt;如果已经被cache，getOrCompute，直接get，或者如果没找到就重算一遍，这个代码比较简单，我就不贴了。&lt;/p&gt;

&lt;p&gt;如果没有被cache，则调用&lt;code class=&quot;highlighter-rouge&quot;&gt;computeOrReadCheckpoint&lt;/code&gt;。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private[spark] def computeOrReadCheckpoint(split: Partition, context: TaskContext): Iterator[T] =
{
  if (isCheckpointedAndMaterialized) {
    firstParent[T].iterator(split, context)
  } else {
    compute(split, context)
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;如果是检查点，先介绍下检查点。&lt;/p&gt;

&lt;h4 id=&quot;检查点&quot;&gt;检查点&lt;/h4&gt;

&lt;p&gt;检查点机制的实现和持久化的实现有着较大的区别。检查点并非第一次计算就将结果进行存储，而是等到一个作业结束后启动专门的一个作业完成存储的操作。&lt;/p&gt;

&lt;p&gt;checkPoint操作的实现在RDD类中，&lt;em&gt;checkPoint&lt;/em&gt;方法会实例化ReliableRDDCheckpointData用于标记当前的RDD&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/**
 * Mark this RDD for checkpointing. It will be saved to a file inside the checkpoint
 * directory set with `SparkContext#setCheckpointDir` and all references to its parent
 * RDDs will be removed. This function must be called before any job has been
 * executed on this RDD. It is strongly recommended that this RDD is persisted in
 * memory, otherwise saving it on a file will require recomputation.
 */
def checkpoint(): Unit = RDDCheckpointData.synchronized {
  // NOTE: we use a global lock here due to complexities downstream with ensuring
  // children RDD partitions point to the correct parent partitions. In the future
  // we should revisit this consideration.
  if (context.checkpointDir.isEmpty) {
    throw new SparkException(&quot;Checkpoint directory has not been set in the SparkContext&quot;)
  } else if (checkpointData.isEmpty) {
    checkpointData = Some(new ReliableRDDCheckpointData(this))
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;RDDCheckpointData类内部有一个枚举类型 &lt;code class=&quot;highlighter-rouge&quot;&gt;CheckpointState &lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/** 
 * Enumeration to manage state transitions of an RDD through checkpointing 
 * [ Initialized --&amp;gt; checkpointing in progress --&amp;gt; checkpointed ]. 
 */  
private[spark] object CheckpointState extends Enumeration {  
  type CheckpointState = Value  
  val Initialized, CheckpointingInProgress, Checkpointed = Value  
} 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;用于表示RDD检查点的当前状态，其值有Initialized 、CheckpointingInProgress、 checkpointed。其转换过程如下
(1)Initialized状态&lt;/p&gt;

&lt;p&gt;该状态是实例化ReliableRDDCheckpointData后的默认状态，用于标记当前的RDD已经建立了检查点(较v1.4.x少一个MarkForCheckPiont状态)&lt;/p&gt;

&lt;p&gt;(2)CheckpointingInProgress状态&lt;/p&gt;

&lt;p&gt;每个作业结束后都会对作业的末RDD调用其doCheckPoint方法，该方法会顺着RDD的关系依赖链往前遍历，直到遇见内部RDDCheckpointData对象被标记为Initialized的为止，此时将RDD的RDDCheckpointData对象标记为CheckpointingInProgress，并启动一个作业完成数据的写入操作。&lt;/p&gt;

&lt;p&gt;(3)Checkpointed状态&lt;/p&gt;

&lt;p&gt;新启动作业完成数据写入操作之后，将建立检查点的RDD的所有依赖全部清除，将RDD内部的RDDCheckpointData对象标记为Checkpointed，&lt;code class=&quot;highlighter-rouge&quot;&gt;将父RDD重新设置为一个CheckPointRDD对象，父RDD的compute方法会直接从系统中读取数据&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;如上只简单地介绍了相关概念，详细介绍请参看：&lt;a href=&quot;https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md&quot;&gt;https://github.com/JerryLead/SparkInternals/blob/master/markdown/6-CacheAndCheckpoint.md&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;compute-链&quot;&gt;compute 链&lt;/h3&gt;
&lt;p&gt;上面有检查点的就直接去父Rdd的compute读取数据了。而非检查点，就compute，compute是一个链。
拿&lt;code class=&quot;highlighter-rouge&quot;&gt;MapPartitionsRDD&lt;/code&gt;举个例子，看看它的compute方法。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def compute(split: Partition, context: TaskContext): Iterator[U] =
f(context, split.index, firstParent[T].iterator(split, context))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;看这里 compute还是调用了iterator，所以还是接着往前找了，直到找到checkpoint或者就是到rdd头。&lt;/p&gt;

&lt;p&gt;再看看其他的rdd的compute方法吧。&lt;/p&gt;

&lt;p&gt;看看&lt;code class=&quot;highlighter-rouge&quot;&gt;ShuffleRdd&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;override def compute(split: Partition, context: TaskContext): Iterator[(K, C)] = {
  val dep = dependencies.head.asInstanceOf[ShuffleDependency[K, V, C]]
  SparkEnv.get.shuffleManager.getReader(dep.shuffleHandle, split.index, split.index + 1, context)
    .read()
    .asInstanceOf[Iterator[(K, C)]]
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后这里shuffleRdd的compute方法就是从shuffle 那里read 数据，这算是一个stage的开始了。&lt;/p&gt;

&lt;p&gt;当然一个stage的开始未必是shuffleRead开始啦，比如textFile，它最终是返回一个HadoopRdd，然后他的compute方法，就是返回一个迭代器。&lt;/p&gt;

&lt;h2 id=&quot;参考&quot;&gt;参考&lt;/h2&gt;

&lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/jiangpeng59/article/details/53213694&quot;&gt;Spark核心RDD：计算函数compute&lt;/a&gt;&lt;/p&gt;

&lt;p&gt; &lt;a href=&quot;http://blog.csdn.net/jiangpeng59/article/details/53212416&quot;&gt;Spark基础随笔：持久化&amp;amp;检查点&lt;/a&gt;&lt;/p&gt;

</description>
                <link>http://turbofei.github.io/spark/2016/12/22/spark%E5%BA%94%E7%94%A8%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B</link>
                <guid>http://turbofei.github.io/spark/2016/12/22/spark应用执行流程</guid>
                <pubDate>2016-12-22T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>spark统一内存管理</title>
                <description>
&lt;h3 id=&quot;background&quot;&gt;Background&lt;/h3&gt;
&lt;p&gt;spark统一内存管理是spark1.6.0的新特性，是对shuffle memory 和 storage memory 进行统一的管理，打破了以往的参数限制。&lt;/p&gt;

&lt;h2 id=&quot;非统一内存管理&quot;&gt;非统一内存管理&lt;/h2&gt;

&lt;p&gt;spark在1.6 之前都是非统一内存管理，通过设置&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.shuffle.memoryFraction&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;spark.storage.memoryFraction&lt;/code&gt;来设置shuffle 和storage的memory 大小。看下&lt;code class=&quot;highlighter-rouge&quot;&gt;StaticMemoryManager&lt;/code&gt;的获得最大shuffle和storage memory的函数。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;private def getMaxStorageMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
  val memoryFraction = conf.getDouble(&quot;spark.storage.memoryFraction&quot;, 0.6)
  val safetyFraction = conf.getDouble(&quot;spark.storage.safetyFraction&quot;, 0.9)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}

/**
 * Return the total amount of memory available for the execution region, in bytes.
 */
private def getMaxExecutionMemory(conf: SparkConf): Long = {
  val systemMaxMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
...
  val memoryFraction = conf.getDouble(&quot;spark.shuffle.memoryFraction&quot;, 0.2)
  val safetyFraction = conf.getDouble(&quot;spark.shuffle.safetyFraction&quot;, 0.8)
  (systemMaxMemory * memoryFraction * safetyFraction).toLong
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;可以看出，&lt;code class=&quot;highlighter-rouge&quot;&gt;systemMaxMemory&lt;/code&gt;是通过参数&lt;code class=&quot;highlighter-rouge&quot;&gt;spark.testing.memory&lt;/code&gt;来获得，如果这个参数没有设置，就取虚拟机内存，然后shuffle 和 storage都有安全系数，最后可用的最大内存都是：系统最大内存*比例系数*安全系数。&lt;/p&gt;

&lt;h2 id=&quot;统一内存管理&quot;&gt;统一内存管理&lt;/h2&gt;

&lt;p&gt;spark 1.6.0 出现了统一内存管理，是打破了shuffle 内存和storage内存的静态限制。通俗的描述，就是如果storage内存不够，而shuffle内存剩余就能借内存，如果shuffle内存不足，此时如果storage已经超出了&lt;code class=&quot;highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，那么就驱逐当前使用storage内存-&lt;code class=&quot;highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，如果storage 使用没有超过&lt;code class=&quot;highlighter-rouge&quot;&gt;storageRegionSize&lt;/code&gt;，那么则把它剩余的都可以借给shuffle使用。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  private def getMaxMemory(conf: SparkConf): Long = {
    val systemMemory = conf.getLong(&quot;spark.testing.memory&quot;, Runtime.getRuntime.maxMemory)
    val reservedMemory = conf.getLong(&quot;spark.testing.reservedMemory&quot;,
      if (conf.contains(&quot;spark.testing&quot;)) 0 else RESERVED_SYSTEM_MEMORY_BYTES)
    val minSystemMemory = (reservedMemory * 1.5).ceil.toLong
    if (systemMemory &amp;lt; minSystemMemory) {
      throw new IllegalArgumentException(s&quot;System memory $systemMemory must &quot; +
        s&quot;be at least $minSystemMemory. Please increase heap size using the --driver-memory &quot; +
        s&quot;option or spark.driver.memory in Spark configuration.&quot;)
    }
    // SPARK-12759 Check executor memory to fail fast if memory is insufficient
    if (conf.contains(&quot;spark.executor.memory&quot;)) {
      val executorMemory = conf.getSizeAsBytes(&quot;spark.executor.memory&quot;)
      if (executorMemory &amp;lt; minSystemMemory) {
        throw new IllegalArgumentException(s&quot;Executor memory $executorMemory must be at least &quot; +
          s&quot;$minSystemMemory. Please increase executor memory using the &quot; +
          s&quot;--executor-memory option or spark.executor.memory in Spark configuration.&quot;)
      }
    }
    val usableMemory = systemMemory - reservedMemory
    val memoryFraction = conf.getDouble(&quot;spark.memory.fraction&quot;, 0.6)
    (usableMemory * memoryFraction).toLong
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;这个是统一内存管理的获得最大内存的函数，因为shuffle和storage是统一管理的，所以只有一个获得统一最大内存的函数。&lt;code class=&quot;highlighter-rouge&quot;&gt;usableMemory = systemMemory - reservedMemory&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;最大内存=&lt;code class=&quot;highlighter-rouge&quot;&gt;usableMemory * memoryFraction&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;统一内存管理的使用&quot;&gt;统一内存管理的使用&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;UnifiedMemoryManager&lt;/code&gt;是在一个静态类里面的&lt;code class=&quot;highlighter-rouge&quot;&gt;apply&lt;/code&gt;方法调用的。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def apply(conf: SparkConf, numCores: Int): UnifiedMemoryManager = {
  val maxMemory = getMaxMemory(conf)
  new UnifiedMemoryManager(
    conf,
    maxHeapMemory = maxMemory,
    onHeapStorageRegionSize =
      (maxMemory * conf.getDouble(&quot;spark.memory.storageFraction&quot;, 0.5)).toLong,
    numCores = numCores)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;然后通过 find Uages 找到是在 &lt;code class=&quot;highlighter-rouge&quot;&gt;sparkEnv&lt;/code&gt;里面调用。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val memoryManager: MemoryManager =
  if (useLegacyMemoryManager) {
    new StaticMemoryManager(conf, numUsableCores)
  } else {
    UnifiedMemoryManager(conf, numUsableCores)
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;是通过判断参数，判断是使用统一内存管理还是非内存管理。&lt;/p&gt;

&lt;p&gt;然后通过查看usages 发现是在 &lt;code class=&quot;highlighter-rouge&quot;&gt;CoarseGrainedExecutorBackEnd&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;MesosExecutorBackEnd&lt;/code&gt;里面调用的，所以是每个executor都有一个统一内存管理的实例(…很显然，逻辑也是这样)。&lt;/p&gt;
</description>
                <link>http://turbofei.github.io/spark/2016/12/19/spark%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86</link>
                <guid>http://turbofei.github.io/spark/2016/12/19/spark统一内存管理</guid>
                <pubDate>2016-12-19T00:00:00+08:00</pubDate>
        </item>

        <item>
                <title>java unsafe类的使用</title>
                <description>
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最近在写堆外操作的代码，需要用到unsafe 类，记录下。&lt;/p&gt;

&lt;h1 id=&quot;unsafe-简介&quot;&gt;unsafe 简介&lt;/h1&gt;

&lt;p&gt;unsafe类位于 sun.misc包,之所以叫unsafe是因为他操作堆外内存，即不受JVM控制的内存。由于最近要做点把数据存储在堆外的工作，所以了解了下unsafe。&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;下面是关于unsafe做测试的代码。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-JAVA&quot;&gt;import sun.misc.Unsafe;

import java.lang.reflect.Field;

/**
 * Created by bbw on 2016/11/11.
 */
class cat{
    public Integer name;
    public Integer age;
    public cat(Integer name,Integer age){
        this.name=name;
        this.age=age;
    }

}
public class testUnSafe {
    private static int apple = 10;
    private int orange = 10;
    private int banana=10;
    public   cat ki=new cat(233,3);

 //这是获得对象里面对象field的方法，根据这个对象在类里面的偏移量来获得
    public Object getObject(long offset) throws SecurityException, NoSuchFieldException, IllegalArgumentException,
            IllegalAccessException{
        return getUnsafeInstance().getObject(this,offset);
    }


    public static void main(String[] args) throws Exception {
        Unsafe unsafe = getUnsafeInstance();
        testUnSafe tus=new testUnSafe();

        Field appleField = testUnSafe.class.getDeclaredField(&quot;apple&quot;);
        // 获得field的偏移量
        System.out.println(&quot;Location of Apple: &quot; + unsafe.staticFieldOffset(appleField));

        Field orangeField = testUnSafe.class.getDeclaredField(&quot;orange&quot;);
        System.out.println(&quot;Location of Orange: &quot; + unsafe.objectFieldOffset(orangeField));



//这是field 是一个cat类的实例化对象，根据他的便宜地址获得对象，然后强制类型转化
        Field catField = testUnSafe.class.getDeclaredField(&quot;ki&quot;);
        System.out.println(&quot;Location of cat: &quot; + unsafe.objectFieldOffset(catField));
        long offset=unsafe.objectFieldOffset(catField);
        Object rki=tus.getObject(offset);
        cat rrki=(cat)rki;
        System.out.println(rrki.name);

        // follow is addressTest
        cat ncat=new cat(333,444);
        cat ncat2=new cat(555,666);
        cat[] ca={ncat,ncat2};
        long catArrayOffset=unsafe.arrayBaseOffset(cat[].class);
        System.out.println(catArrayOffset+&quot; &quot;+unsafe.arrayIndexScale(cat[].class));
        //cat rncat=((cat[])(tus.getObject(catArrayOffset)))[0];
       // System.out.println(rncat.name+rncat.age);
        Field bananaField = testUnSafe.class.getDeclaredField(&quot;banana&quot;);
        System.out.println(&quot;Location of banana: &quot; + unsafe.objectFieldOffset(bananaField));
    }
    
    //获得unsafe 的方法，是单例模式
    private static Unsafe getUnsafeInstance() throws SecurityException, NoSuchFieldException, IllegalArgumentException,
            IllegalAccessException {
        Field theUnsafeInstance = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);
        theUnsafeInstance.setAccessible(true);
        return (Unsafe) theUnsafeInstance.get(Unsafe.class);
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;unsafe 是单例模式，所以全局就只有一个unsafe，必须用它提供的方法来获取。
然后里面有获得里面字段 和静态字段偏移地址的方法，偏移地址是相对于在这个对象里面的偏移地址，可以根据偏移地址获得这个field。
例如，我在这个类里面声明的 cat 类 field ，就可以根据它在对象里面偏移地址来取得这个类。&lt;/p&gt;

&lt;p&gt;至于如何获得方法里面变量的内存地址以及如何通过这个获得的内存地址来取得这个变量对象，我还不是很明白，只知道unsafe.arrayBaseOffset 来获得对象数据的偏移地址。&lt;/p&gt;

&lt;p&gt;下面是我写的一个静态类，可以用来实现unsafe的放置变量，并且可以把这块堆外内存里面存的数据转化为迭代器。
我是这样存数据的，首先是申请一块堆外内存，然后前四个字节存储这块内存的大小，然后紧接着四个字节存储已经使用的大小。然后存储数据的类型是从外部传进去的，0代表int,1代表long，2代表double。
然后每次在写入数据的时候，都会判断这块内存的大小够不够写入数据，如果不够就申请一个更大的内存，然后把原来的数据拷贝到新的内存里面，重新对这块内存的前八个字节赋值，即内存的大小和使用情况。
然后这个类的静态参数在每次传入内存的起始地址后会首先读取这块内存的前八个字节，获得内存大小以及使用情况。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&quot;language-JAVA&quot;&gt;
package org.apache.spark.unsafe;
import java.util.Iterator;
/**
 * Created by bbw on 2016/11/14.
 */
public  final class UnsafeBuffer&amp;lt;T&amp;gt; {



    public  static int  MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    public static   int  hugeCapacity(int minCapacity) {
        if (minCapacity &amp;lt; 0) throw new OutOfMemoryError();
        if ((minCapacity &amp;gt; MAX_ARRAY_SIZE))
            return Integer.MAX_VALUE;
        else
            return MAX_ARRAY_SIZE;
        }


    public static long  copyBuf2New ( long baseAddress,int vType,int  minCapacity) {
        // read the size and count of this buf(the format size,count)
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);



        long address = PlatformDependent.UNSAFE.allocateMemory(minCapacity);
        // write the size and count

        PlatformDependent.UNSAFE.putInt(null,address,minCapacity);
        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount);


        int   i= 8;
        switch (vType) {
            case 0 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putInt(null, address + i, PlatformDependent.UNSAFE.getInt(null, baseAddress + i));
        i = i + 4;
        }
            case 1 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putLong(null, address + i, PlatformDependent.UNSAFE.getLong(null, baseAddress + i));
        i = i + 8;
        }
            case 2 :
        while (i &amp;lt; sizeCount) {
        PlatformDependent.UNSAFE.putDouble(null, address + i, PlatformDependent.UNSAFE.getDouble(null, baseAddress + i));
        i = i + 8;
        }
        default:
            assert (1==0);
        }
        return address;

        }


        public static long putInt(long baseAddress, int vType,int value){
            int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
            int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

           long address= ensureCapacity(baseAddress,vType,sizeCount+4);

            PlatformDependent.UNSAFE.putInt(null,address+sizeCount,value);

            PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+4);

            return address;


        }
    public static long putLong(long baseAddress, int vType,long value){
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

        long address= ensureCapacity(baseAddress,vType,sizeCount+8);

        PlatformDependent.UNSAFE.putLong(null,address+sizeCount,value);

        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+8);

        return address;


    }
    public static long putDouble(long baseAddress, int vType,double value){
        int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);

        long address= ensureCapacity(baseAddress,vType,sizeCount+8);

        PlatformDependent.UNSAFE.putDouble(null,address+sizeCount,value);

        PlatformDependent.UNSAFE.putInt(null,address+4,sizeCount+8);

        return address;


    }


public  static long grow (long  baseAddress,int vType,int minCapacity) {

    int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
    int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);
        int  oldCapacity=size;
        int  newCapacity = oldCapacity &amp;lt;&amp;lt; 1;
        if (newCapacity - minCapacity &amp;lt; 0) newCapacity = minCapacity;
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0) newCapacity = hugeCapacity(minCapacity);
        //buf = Arrays.copyOf(buf, newCapacity)
        //重新分配空间
        // baseAddress=PlatformDependent.UNSAFE.allocateMemory(newCapacity)
        long  temp=copyBuf2New(baseAddress,vType,minCapacity);
        PlatformDependent.UNSAFE.freeMemory(baseAddress);

    return temp;
}

    public static  long   ensureCapacity (long baseAddress,int vType,int minCapacity) {

    int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
    int sizeCount=PlatformDependent.UNSAFE.getInt(null,baseAddress+4);


        if (minCapacity - size &amp;gt; 0)
           return grow(baseAddress,vType,minCapacity);
    else return baseAddress;
}




    public static   Iterator&amp;lt;Integer&amp;gt; intIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Integer&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Integer next() {
                offset += 4;
                return PlatformDependent.UNSAFE.getInt(null, address + offset - 4);
            }
        };
    }

    public static   Iterator&amp;lt;Long&amp;gt; longIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Long&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Long next() {
                offset += 8;
                return PlatformDependent.UNSAFE.getLong(null, address + offset - 8);
            }
        };
    }

    public static   Iterator&amp;lt;Double&amp;gt; doubleIterator( long baseAddress) {
        // int size=PlatformDependent.UNSAFE.getInt(null,baseAddress);
        final int sizeCount = PlatformDependent.UNSAFE.getInt(null, baseAddress + 4);
        final long address = baseAddress;
        return new Iterator&amp;lt;Double&amp;gt;() {
            int offset = 8;

            @Override
            public boolean hasNext() {
                if (offset &amp;lt; sizeCount)
                    return true;
                else {
                    PlatformDependent.UNSAFE.freeMemory(address);
                    return false;
                }
            }

            @Override
            public Double next() {
                offset += 8;
                return PlatformDependent.UNSAFE.getDouble(null, address + offset - 8);
            }
        };
    }


    public static  long createBuff(int size){
        long address=PlatformDependent.UNSAFE.allocateMemory(size);
        PlatformDependent.UNSAFE.putInt(null,address,size);
        PlatformDependent.UNSAFE.putInt(null,address+4,8);
        return address;
    }
}

&lt;/code&gt;&lt;/pre&gt;
</description>
                <link>http://turbofei.github.io/coding/2016/11/13/java-unsafe%E7%B1%BB%E7%9A%84%E4%BD%BF%E7%94%A8</link>
                <guid>http://turbofei.github.io/coding/2016/11/13/java-unsafe类的使用</guid>
                <pubDate>2016-11-13T08:24:19+08:00</pubDate>
        </item>

        <item>
                <title>ganglia 安装</title>
                <description>
&lt;p&gt;&lt;strong&gt;Overview&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;最近帮大菠萝安装ganglia，记录下，方便以后安装。&lt;/p&gt;

&lt;h1 id=&quot;cluster-server-and-clients&quot;&gt;Cluster Server and Clients&lt;/h1&gt;

&lt;p&gt;I configured our nodes with the following hostnames using these steps. Our server is:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;3.buhpc.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The clients are:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1.buhpc.com
2.buhpc.com
4.buhpc.com
5.buhpc.com
6.buhpc.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;!--more--&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation&lt;/h1&gt;

&lt;p&gt;On the server, inside the shared folder of our cluster, we will first download the latest version of ganglia. For our cluster, /nfs is the folder with our network file system.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /nfs
wget http://downloads.sourceforge.net/project/ganglia/ganglia%20monitoring%20core/3.7.2/ganglia-3.7.2.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;On the server, we will install dependencies and libconfuse.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;yum install freetype-devel rpm-build php httpd libpng-devel libart_lgpl-devel python-devel pcre-devel autoconf automake libtool expat-devel rrdtool-devel apr-devel gcc-c++ make pkgconfig -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-2.7-7.el7.x86_64.rpm -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-devel-2.7-7.el7.x86_64.rpm -y

#建立rrd数据库
mkdir -p /var/lib/ganglia/rrds/
chown nobody:nobody -R /var/lib/ganglia/rrds/
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Now, we will build the rpms from ganglia-3.7.2 on the server.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rpmbuild -tb ganglia-3.7.2.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;After running rpmbuild, /root/rpmbuild/RPMS/x86_64 contains the generated rpms:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /root/rpmbuild/RPMS/x86_64/
yum install *ganglia*.rpm -y
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;We will remove gmetad because we do not need it on the clients. Send the rest of the rpms to all the clients’ /tmp folder:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /root/rpmbuild/RPMS/x86_64/
rm -rf ganglia-gmetad*.rpm
scp *.rpm root@1.buhpc.com:/tmp
scp *.rpm root@2.buhpc.com:/tmp
scp *.rpm root@4.buhpc.com:/tmp
scp *.rpm root@5.buhpc.com:/tmp
scp *.rpm root@6.buhpc.com:/tmp
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;SSH onto every client and install the rpms that we will need:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh root@#.buhpc.com
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-2.7-7.el7.x86_64.rpm -y
yum install https://dl.fedoraproject.org/pub/epel/7/x86_64/l/libconfuse-devel-2.7-7.el7.x86_64.rpm -y
yum install /tmp/*ganglia*.rpm - y
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Back on the server, we will adjust the gmetad configuration file:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /etc/ganglia
vim gmetad.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;buhpc will be the name of  our cluster. Find the following line and add the name of your cluster and ip address. I am using the subdomain instead of the ip address.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;data_source &quot;buhpc&quot; 1 3.buhpc.com
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Now, we edit the server’s gmond configuration file.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/ganglia/gmond.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Make sure that these sections have the following and comment any extra lines you see that are within each section.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster {
  name = &quot;buhpc&quot;
  owner = &quot;unspecified&quot;
  latlong = &quot;unspecified&quot;
  url = &quot;unspecified&quot;
}

udp_send_channel {
  host = 1.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 2.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 3.buhpc.com
  port = 8649
  ttl = 1
}
udp_send_channel {
  host = 4.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 5.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 6.buhpc.com
  port = 8649
  ttl = 1
}

udp_recv_channel {
  port = 8649
  retry_bind = true
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Now, SSH into each of the clients and do the following individually. On every client:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/ganglia/gmond.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;We will change the clients’ gmond.conf in the same way as the server’s.  Make sure that these sections have the following lines and comment any extra lines you see that are within each section.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cluster {
  name = &quot;buhpc&quot;
  owner = &quot;unspecified&quot;
  latlong = &quot;unspecified&quot;
  url = &quot;unspecified&quot;
}

udp_send_channel {
  host = 1.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 2.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 3.buhpc.com
  port = 8649
  ttl = 1
}
udp_send_channel {
  host = 4.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 5.buhpc.com
  port = 8649
  ttl = 1
}

udp_send_channel {
  host = 6.buhpc.com
  port = 8649
  ttl = 1
}

udp_recv_channel {
  port = 8649
  retry_bind = true
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;We will start gmond on the clients for monitoring.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chkconfig gmond on
systemctl start gmond
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;然后，安装ganglia-web 3.7.1&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget http://superb-sea2.dl.sourceforge.net/project/ganglia/ganglia-web/3.7.1/ganglia-web-3.7.1.tar.gz
tar zxvf  ganglia-web-3.7.1.tar.gz
cd  ganglia-web-3.7.1
vim Makefile
      # Location where gweb should be installed to (excluding conf, dwoo dirs).
      GDESTDIR = /var/www/html/ganglia

      # Gweb statedir (where conf dir and Dwoo templates dir are stored)
      GWEB_STATEDIR = /var/lib/ganglia-web

      # Gmetad rootdir (parent location of rrd folder)
      GMETAD_ROOTDIR = /var/lib/ganglia

      # User by which your webserver is running
      APACHE_USER =  apache

 make install
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Next, we will want to disable SELinux. Change SELINUX inside /etc/sysconfig/selinux from enforcing to disabled. Then, restart the server node.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vim /etc/sysconfig/selinux
SELINUX=disabled
#如果 SELINUX本就是disable，不必reboot
reboot
Now, on the server, we’ll open the correct ports on the firewall.

#如果 firewall 没有打开，systemctl service firewalld
firewall-cmd --permanent --zone=public --add-service=http
firewall-cmd --permanent --zone=public --add-port=8649/udp
firewall-cmd --permanent --zone=public --add-port=8649/tcp
firewall-cmd --permanent --zone=public --add-port=8651/tcp
firewall-cmd --permanent --zone=public --add-port=8652/tcp
firewall-cmd --reload
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;On the server, we will now start httpd, gmetad, and gmond.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chkconfig httpd
chkconfig gmetad on
chkconfig gmond on
systemctl start httpd
systemctl start gmetad
systemctl start gmond
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;Visit http://3.buhpc.com/ganglia to see Ganglia’s monitoring. You should see something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.slothparadise.com/wp-content/uploads/2016/03/ganglia-home-page.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

</description>
                <link>http://turbofei.github.io/bigdata/2016/08/17/ganglia-%E5%AE%89%E8%A3%85</link>
                <guid>http://turbofei.github.io/bigdata/2016/08/17/ganglia-安装</guid>
                <pubDate>2016-08-17T05:15:03+08:00</pubDate>
        </item>


</channel>
</rss>
